В настоящем разделе мы разберемся, что делать в случае, когда матрица $A$ - не обратима, но обратить её все-таки необходимо.

Задача 1.15. Пусть $X_{0}$ - решение уравнения $A X=E$, где $A$ - квадратная невырожденная матрица. Докажите, что $X_{0}$ - единственное решение этого уравнения, причем $X_{0} A=A X_{0}$.

Решение. Докажем, что если $A X_{0}=E$, то $X_{0} A=E$. Действительно, раз $A X_{0}=E$, значит, $\left(A X_{0}\right) A=A$, в силу ассоциативности умножения матриц, следовательно, и $A\left(X_{0} A\right)=A$. Откуда получаем, что
$$
A\left(\left(X_{0} A\right)-E\right)=0
$$

Обозначим через $x_{j} j-$ й столбец матрицы $X_{0} A-E$. Полученное матричное равенство распадается в серию равенств столбцов
$$
A x_{j}=0
$$

в силу невырожденности матрицы $A$ мы имеем, что $x_{j}=0$, значит, $X_{0} A=E$. Мы умышленно не пользуемся здесь формулой для обращения матриц и пользуемся только самыми элементарными свойствами матриц, так как на самом деле при доказательстве формулы обращения неявно используется утверждение данной задачи.
Теперь докажем единственность. Пусть $X_{0}, X_{1}$ - решения уравнения $A X= E$. В таком случае $A\left(X_{0}-X_{1}\right)=0$, и аналогично с рассуждением из первого пункта получаем, что $X_{0}=X_{1}$.
Предлагаем читателю самостоятельно проверить такой "очевидный" факт, что в алгебре матриц только одна правая единица, то есть существует единственная матрица $E$ такая, что $A E=A, \forall A$. Отдельно проверьте, что правая единица совпадает с левой.
Вернемся к уравнению $A X=E$.
Если матрица $A$ имеет нулевой определитель, то решения нет. Если мы избавимся от требования к матрице $A$ быть квадратной и предположим, что $A$ и $X$ - прямоугольные матрицы согласованного размера, то у соответствующего уравнения, вообще говоря, не будет единственного решения. Однако есть способ определить так называемые псевдообратные матрицы, которые, с одной стороны, будут удовлетворять свойствам, похожим на свойства обратной матрицы, а с другой стороны, для них будет верна теорема существования и единственности для всевозможных, в том числе и прямоугольных, матриц $A$.
Пусть $A$ - некоторая матрица размера $m \times n$.
Определение 1.16. Матрицу $A^{+}$размера $n \times m$ будем называть псевдообратной матрицей для $A$, если выполняются два условия:
$$
\begin{gathered}
A A^{+} A=A \quad \text { и } \\
\exists U, V: A^{+}=U A^{*}=A^{*} V,
\end{gathered}
$$

здесь $U, V$ - матрицы подходящего размера, а $A^{*}=\bar{A}^{T}$ - сопряженная матрица.

Первое условие - это следствие уравнения $A X=E . \mathrm{K}$ сожалению, уравнение $A X A=A$ имеет, вообще говоря, бесконечное множество решений, так что второе условие необходимо для однозначного выбора решения. В силу причин, о которых будет сказано ниже (связь с методом наименьших квадратов), условие выбирается таким образом, что строки и столбцы псевдообратной матрицы должны являться линейными комбинациями строк и столбцов исходной матрицы и сопряженной к ней.

Задача 1.17. Пусть $A$ - квадратная невырожденная матрица. Докажите, что $A^{+}=A^{-1}$.

Решение. По условию обратная матрица существует, докажем, что она будет псевдообратной. Начнем с первого условия:
$$
A A^{+} A=A A^{-1} A=E A=A .
$$

Проверим второе условие. Нужно подобрать такую матрицу $U$, что $A^{-1}= U A^{*}$. Поскольку матрица $A$ была невырожденной, такой же будет и матрица $A^{*}$, значит, $U=A^{-1} A^{*-1}=\left(A^{*} A\right)^{-1}$, аналогично находится и матрица $V$. \(\square\)

Естественные вопросы: для каких матриц псевдообратная матрица определена, и если определена, то будет ли она единственной? Следующее утверждение носит название теоремы Мура-Пенроуза.

Задача 1.18. Докажите, что для любой матрицы $A \in \mathrm{Mat}_{m \times n}$ существует, причем единственная псевдообратная матрица $A^{+}$.

Решение. Пусть $\operatorname{rk} A=r$. Представим матрицу $A$ в виде произведения $A=B C$, где матрица $B$ имеет размер $m \times r$, матрица $C$ имеет размер $r \times n$. Заметим, что если такое разложение существует, то $\operatorname{rk} B=\operatorname{rk} C=r$. Действительно, с одной стороны, $\operatorname{rk} B \leq r$ и $\operatorname{rk} C \leq r$, с другой стороны, $\operatorname{rk}(B C) \leq \min (\operatorname{rk} B, \operatorname{rk} C)$. Остается проверить, что такое разложение действительно существует (оно, вообще говоря, не единственно). Возьмем в качестве матрицы $B$ какую-нибудь матрицу, $r$ столбцов которой совпадают с $r$ линейно независимыми столбцами исходной матрицы $A$. Тогда уравнение $A=B C$ означает, что $j$-й столбец матрицы $A$ равен линейной комбинации этих столбцов с коэффициентами, которые являются элементами $j$-го столбца матрицы $C$. Разумеется, такие коэффициенты можно подобрать, так как любой столбец матрицы $A$ должен выражаться как линейная комбинация $r$ линейно независимых столбцов (так как это максимальное количество линейно независимых столбцов в матрице $A$ ). Читателю в качестве несложного упражнения предлагается доказать, что таких разложений, вообще говоря, бесконечно много.
Далее, фиксируем разложение $A=B C$. Понятно, что $B^{*} B$ и $C C^{*}$ - квадратные матрицы размера $r \times r$. Значит, эти матрицы невырождены, так как в матрицах $B$ и $C$ было по $r$ линейно независимых столбцов ${ }^{17}$.

\footnotetext{
${ }^{17}$ Для доказательства невырожденности указанных матриц также можно воспользоваться идеей задачи 3.43.
}

Логично предположить, что по аналогии с обратными матрицами должно иметь место равенство $A^{+}=C^{+} B^{+}$, поэтому логично сначала найти $B^{+}$и $C^{+}$. Мы знаем, что $B^{*} B$ - невырожденная матрица. Пусть $L:=\left(B^{*} B\right)^{-1}$. Тогда $L B^{*} B=E$. Домножив слева на $B$, получаем $B\left(L B^{*}\right) B=B$. Остается проверить, что матрица
$$
B^{+}=\left(B^{*} B\right)^{-1} B^{*}
$$

удовлетворяет и второму условию для псевдообратной матрицы, то есть должны существовать такие матрицы $U, V$, что
$$
B^{+}=U B^{*}=B^{*} V
$$

В качестве матрицы $U$ можно взять матрицу $L$. Найдем матрицу $V$, удовлетворяющую условию
$$
B^{+}=B^{*} V
$$

В качестве матрицы $V$ можно взять $V=B\left(B^{*} B\right)^{-1} B^{+}$, где $B^{+}$мы определили выше.
Аналогичные рассуждения показывают, что $C^{+}=C^{*}\left(C C^{*}\right)^{-1}$. Проверим теперь нашу гипотезу, что $A^{+}=C^{+} B^{+}$.
Прежде всего проверим условие $A A^{+} A=A$. Имеем
$$
A A^{+} A=A\left(C^{+} B^{+}\right) A=B C C^{*}\left(C C^{*}\right)^{-1}\left(B^{*} B\right)^{-1} B^{*} B C=B C=A .
$$

Теперь остается проверить, что найдутся такие матрицы $U$ и $V$, что $A^{+}= U A^{*}=A^{*} V$. Если преобразовать явное выражение для матрицы $A^{+}$, которое мы получили выше, получим
$$
\begin{array}{r}
A^{+}=C^{*}\left(C C^{*}\right)^{-1}\left(B^{*} B\right)^{-1} B^{*}= \\
=C^{*}\left(C C^{*}\right)^{-1}\left(B^{*} B\right)^{-1}\left[\left(C C^{*}\right)^{-1} C C^{*}\right] B^{*}=U C^{*} B^{*}=U A^{*}
\end{array}
$$

Аналогично находится и матрица $V$.
Проверим теперь, что матрица $A^{+}$единственна. Действительно, пусть есть две псевдообратные матрицы $A_{1,2}^{+}$такие, что
$$
A A_{j}^{+} A=A, \quad A_{j}^{+}=U_{j} A^{*}=A^{*} V_{j}, \quad j=1,2 .
$$

Положим $D=A_{2}^{+}-A_{1}^{+}$. Мы хотим доказать, что $D=0$. Легко видеть, что
$$
A D A=0, \quad D=\left(U_{2}-U_{1}\right) A^{*}=A^{*}\left(V_{2}-V_{1}\right)
$$

Заметим, что $(D A)^{*}=A^{*} D^{*}=A^{*}\left(A^{*}\left(V_{2}-V_{1}\right)\right)^{*}=A^{*} V^{*} A$, где $V=V_{2}-V_{1}$. Значит,
$$
(D A)^{*} D A=A^{*} V^{*} A D A=A^{*} V^{*}(A D A)=0
$$

Как следует из результатов пункта 3.4., отсюда мы получаем, что $D A=0$. С другой стороны,
$$
0=D A U^{*}=D D^{*}
$$

где $U:=U_{2}-U_{1}$, значит, и $D D^{*}=0$, следовательно, окончательно получаем $D=0$.

Теперь перейдем к вопросу о прикладной роли псевдообратной матрицы. Логично предположить, что уравнение $A x=y$ должно иметь "решение" $x=$
$A^{+} y$. Вопрос только, в каком смысле, если система уравнений несовместна или, наоборот, имеет бесконечно много решений. Справедлива следующая теорема (см. например [18], с. 36).

Теорема 1.19. Вектор $x_{0}$, определяемый как $x_{0}:=A^{+} y$, является наилучшим приближенным решением системы $A x=y$, то есть квадратичное отклонение $|y-A x|^{2}$ достигает минимального значения при $x=x_{0}$, а среди всех векторов $x$ таких, что значение квадратичного отклонения минимально, вектор $x_{0}$ имеет наименьший модуль $\left|x_{0}\right|$.

Таким образом, оказывается, что псевдообратные матрицы при отсутствии единственного решения дают наилучшее решение в смысле метода наименьших квадратов, что и обуславливает важное прикладное значение данного объекта. Заметим, что в настоящем параграфе псевдообратная матрица построена в алгоритмизуемом виде. Вопрос об эффективности данного, явного, алгоритма мы не обсуждаем, и заинтересованного читателя отсылаем к современным работам по вычислительной математике.

\section*{2 Линейные операторы}

\section*{2.1. Структура линейного преобразования}

Пусть $V$ - векторное пространство над полем $\mathbb{K}, \varphi: V \rightarrow V$ - линейный оператор, $A$ - его матрица в некотором базисе пространства $V$.

Определение 2.1. Характеристическим многочленом оператора $\varphi$ называется многочлен
$$
\chi_{\varphi}(t):=\operatorname{det}(t E-A) \in \mathbb{K}[t] .
$$

Проверим, что характеристический многочлен оператора корректно определен (то есть не зависит от базиса, в котором вычислялась матрица $A$ оператора $\varphi$ ). Действительно, в другом базисе матрица того же оператора будет $A^{\prime}=C^{-1} A C$, где $C$ - матрица перехода между базисами, и тогда
$$
\begin{gathered}
\operatorname{det}\left(t E-A^{\prime}\right)=\operatorname{det}\left(t E-C^{-1} A C\right)=\operatorname{det}\left(C^{-1}(t E-A) C\right)= \\
=\operatorname{det}\left(C^{-1}\right) \operatorname{det}(t E-A) \operatorname{det} C=\operatorname{det}(t E-A)
\end{gathered}
$$

Отметим полезную формулу:
$$
\begin{equation*}
\chi_{\varphi}(t)=t^{n}-(\operatorname{tr} A) t^{n-1}+\ldots+(-1)^{n} \operatorname{det} A \tag{23}
\end{equation*}
$$

где $A$ - матрица оператора $\varphi$ в произвольном базисе. В частности, след и определитель матрицы оператора не зависят от базиса (и, таким образом, можно говорить про след и определитель оператора; то же, конечно, относится и к другим коэффициентам характеристического многочлена, по поводу их выражения через матрицу $A$ оператора см. текст после леммы 2.36).

Задача 2.2. Пусть $P$ - матрица проектора (см. определение 1.5) в некотором базисе. Докажите, что ранг матрицы $P$ равен ее следу.

Решение. След матрицы линейного оператора, будучи одним из коэффициентов характеристического многочлена, не зависит от базиса ${ }^{18}$. Аналогично, ранг матрицы линейного оператора, будучи равным размерности его образа, также не зависит от базиса. Значит, указанную формулу $\operatorname{rk} P=\operatorname{tr} P$ достаточно доказать в каком-то одном базисе.
Мы знаем (см. задачу 1.6), что проектор $P: V \rightarrow V$ совпадает с оператором проектирования $\operatorname{Pr}_{U}^{W}$ на некоторое подпространство $U \subset V$ параллельно некоторому подпространству $W \subset V$ такому, что $V=U \oplus W$, причем $U=\operatorname{im} P, W=\operatorname{ker} P$. Выберем базис в $V$, согласованный с указанным разложением в прямую сумму, то есть такой, что его первые $k$ векторов образуют базис в $U$, а оставшиеся $n-k$ - базис в $W$. Легко видеть, что в указанном базисе оператор $P$ имеет диагональную матрицу, в которой на первых $k$ местах на главной диагонали стоят единицы, а на оставшихся $n-k$ - нули. Тогда число единиц есть $k=\operatorname{dim} U=\operatorname{rk} P$, а их сумма есть $\operatorname{tr} P$.

\footnotetext{
${ }^{18}$ Впрочем, инвариантность следа может быть легко доказана и с помощью непосредственно проверяемого тождества $\operatorname{tr}(A B)=\operatorname{tr}(B A) \forall A \in \in \operatorname{Mat}_{m \times n}(\mathbb{K}), B \in \operatorname{Mat}_{n \times m}(\mathbb{K})$.
}

Задача 2.3. Пусть $A$ - матрица (в некотором базисе) поворота трехмерного пространства вокруг некоторой оси на угол $\alpha$. Выразить $\alpha$ через элементы матрицы $A$.

Решение. Как и в предшествующей задаче, воспользуемся независимостью следа матрицы оператора от базиса. Выберем в трехмерном пространстве ортонормированный базис $\left\{\mathbf{e}_{1}, \mathbf{e}_{2}, \mathbf{e}_{3}\right\}$, у которого $\mathbf{e}_{3}$ совпадает с направлением оси поворота, а $\mathbf{e}_{1}, \mathbf{e}_{2}$ образуют базис в ортогональной к $\mathbf{e}_{3}$ плоскости. Тогда матрица поворота имеет вид
$$
\left(\begin{array}{ccc}
\cos \alpha & -\sin \alpha & 0 \\
\sin \alpha & \cos \alpha & 0 \\
0 & 0 & 1
\end{array}\right)
$$

или с возможной заменой $\alpha$ на $-\alpha$ (что не влияет на знак диагональных элементов в силу четности функции $\cos \alpha$ ). Отсюда получаем, что $\cos \alpha= \frac{\operatorname{tr} A-1}{2}$.

Последовательность Фибоначчи $0,1,1,2,3,5,8,13, \ldots$ определяется тем, что каждый следующий член равен сумме двух предыдущих, $a_{n}=a_{n-1}+ a_{n-2}$, и двумя начальными членами $a_{0}=0, a_{1}=1$.

Задача 2.4. Найти явную формулу для $a_{n}$.
Решение. 1-й способ. Заметим, что вектор $\mathbf{v}_{n}:=\left(a_{n}, a_{n-1}\right)^{T}$ линейно выражается через $\mathbf{v}_{n-1}$ :
$$
\mathbf{v}_{n}=A \mathbf{v}_{n-1}, \quad \text { где } A=\left(\begin{array}{ll}
1 & 1 \\
1 & 0
\end{array}\right),
$$

причем $\mathbf{v}_{1}=(1,0)^{T}$. Поэтому $a_{n}$ есть первая компонента $A^{n-1} \mathbf{v}_{1}$.
Рассмотрим $A=\left(\begin{array}{ll}1 & 1 \\ 1 & 0\end{array}\right)$ как матрицу некоторого оператора, заданную относительно стандартного базиса в $\mathbb{R}^{2}$. Характеристический многочлен оператора с матрицей $A$ есть $\chi_{A}(t)=t^{2}-(\operatorname{tr} A) t+\operatorname{det} A=t^{2}-t-1$; его корни $\alpha:=\frac{1+\sqrt{5}}{2}, \beta:=\frac{1-\sqrt{5}}{2}$. Поскольку $\alpha \neq \beta$, матрица $A$ диагонализируема. Легко посчитать, что собственные векторы, отвечающие $\alpha$ и $\beta$, суть соответственно $\mathbf{u}_{1}:=(\alpha, 1)^{T}, \mathbf{u}_{2}:=(\beta, 1)^{T}$. Тогда наш оператор в базисе $\left\{\mathbf{u}_{1}, \mathbf{u}_{2}\right\}$ имеет диагональную матрицу $\Lambda:=\operatorname{diag}(\alpha, \beta)$, и мы имеем $\Lambda=C^{-1} A C$, где $C=\left(\begin{array}{cc}\alpha & \beta \\ 1 & 1\end{array}\right)$ - матрица перехода от исходного стандартного базиса к базису $\left\{\mathbf{u}_{1}, \mathbf{u}_{2}\right\}$. Тогда $A=C \Lambda C^{-1}$ и, значит, для любого натурального $n \geq 1 A^{n-1}=C \Lambda^{n-1} C^{-1}$, причем (как легко проверить) возведение диагональной матрицы в степень сводится к возведению в степень ее диагональных элементов. Находим $C^{-1}=\frac{1}{\sqrt{5}}\left(\begin{array}{cc}1 & -\beta \\ -1 & \alpha\end{array}\right)$, и теперь первая компонента $A^{n-1} \mathbf{v}_{1}$ легко вычисляется:
$$
a_{n}=\frac{1}{\sqrt{5}}\left(\alpha^{n}-\beta^{n}\right)=\frac{1}{\sqrt{5}}\left(\left(\frac{1+\sqrt{5}}{2}\right)^{n}-\left(\frac{1-\sqrt{5}}{2}\right)^{n}\right) .
$$

Для полноты приведем два других решения данной задачи.
2-й способ (интерполяционный многочлен). Согласно теореме ГамильтонаКэли, характеристический многочлен $\chi_{A}(t)$ аннулирует оператор $A$. Для произвольного многочлена $P(t) \in \in \mathbb{R}[t]$ существует многочлен $p(t) \in \mathbb{R}[t]$ степени не выше 1 такой, что $P(A)=p(A)$ (равенство элементов кольца матриц $\operatorname{Mat}_{2}(\mathbb{R})$ ). Чтобы это доказать, поделим $P(t)$ на $\chi_{A}(t)$ с остатком: $P(t)==Q(t) \chi_{A}(t)+p(t)$, где либо $p(t)=0$, либо $\operatorname{deg} p(t)<\operatorname{deg} \chi_{A}(t)==2$, тогда $P(A)=p(A)$, поскольку $\chi_{A}(A)=0$ (нулевой линейный оператор).
Для каждого натурального $n$ рассмотрим многочлен $P_{n}(t)==t^{n}$; согласно предыдущему, $\forall n \in \mathbb{N} \exists p_{n}(t)=a_{n}+b_{n} t \in \mathbb{R}[t]$ такой, что $P_{n}(A)=p_{n}(A)$. Легко видеть, что последнее равенство равносильно системе
$$
\left\{\begin{array}{l}
P_{n}(\alpha)=p_{n}(\alpha)=a_{n}+b_{n} \alpha \\
P_{n}(\beta)=p_{n}(\beta)=a_{n}+b_{n} \beta
\end{array}\right.
$$
(Действительно, так как $A$ имеет простой спектр, то существует обратимая матрица $C$ такая, что $C^{-1} A C=\Lambda=\operatorname{diag}(\alpha, \beta)$; кроме того,
$$
C^{-1} P(A) C=P\left(C^{-1} A C\right)=P(\Lambda)=\operatorname{diag}(P(\alpha), P(\beta)),
$$

и аналогично
$$
C^{-1} p(A) C=p\left(C^{-1} A C\right)=p(\Lambda)=\operatorname{diag}(p(\alpha), p(\beta))
$$

теперь осталось только заметить, что равенства $P(A)=p(A)$ и $C^{-1} P(A) C= C^{-1} p(A) C$ равносильны.) Таким образом, нам нужно решить (относительно $\left.a_{n}, b_{n}\right)$ систему
$$
\left\{\begin{array}{l}
a_{n}+b_{n} \frac{1+\sqrt{5}}{2}=\left(\frac{1+\sqrt{5}}{2}\right)^{n} \\
a_{n}+b_{n} \frac{1-\sqrt{5}}{2}=\left(\frac{1-\sqrt{5}}{2}\right)^{n}
\end{array}\right.
$$

откуда $2 a_{n}+b_{n}=\alpha^{n}+\beta^{n}, \sqrt{5} b_{n}=\alpha^{n}-\beta^{n}$. Несложные вычисления приводят к результату
$$
P_{n}(A)=A^{n}=a_{n} E+b_{n} A=\left(\begin{array}{cc}
\frac{1}{\sqrt{5}}\left(\alpha^{n+1}-\beta^{n+1}\right) & \frac{1}{\sqrt{5}}\left(\alpha^{n}-\beta^{n}\right) \\
\frac{1}{\sqrt{5}}\left(\alpha^{n}-\beta^{n}\right) & \frac{1}{\sqrt{5}}\left(\alpha^{n-1}-\beta^{n-1}\right)
\end{array}\right) .
$$

Таким образом, мы приходим к той же формуле для $n$-го числа Фибоначчи, что и в предыдущем решении. Подробности см. в [15], гл. $6, § 5$.

3-й способ (метод производящих функций). Здесь удобнее вместо исходной последовательности рассмотреть последовательность $f_{0}=1, f_{1}= 1, f_{n+2}=f_{n+1}+f_{n}$. Рассмотрим ее производящую функцию
$$
\operatorname{Fib}(s):=f_{0} s^{0}+f_{1} s+f_{2} s^{2}+\ldots+f_{n} s^{n}+\ldots=1+s+2 s^{2}+3 s^{3}+5 s^{4}+\ldots
$$

Умножая обе части предыдущего равенства на $s+s^{2}$ и используя рекуррентное соотношение для последовательности Фибоначчи, получаем равенство в

кольце формальных степенных рядов
$$
\left(s+s^{2}\right) \operatorname{Fib}(s)=\operatorname{Fib}(s)-1,
$$

откуда
$$
\operatorname{Fib}(s)=\frac{1}{1-s-s^{2}} .
$$

Раскладывая последнее выражение на простейшие дроби, получаем
$$
\begin{gathered}
\frac{1}{1-s-s^{2}}=\frac{1}{\sqrt{5}}\left(\frac{1}{s+\frac{1+\sqrt{5}}{2}}-\frac{1}{s-\frac{-1+\sqrt{5}}{2}}\right)= \\
=\frac{1}{\sqrt{5}}\left(\frac{1}{\alpha+s}-\frac{1}{\beta+s}\right)=\frac{1}{\sqrt{5}}\left(\frac{1}{\alpha(1-\beta s)}-\frac{1}{\beta(1-\alpha s)}\right)= \\
=\frac{1}{\sqrt{5}}\left(\sum_{n=0}^{\infty} \frac{\beta^{n} s^{n}}{\alpha}-\sum_{n=0}^{\infty} \frac{\alpha^{n} s^{n}}{\beta}\right)=\frac{1}{\sqrt{5}} \sum_{n=0}^{\infty}\left(\alpha^{n+1}-\beta^{n+1}\right) s^{n},
\end{gathered}
$$

где использовано соотношение $\alpha \beta=-1$. Мы приходим тем самым к полученной выше формуле для $a_{n}$ (с учетом сделанного сдвига нумерации последовательности). Подробности см., например, в [14], § 11, 12; [36], § 2.2 или в [37], § 2.2. \(\square\)

Комментарии. В связи со 2 -м способом нам потребовался ответ на следующий вопрос: пусть на $n$-мерном вещественном пространстве $V$ задан линейный оператор $A: V \rightarrow V$, тогда для каких многочленов $f(t), g(t) \in \mathbb{R}[t]$ имеет место равенство $f(A)==g(A)$ ? Очевидно, этот вопрос эквивалентен следующему: когда $f(A)=0$ ? Ясно, что такие ненулевые многочлены существуют, так как $E=A^{0}, A, A^{2}, \ldots A^{n^{2}}$ линейно зависимы, поскольку $\operatorname{dim}\left(\operatorname{Mat}_{n}(\mathbb{R})\right)=n^{2}$.
Например, пусть $A$ имеет простой спектр $\left\{\lambda_{1}, \ldots, \lambda_{n}\right\}$, содержащийся в $\mathbb{R}$. Тогда $f(A)=0 \Leftrightarrow f\left(\lambda_{k}\right)=0 \forall k, 1 \leq k \leq n$. Если же жорданова нормальная форма $A$ есть одна клетка $J_{n}(\lambda), \lambda \in \in \mathbb{R}$, то $f(A)=0 \Leftrightarrow f^{(k)}(\lambda)= 0 \forall k, 0 \leq k \leq n-1$. Доказательство последнего утверждения следует из тождества
$$
f\left(J_{n}(\lambda)\right)=\left(\begin{array}{ccccc}
f(\lambda) & f^{\prime}(\lambda) & \frac{1}{2} f^{\prime \prime}(\lambda) & \ldots & \frac{1}{(n-1)!} f^{(n-1)}(\lambda)  \tag{24}\\
0 & f(\lambda) & f^{\prime}(\lambda) & \ldots & \frac{1}{(n-2)!} f^{(n-2)}(\lambda) \\
0 & 0 & f(\lambda) & \ldots & \frac{1}{(n-3)!} f^{(n-3)}(\lambda) \\
\ldots \ldots & \ldots & \ldots & \ldots & \ldots
\end{array}\right) .
$$

Можно также спросить: чему изоморфна подалгебра $\mathbb{R}[A] \subset \subset \operatorname{Mat}_{n}(\mathbb{R})$, порожденная (как алгебра с единицей) оператором $A$ ? В случае простого спектра $\left\{\lambda_{1}, \ldots, \lambda_{n}\right\}$, содержащегося в $\mathbb{R}$, имеем изоморфизм $\mathbb{R}[A] \cong \mathbb{R}^{n}$, который задается формулой
$$
\mathbb{R}[A] \ni f(A) \mapsto\left(f\left(\lambda_{1}\right), \ldots, f\left(\lambda_{n}\right)\right) \in \mathbb{R}^{n}
$$

Другими словами, $\mathbb{R}[A]$ в этом случае - алгебра $\mathbb{R}$-значных функций на

спектре оператора $A$. В случае оператора $A$ с жордановой формой, совпадающей с одной жордановой клеткой $J_{n}(\lambda)$, алгебра $\mathbb{R}[A]$ изоморфна $\mathbb{R}[t] /\left(t^{n}\right) \cong \mathbb{R}[\varepsilon]$, где $\varepsilon$ удовлетворяет единственному соотношению $\varepsilon^{n}=0$, причем изоморфизм задается формулой, ср. (24):
$$
\begin{gathered}
\mathbb{R}[A] \ni f(A)=f(\lambda) E+\frac{f^{\prime}(\lambda)}{1}\left(J_{n}(\lambda)-\lambda E\right)+ \\
+\frac{f^{\prime \prime}(\lambda)}{2!}\left(J_{n}(\lambda)-\lambda E\right)^{2}+\ldots+\frac{f^{(n-1)}(\lambda)}{(n-1)!}\left(J_{n}(\lambda)-\lambda E\right)^{n-1} \mapsto \\
\mapsto f(\lambda)+\frac{f^{\prime}(\lambda)}{1!} \varepsilon+\frac{f^{\prime \prime}(\lambda)}{2!} \varepsilon^{2}+\ldots+\frac{f^{(n-1)}(\lambda)}{(n-1)!} \varepsilon^{n-1} \in \mathbb{R}[\varepsilon]
\end{gathered}
$$

Чему изоморфна алгебра $\mathbb{R}[A]$ в случае, когда спектр не содержится в $\mathbb{R}$ ? Рассмотрим сюръективный гомоморфизм алгебр $\mathbb{R}[t] \rightarrow \mathbb{R}[A]$, ядром которого является (главный) идеал в $\mathbb{R}[t]$, порожденный минимальным многочленом $m_{A}(t) \in \mathbb{R}[t]$ оператора $A$. Тогда, согласно теореме о гомоморфизмах колец, $\mathbb{R}[A] \cong \cong \mathbb{R}[t] /\left(m_{A}(t)\right)$.
Дадим полный ответ в частном случае $n=2$, когда возможны варианты: $\mathbb{R}[A] \cong \mathbb{C}, \mathbb{R}^{2}, \mathbb{R}[\varepsilon]$ (с точностью до изоморфизма, это - все коммутативные ассоциативные двумерные алгебры над $\mathbb{R}$ с единицей), а также $\mathbb{R}$.
Имеет место изоморфизм $\mathbb{R}[A] \cong \mathbb{C} \Leftrightarrow m_{A}(t)$ - неприводимый над $\mathbb{R}$ многочлен второй степени $\Leftrightarrow \chi_{A}(t)$ - неприводимый над $\mathbb{R}$ многочлен второй степени $^{19} \Leftrightarrow(\operatorname{tr} A)^{2}-4 \operatorname{det} A<0$, ср. с задачей 1.11. В случае, когда $m_{A}(t)$ имеет два различных корня в $\mathbb{R}$, факторкольцо $\mathbb{R}[A] \cong \mathbb{R}^{2}$; в случае, когда $m_{A}(t)$ имеет кратный корень, $\mathbb{R}[A] \cong \mathbb{R}[\varepsilon], \varepsilon^{2}=0$, в согласии со сказанным выше. Если $\operatorname{deg}\left(m_{A}(t)\right)=1$, то $\mathbb{R}[A] \cong \mathbb{R}$. Подробности см. в [28], § 5 .

Заметим, что формулу Тейлора можно записать в виде формального тождества
$$
\begin{equation*}
\exp \left(h \frac{d}{d x}\right) f(x)=T_{h}(f(x)) \tag{25}
\end{equation*}
$$

где $T_{h}(f(x)):=f(x+h)$ - оператор сдвига.
Задача 2.5. Проверить формулу (25) для
1) вещественных многочленов степени не выше $n$;
2) функций на $\mathbb{R}$ из линейной оболочки $\langle\sin x, \cos x\rangle$.

Решение. В этой задаче мы будем вычислять экспоненту конечномерного линейного оператора $\varphi$. Она определяется как сумма ряда, получающегося подстановкой матрицы $A$ оператора $\varphi$ в ряд для экспоненты $\exp x= \sum_{k=0}^{\infty} \frac{x^{k}}{k!}$. При этом получается матрица $\exp A$, являющаяся матрицей линейного оператора $\exp \varphi$. Действительно, если мы выберем другой базис, отвечающий матрице перехода $C$, то $\varphi$ будет иметь в нем матрицу $C^{-1} A C$ и из соотношения $\exp \left(C^{-1} A C\right)=C^{-1}(\exp A) C$ (доказанное ниже в Замечании

\footnotetext{
${ }^{19} \mathrm{~B}$ этом случае он совпадает с $m_{A}(t)$.
}
3.75) следует, что $\exp A$ преобразуется как матрица оператора при переходе к новому базису. Обоснование сходимости ряда $\exp A$ для произвольной матрицы $A$ порядка $n$ будет дано в конце $\S 3.7$. (см. также [15], гл. $6, \S 5$, где помимо прочего приводится пример использования матричной экспоненты для решения системы линейных однородных дифференциальных уравнений с постоянными коэффициентами).
1) Пусть $\mathbb{R}[x]_{n}$ обозначает пространство вещественных многочленов степени не выше $n$. Рассмотрим базис в $\mathbb{R}[x]_{n}$, состоящий из мономов $\left\{1, \frac{x}{1!}, \frac{x^{2}}{2!}, \ldots, \frac{x^{n}}{n!}\right\}$. В этом базисе матрица $D$ оператора дифференцирования $\frac{d}{d x}$ есть следующая матрица порядка $n+1$ :
$$
D:=\left(\begin{array}{lllllll}
0 & 1 & 0 & 0 & \ldots & 0 & 0 \\
0 & 0 & 1 & 0 & \ldots & 0 & 0 \\
0 & 0 & 0 & 1 & \ldots & 0 & 0 \\
\ldots & \ldots & \ldots & \ldots & \ldots & \ldots & \ldots \\
0 & 0 & 0 & 0 & \ldots & 0 & 1 \\
0 & 0 & 0 & 0 & \ldots & 0 & 0
\end{array}\right)
$$
(такая матрица называется жордановой клеткой порядка $n+1$ с собственным значением 0 и обозначается $J_{n+1}(0)$ ). В силу соотношения $D^{n+1}=0$, сумма ряда $\exp (h D)$ есть конечная сумма
$$
E+\sum_{k=1}^{n} D^{k} \frac{h^{k}}{k!}=\left(\begin{array}{ccccccc}
1 & h & \frac{h^{2}}{2!} & \frac{h^{3}}{3!} & \ldots & \frac{h^{n-1}}{(n-1)!} & \frac{h^{n}}{n!} \\
0 & 1 & h & \frac{h^{2}}{2!} & \ldots & \frac{h^{n-2}}{(n-2)!} & \frac{h^{n-1}}{(n-1)!} \\
0 & 0 & 1 & h & \ldots & \frac{h^{n-3}}{(n-3)!} & \frac{h^{n-2}}{(n-2)!} \\
\ldots & \ldots & \ldots & \ldots & \ldots & \ldots & \ldots
\end{array}\right)
$$
(для вычисления также можно использовать (24)).
С другой стороны, формула
$$
T_{h}\left(\frac{x^{k}}{k!}\right)=\frac{(x+h)^{k}}{k!}=\frac{h^{k}}{k!}+\frac{h^{k-1}}{(k-1)!} \cdot \frac{x}{1!}+\frac{h^{k-2}}{(k-2)!} \cdot \frac{x^{2}}{2!}+\ldots+\frac{x^{k}}{k!}
$$

показывает, что линейный оператор $T_{h}: \mathbb{R}[x]_{n} \rightarrow \mathbb{R}[x]_{n}$ имеет ту же самую матрицу в базисе $\left\{1, \frac{x}{1!}, \frac{x^{2}}{2!}, \ldots, \frac{x^{n}}{n!}\right\}$, что и $\exp \left(h \frac{d}{d x}\right)$. Значит, эти два оператора на пространстве $\mathbb{R}[x]_{n}$ равны.
2) Оператор $\frac{d}{d x}$ в базисе $\{\sin x, \cos x\}$ имеет матрицу $D:=:=\left(\begin{array}{cc}0 & -1 \\ 1 & 0\end{array}\right)$.

Для вычисления $\exp (h D)$ можно либо воспользоваться задачей 1.11, либо просуммировать ряд из матриц, используя соотношение $D^{2}=-E$ и разложения в ряды Маклорена для функций $\sin h, \cos h$. В любом случае получается ответ: $\exp (h D)=\left(\begin{array}{cc}\cos h & -\sin h \\ \sin h & \cos h\end{array}\right)$.
С другой стороны, используя тригонометрические тождества $\sin (x+h)= \cos h \sin x+\sin h \cos x, \cos (x+h)=-\sin h \sin x++\cos h \cos x$ (напомним, что $\sin x, \cos x$ - базисные векторы, а $\sin h$ и $\cos h$ - координаты разложения по

базису), получаем, что матрица $T_{h}$ в том же базисе та же самая.

Комментарий. Решенная задача подсказывает быстрый способ нахождения экспоненты $\exp \left(h J_{n}(\lambda)\right)$, где $J_{n}(\lambda)$ - жорданова клетка порядка $n$ с собственным значением $\lambda$. Дело в том, что оператор дифференцирования на пространстве квазимногочленов степени, не превосходящей $n-1$, в базиce
$$
\left\{e^{\lambda x}, \frac{x}{1!} e^{\lambda x}, \frac{x^{2}}{2!} e^{\lambda x}, \ldots, \frac{x^{n-1}}{(n-1)!} e^{\lambda x}\right\}
$$

как раз имеет матрицу $J_{n}(\lambda)$. Таким образом, по формуле Тейлора $\exp \left(h J_{n}(\lambda)\right)= T_{h}$, где $T_{h}$ - матрица оператора $f(x) \mapsto f(x+h)$ сдвига на $h$ в том же базисе.

Определение 2.6. Говорят, что две матрицы $A, B: V \rightarrow V$ коммутируют, если $A B=B A$. Другими словами, их коммутатор $[A, B]=A B-B A$ равен 0.

Задача 2.7. Найти все матрицы в $\operatorname{Mat}_{n}(\mathbb{K})$, коммутирующие с жордановой клеткой $J_{n}(\lambda)$.

Решение. Во-первых, заметим, что $\forall B \in \operatorname{Mat}_{n}(\mathbb{K})$ множество
$$
N(B):=\left\{A \in \operatorname{Mat}_{n}(\mathbb{K}) \mid[A, B]=0\right\}
$$

является векторным пространством ${ }^{20}$. Во-вторых, так как $J_{n}(\lambda)=\lambda E+ J_{n}(0)$, а скалярные матрицы коммутируют со всеми матрицами, то достаточно найти пространство матриц, коммутирующих с $J_{n}:=J_{n}(0)$. Ясно, что алгебра $\mathbb{K}\left[J_{n}\right]$ матриц вида (ср. 24):
$$
f\left(J_{n}\right)=\left(\begin{array}{ccccc}
\alpha_{0} & \alpha_{1} & \alpha_{2} & \ldots & \alpha_{n-1}  \tag{26}\\
0 & \alpha_{0} & \alpha_{1} & \ldots & \alpha_{n-2} \\
0 & 0 & \alpha_{0} & \ldots & \alpha_{n-3} \\
\ldots & \ldots & \ldots & \ldots & \ldots \\
0 & 0 & 0 & \ldots & \alpha_{0}
\end{array}\right),
$$

где $f(t)=\alpha_{0}+\alpha_{1} t+\ldots+\alpha_{n-1} t^{n-1} \in \mathbb{K}[t]$, является коммутативной подалгеброй в $\operatorname{Mat}_{n}(\mathbb{K})$ размерности $n$ (поскольку $\left(J_{n}\right)^{n}=0$ ), то есть $\mathbb{K}\left[J_{n}\right] \subset N\left(J_{n}\right)$. Покажем, что в действительности $\mathbb{K}\left[J_{n}\right]=N\left(J_{n}\right)$. Матрица $J_{n}$ является матрицей оператора $\varphi$, действующего в выбранном базисе $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ по формуле $\varphi\left(\mathbf{e}_{k}\right)=\mathbf{e}_{k-1}, 2 \leq k \leq n, \varphi\left(\mathbf{e}_{1}\right)==\mathbf{0}$. Пусть $A \in N\left(J_{n}\right)$. Пусть
$$
A \mathbf{e}_{n}=\alpha_{n-1} \mathbf{e}_{1}+\alpha_{n-2} \mathbf{e}_{2}+\ldots+\alpha_{0} \mathbf{e}_{n}
$$

где $\alpha_{k}$ - некоторые скаляры. Тогда
$$
\begin{gathered}
A \mathbf{e}_{n-1}=A J_{n} \mathbf{e}_{n}=J_{n} A \mathbf{e}_{n}=\alpha_{n-2} \mathbf{e}_{1}+\alpha_{n-3} \mathbf{e}_{2}+\ldots+\alpha_{0} \mathbf{e}_{n-1} \\
A \mathbf{e}_{n-2}=A J_{n} \mathbf{e}_{n-1}=J_{n} A \mathbf{e}_{n-1}=\alpha_{n-3} \mathbf{e}_{1}+\alpha_{n-4} \mathbf{e}_{2}+\ldots+\alpha_{0} \mathbf{e}_{n-2}
\end{gathered}
$$

\footnotetext{
${ }^{20}$ Даже подалгеброй с единицей в $\operatorname{Mat}_{n}(\mathbb{K})$, поскольку $[A C, B]=A[C, B]+ +[A, B] C$.
}

и так далее. Таким образом, оператор $A$ в данном базисе имеет матрицу (26). \(\square\)

Векторное пространство квадратных матриц $\operatorname{Mat}_{n}(\mathbb{R})$ можно отождествить с арифметическим пространством $\mathbb{R}^{n^{2}}$, например, выбрав в $\operatorname{Mat}_{n}(\mathbb{R})$ базис из матричных единиц $E_{i j}$. При этом отождествлении матрице $A=\left(a_{i j}\right)$ сопоставляется набор ее координат - матричных элементов $\left(a_{i j}\right)$ (упорядоченных в соответствии с выбранным порядком в базисе из матричных единиц). Пространство $\mathbb{R}^{n^{2}}$ можно рассматривать как метрическое пространство относительно стандартной метрики, в которой квадрат длины $|\mathbf{a}|^{2}$ вектора $\mathbf{a}=\left(a_{k}\right)$ выражается формулой $|\mathbf{a}|^{2}==\sum_{k=1}^{n^{2}} a_{k}^{2}$ (в терминах матрицы $A$ это равно $|A|^{2}:=\operatorname{tr}\left(A^{T} A\right)^{21}$ ).
Таким образом, $\operatorname{Mat}_{n}(\mathbb{R})$ - метрическое пространство. Напомним, что подмножество $M \subset X$ метрического пространства $X$ называется плотным [31], если для любой точки $x \in X$ любая ее окрестность $U_{x}$ имеет непустое пересечение с $M$. Равносильное определение: подмножество $M$ плотно в $X$, если всякая точка $x \in X$ является точкой прикосновения $M$, или, что эквивалентно, замыкание $M$ совпадает с $X$.

Задача 2.8. Доказать, что множество обратимых матриц порядка $n$ плотно в $\operatorname{Mat}_{n}(\mathbb{R})$.

Решение. Пусть $A \in \operatorname{Mat}_{n}(\mathbb{R})$ - произвольная матрица. Рассмотрим ее характеристический многочлен $\chi_{A}(t)=\operatorname{det}(t E-A)$. Многочлен $\chi_{A}(t)$ ненулевой, поскольку у него коэффициент при $t^{n}$ равен 1 . Ненулевой многочлен степени $n$ имеет не более $n$ корней, поэтому существует проколотая окрестность точки $t=0$ на прямой, в которой нет корней $\chi_{A}(t)$. Для любого $t$, не принадлежащего множеству корней $\chi_{A}(t)$, матрица $A-t E$ обратима. Таким образом, любая окрестность матрицы $A$ в $\operatorname{Mat}_{n}(\mathbb{R})=\mathbb{R}^{n^{2}}$ содержит обратимую матрицу. \(\square\)

Комментарии. 1) Во-первых, заметим, что в предшествующих рассуждениях поле $\mathbb{R}$ может быть заменено полем $\mathbb{C}$.
2) Множество необратимых матриц порядка $n$ совпадает с множеством нулей
$$
\left\{A \in \operatorname{Mat}_{n}(\mathbb{R}) \mid \operatorname{det} A=0\right\}
$$

многочлена $\operatorname{det} A$ от $n^{2}$ переменных - элементов матрицы $A$. В частности, оно замкнуто (поскольку многочлен - непрерывная функция), а дополнение к нему - множество обратимых матриц - открыто.
3) Полученный в задаче результат позволяет распространять "по непрерывности" тождества, известные для обратимых матриц, на все матрицы (в случае полей $\mathbb{R}$ или $\mathbb{C}$ ). Докажем, например, равенство $\chi_{A B}(t)=\chi_{B A}(t)$ для

\footnotetext{
${ }^{21}$ Мы предостерегаем читателя от путаницы: здесь и ниже $|A|$ обозначает не определитель, а евклидову длину матрицы $A$ как вектора пространства $\operatorname{Mat}_{n}(\mathbb{R})$ со скалярным произведением $(A, B)=\operatorname{tr}\left(A^{T} B\right)$, см. задачу 3.6.
}

любых $A, B \in \operatorname{Mat}_{n}(\mathbb{R})$. Если матрица $A$ обратима, то матрицы $A B$ и $B A$ сопряжены: $B A=A^{-1}(A B) A$, и требуемое равенство следует из инвариантности характеристического многочлена оператора относительно замен базиса. Рассмотрим теперь многочлен $f_{A B}(t):=\chi_{A B}(t)-\chi_{B A}(t)$. Коэффициенты $f_{A B}(t)$, являясь непрерывными функциями (многочленами) матричных элементов $A$ (при фиксированной матрице $B$ ), обращаются в 0 на плотном подмножестве в $\operatorname{Mat}_{n}(\mathbb{R})$, состоящем из обратимых матриц. Значит, они равны нулю всюду ${ }^{22}$. Другой пример использования этого метода - распространение полярного разложения на вырожденные матрицы при условии, что оно доказано для невырожденных (см. задачу 3.45).

Задача 2.9. Доказать, что множество диагонализируемых матриц плотно в $\operatorname{Mat}_{n}(\mathbb{C})$.

Решение. Заметим, что произвольную матрицу $A \in \operatorname{Mat}_{n}(\mathbb{C})$ можно привести к верхнему треугольному виду (см. задачу 2.34 , а также [10], гл. VI, § 4), то есть существует такая обратимая матрица $C \in \operatorname{Mat}_{n}(\mathbb{C})$, что $C^{-1} A C=T$, где матрица $T$ - верхняя треугольная. На главной диагонали $T$ стоит набор $\left\{\lambda_{1}, \ldots, \lambda_{n}\right\}$ собственных значений матрицы $T$ (и $A$ ). Если они попарно различны, то матрица $A$ диагонализируема. Если среди них есть совпадающие, то их можно сколь угодно мало изменить, чтобы сделать попарно различными. Пусть при этом мы получили диагонализируемую матрицу $T^{\prime}$ с попарно различными собственными значениями $\lambda_{1}^{\prime}, \ldots, \lambda_{n}^{\prime}$, то же можно сказать и про матрицу $A^{\prime}:=C T^{\prime} C^{-1}$. Выбирая $T^{\prime}$ сколь угодно мало отличающейся от $T$, можно сделать $A^{\prime}$ сколь угодно мало отличающейся от $A=C T C^{-1}$, поскольку матричные элементы $A^{\prime}$ являются линейными функциями от матричных элементов $T^{\prime}$, а значит, непрерывны.
Комментарий. Достаточным условием диагонализируемости матрицы $A$ над $\mathbb{C}$ является отсутствие кратных корней у ее характеристического многочлена $\chi_{A}(t)$. Подмножество матриц в $\operatorname{Mat}_{n}(\mathbb{C})$ без кратных корней задается условием, что дискриминант $\Delta\left(\chi_{A}(t)\right) \neq 0$. Заметим, что $\Delta\left(\chi_{A}(t)\right)$ - ненулевой многочлен от матричных элементов $A$ (которые мы считаем независимыми переменными), его множество нулей - собственное замкнутое подмножество в $\operatorname{Mat}_{n}(\mathbb{C})$.
Доказанный в задаче результат позволяет распространять "по непрерывности" тождества, известные для диагонализируемых матриц, на все матрицы данного порядка над $\mathbb{C}$. Пример такого доказательства дает следующая задача.

Напомним, что теорема Гамильтона-Кэли утверждает, что характеристический многочлен $\chi_{\varphi}(t)$ аннулирует оператор, то есть $\chi_{\varphi}(\varphi)=0$.

Задача 2.10. Используя результат предыдущей задачи, доказать теорему Гамильтона-Кэли для полей $\mathbb{R}$ и $\mathbb{C}$.
${ }^{22}$ Здесь мы используем следующий результат из анализа: непрерывная функция $f: \mathbb{R}^{m} \rightarrow \mathbb{R}$, равная нулю на плотном подмножестве $U \subset \mathbb{R}^{m}$, равна нулю на всем $\mathbb{R}^{m}$.

Решение. Рассмотрим вначале случай алгебраически замкнутого поля $\mathbb{C}$. Пусть в некотором базисе оператор $\varphi$ имеет матрицу $A$. Для диагонализируемых операторов теорема почти очевидна. Действительно, если $A=C \Lambda C^{-1}$, где $\Lambda:=\operatorname{diag}\left(\lambda_{1}, \ldots, \lambda_{n}\right)$, то
$$
\begin{aligned}
& \chi_{A}(t)=\prod_{i}\left(t-\lambda_{i}\right) \Rightarrow \chi_{A}(A)=\chi_{A}\left(C \Lambda C^{-1}\right)= \\
& =C \chi_{A}(\Lambda) C^{-1}=C\left(\prod_{i}\left(\Lambda-\lambda_{i} E\right)\right) C^{-1}=0
\end{aligned}
$$

Для доказательства в общем случае осталось лишь заметить, что $A \mapsto \chi_{A}(A)$ - непрерывная функция $\operatorname{Mat}_{n}(\mathbb{C}) \rightarrow \operatorname{Mat}_{n}(\mathbb{C})$, равная 0 на плотном подмножестве, состоящем из диагонализируемых матриц, следовательно, она тождественно равна нулю на всем множестве $\operatorname{Mat}_{n}(\mathbb{C})$.
Осталось доказать теорему для случая поля $\mathbb{R}$. Пусть $A \in \in \operatorname{Mat}_{n}(\mathbb{R})$ - матрица оператора, действующего на вещественном векторном пространстве. Матрицу $A$ можно рассматривать и как матрицу из $\operatorname{Mat}_{n}(\mathbb{C})$, и тогда по доказанному получаем $\chi_{A}(A)=0$. При этом понятно, что характеристический многочлен $\chi_{A}(t)$ не зависит от того, рассматриваем ли мы матрицу $A$ как матрицу с вещественными или комплексными элементами. \(\square\)

Напомним определение порядка элемента $g$ группы $G$. Если существует такое натуральное число $N \geq 1$, что $g^{N}=e$, то порядком $g$ называется наименьшее из таких натуральных чисел (из алгоритма Евклида легко следует, что порядок $g$ является делителем любого натурального $N$ такого, что $g^{N}=e$ ). В противном случае порядок $g$ полагается равным бесконечности.

Задача 2.11. Найдите порядок элемента
$$
A=\left(\begin{array}{ccccc}
\lambda_{1} & * & * & \cdots & * \\
0 & \lambda_{2} & * & \cdots & * \\
0 & 0 & \lambda_{3} & \cdots & * \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \ldots & \lambda_{n}
\end{array}\right) \in \mathrm{GL}_{n}(\mathbb{C}),
$$

где $\lambda_{1}, \ldots, \lambda_{n}$ - различные комплексные корни $n$-й степени из 1 .
Решение. Так как матрица $A$ верхняя треугольная с элементами $\lambda_{1}, \ldots, \lambda_{n}$ на главной диагонали, то ее собственные значения - в точности все корни $\lambda_{1}, \ldots, \lambda_{n} n$-й степени из 1 . Поэтому характеристический многочлен $\chi_{A}(t)$ матрицы $A$ равен $t^{n}-1$. По теореме Гамильтона-Кэли $A^{n}=E$, поэтому порядок $A \in \mathrm{GL}_{n}(\mathbb{C})$ делит $n$. С другой стороны, он не может быть меньше $n$, поскольку при возведении верхней треугольной матрицы в степень $k$ ее диагональные элементы возводятся в степень $k$, а так как группа корней степени $n$ из 1 является циклической, в ней есть элемент, порядок которого совпадает с порядком (= числом элементов) этой группы, то есть $n$.
Без использования теоремы Гамильтона-Кэли можно рассуждать так. Из условия следует, что все собственные значения оператора попарно различны

и являются всеми корнями $n$-й степени из 1 . Из первого вытекает диагонализируемость оператора, а из второго - что его порядок равен $n$.

Задача 2.12. Пусть $V$ - векторное пространство над полем $\mathbb{K}, \varphi: V \rightarrow V-$ линейный оператор, $\chi_{\varphi}(t)=\prod_{i=1}^{k}\left(t-\lambda_{i}\right)^{r_{i}}, r_{i} \geq \geq 1$ - его характеристический многочлен, причем $\lambda_{i} \neq \lambda_{j}$ при $i \neq j$. Доказать, что $\varphi$ диагонализируем $\Leftrightarrow \lambda_{i} \in \mathbb{K}, 1 \leq i \leq k$ и многочлен $m_{\varphi}(t):=\prod_{i=1}^{k}\left(t-\lambda_{i}\right)$ аннулирует $\varphi$ (на самом деле он совпадает с минимальным многочленом $\varphi$ ).

Решение. Пусть $\varphi$ диагонализируем. Тогда в $V$ существует базис, состоящий из собственных векторов оператора $\varphi$. Так как сумма собственных подпространств, отвечающих разным собственным значениям, является прямой (см. [10], VI, § 4), то
$$
\begin{equation*}
V=V_{\lambda_{1}} \oplus \ldots \oplus V_{\lambda_{l}}, \quad l \leq k \tag{27}
\end{equation*}
$$

где $V_{\lambda_{i}}$ - собственное подпространство, отвечающее собственному значению $\lambda_{i}$. Поскольку размерность собственного подпространства $V_{\lambda_{i}}$ не превосходит кратности $r_{i}$ корня $\lambda_{i}$ характеристического многочлена (см. [10], VI, § 4), (27) возможно, только если $\operatorname{dim} V_{\lambda_{i}}=r_{i}$ и $l=k$. Значит, все $\lambda_{i} \in \mathbb{K}$. С другой стороны, легко видеть, что ограничение $\varphi-\lambda_{i} \mathrm{id}$ на $V_{\lambda_{i}}-$ нулевой оператор. Тогда $\prod_{i=1}^{k}\left(\varphi-\lambda_{i} \mathrm{id}\right)$ - нулевой оператор на $V$. Значит, $m_{\varphi}(t)$ аннулирует $\varphi$.
Обратно, пусть $m_{\varphi}(t)$ аннулирует $\varphi$. Определим многочлены $g_{i}(t):=m_{\varphi}(t)(t- \left.\lambda_{i}\right)^{-1}, 1 \leq i \leq k$. Очевидно, что
$$
L_{i}:=\operatorname{im}\left(g_{i}(\varphi)\right) \subset V_{\lambda_{i}}
$$

Многочлены $g_{1}(t), \ldots, g_{k}(t) \in \mathbb{K}[t]$ взаимно просты в совокупности, поэтому существуют многочлены $h_{i}(t), 1 \leq i \leq k$ такие, что $\sum_{i=1}^{k} g_{i}(t) h_{i}(t)=1$. Тогда $\sum_{i=1}^{k} g_{i}(\varphi) h_{i}(\varphi)=\mathrm{id}_{V}$, а следовательно, $V=L_{1}+\ldots+L_{k}$. Так как $L_{i} \subset V_{\lambda_{i}}$ и $V_{\lambda_{i}} \cap\left(\oplus_{j \neq i} V_{\lambda_{j}}\right)=\{\mathbf{0}\}$, то $V=V_{\lambda_{1}} \oplus \ldots \oplus V_{\lambda_{k}}$ (и $L_{i}=V_{\lambda_{i}}$ ).

Определение 2.13. Линейный оператор $\varphi: V \rightarrow V$ называется нильпотентным, если существует такое натуральное $k$, что $\varphi^{k}=0$. Наименьшее $k$ с указанным свойством называется высотой оператора или порядком нильпотентности.

Например, жорданова клетка $J_{n}(0)$ нильпотентна: $J_{n}(0)^{n}=0$. Следующая задача является важным этапом при доказательстве теоремы о жордановой нормальной форме (ЖНФ).

Задача 2.14. Пусть $N$ - нильпотентный оператор высоты $n$ и е - такой вектор, что $N^{n-1} \mathbf{e} \neq \mathbf{0}$. Доказать, что система векторов $\left\{\mathbf{e}, N \mathbf{e}, N^{2} \mathbf{e}, \ldots, N^{n-1} \mathbf{e}\right\}$ линейно независима.

Решение. Предположим обратное: существуют такие не равные одновременно нулю константы $\alpha_{0}, \ldots, \alpha_{n-1}$, что
$$
\sum_{j=0}^{n-1} \alpha_{j} N^{j} \mathbf{e}=\mathbf{0}
$$

Пусть $k$ - номер первого ненулевого коэффициента $\alpha_{k} \neq 0$. В таком случае после применения к левой и правой частям последней формулы оператора $N^{n-k-1}$ получим
$$
\alpha_{k} N^{n-1} \mathbf{e}+\alpha_{k+1} N^{n} \mathbf{e}+\cdots=\mathbf{0} .
$$

Все слагаемые, кроме первого, по определению нильпотентного оператора нулевые. Значит, в силу выбора вектора е получаем, что $\alpha_{k}=0$. Следовательно, все коэффициенты $\alpha_{j}$ равны нулю. Значит, наша система линейно независима. \(\square\)

Комментарий. Отметим, что полученная система линейно независима, но совсем не обязана быть базисом. Проверьте, что примером такого оператора является оператор, ЖНФ которого состоит из нескольких жордановых клеток с нулевым собственным значением.

Задача 2.15. Рассмотрим нильпотентный оператор $N: V \rightarrow \rightarrow V$. Доказать, что порядок нильпотентности оператора $N$ не может превышать $\operatorname{dim} V$.

Решение. Предположим обратное. Значит, существует такой вектор $\mathbf{e} \in V$, что $N^{n} \mathbf{e} \neq \mathbf{0}$, причем $n>\operatorname{dim} V$. Как было показано в задаче 2.14 , система векторов $\left\{\mathbf{e}, N \mathbf{e}, \ldots, N^{n} \mathbf{e}\right\}$ линейно независима, чего не может быть, так как $n>\operatorname{dim} V$. \(\square\)

Отсюда, например, следует, что не существует решений уравнения $x^{3}=0$, которые не были бы решениями уравнения $x^{2}=0$ среди квадратных матриц $\operatorname{Mat}_{2}(\mathbb{K})$.

Задача 2.16. Пусть $V$ - конечномерное векторное пространство над полем $\mathbb{K}, \varphi: V \rightarrow V$ - линейный оператор на $V$. Предположим, что все корни характеристического многочлена ${ }^{23} \varphi$ равны 0 (в случае алгебраически замкнутого основного поля $\mathbb{K}$ это эквивалентно равенству нулю всех собственных значений $\varphi$ ). Доказать, что тогда $\varphi$ нильпотентен.

Решение. Характеристический многочлен $\varphi$ имеет только нулевой корень, значит, $\chi_{\varphi}(t)=t^{n}$, где $n=\operatorname{dim} V$. По теореме Гамильтона-Кэли, $\varphi^{n}=0$. Кстати, заметим, что для наименьшего $k$ такого, что $\varphi^{k}=0$, мы еще раз получили оценку $k \leq \leq \operatorname{dim} V$, причем все случаи $1 \leq k \leq n$ реализуются (взять в левом верхнем углу жорданову клетку $J_{k}(0)$ и дополнить нулями, если $k<n$ ). \(\square\)

Комментарий. Заметим, что если линейный оператор $\varphi$ на векторном пространстве $V$ нильпотентен, то все его собственные значения равны 0 . Действительно, предположим, что у нильпотентного оператора $\varphi$ степени нильпотентности $n$ есть собственное значение $\lambda$. Тогда существует $\mathbf{v} \in V, \mathbf{v} \neq \mathbf{0}$ такой, что $\varphi(\mathbf{v})=\lambda \mathbf{v} \quad \Rightarrow \quad \mathbf{0}=\varphi^{n}(\mathbf{v})=\lambda^{n} \mathbf{v} \quad \Rightarrow \quad \lambda^{n}=0 \quad \Rightarrow \quad \lambda=0$. Кроме того, 0 является собственным значением $\varphi$. Действительно, $\varphi^{n-1} \neq 0$, значит, существует $\mathbf{u} \in V$ такой, что $\varphi^{n-1}(\mathbf{u}) \neq \mathbf{0}$, но $\varphi^{n}(\mathbf{u})=\mathbf{0}$. Полагая $\mathbf{w}:=\varphi^{n-1}(\mathbf{u})$, имеем $\mathbf{w} \neq \mathbf{0}$, но $\varphi(\mathbf{w})=\mathbf{0} \Rightarrow 0$ является собственным значением $\varphi$.

\footnotetext{
${ }^{23} \mathrm{~B}$ алгебраическом замыкании $\mathbb{K}$.
}

Более того, верно утверждение, обратное доказанному в предшествующей задаче: все корни характеристического многочлена нильпотентного оператора $\varphi$ равны 0 . Для алгебраически замкнутого основного поля $\mathbb{K}$ это следует из предыдущего: в этом случае все корни характеристического многочлена являются собственными значениями. Если $\mathbb{K}=\mathbb{R}$, то для доказательства можно использовать комплексификацию $V$ (см. ниже), а в общем случае расширение поля скаляров (см. [35]). Доказательство в случае произвольного поля $\mathbb{K}$ можно также получить, используя задачу 2.35 .
Задача 2.17. Доказать, что симметричная нильпотентная матрица $A$ с вещественными элементами нулевая.
Решение. Вещественная симметричная матрица $A$ обязательно диагонализируема, то есть существует невырожденная матрица $C$ такая, что матрица $\Lambda=C^{-1} A C$ диагональна, причем на ее главной диагонали стоят собственные значения матрицы $A$, которые, согласно вышесказанному, равны нулю.
Комментарий. Заметим, что для матриц с комплексными элементами утверждение задачи неверно. Контрпример дает, например, матрица $\left(\begin{array}{cc}1 & i \\ i & -1\end{array}\right)$, подобная над $\mathbb{C}$ матрице $\left(\begin{array}{ll}0 & 1 \\ 0 & 0\end{array}\right)$ (последнее следует из теории жордановой формы). Вообще, можно показать, что любая комплексная матрица подобна симметричной.
"Правильным" комплексным аналогом вещественных симметричных матриц являются эрмитово симметричные матрицы, то есть такие матрицы $A \in \operatorname{Mat}_{n}(\mathbb{C})$, для которых $\bar{A}^{T}=A$, где черта означает комплексное сопряжение (такая матрица с вещественными элементами симметрична). Дело в том, что симметричные и эрмитово симметричные матрицы являются матрицами самосопряженных операторов в ортонормированных базисах в евклидовом и унитарном пространстве соответственно.
Задача 2.18. Доказать, что если квадратные матрицы $A$ и $B$ порядка $n$ над полем $\mathbb{K}$ характеристики 0 удовлетворяют соотношению $A B-B A=B$, то матрица $B$ нильпотентна.
Решение. Докажем индукцией по $k$, что $A B^{k}-B^{k} A=k B^{k} \forall k \in \in \mathbb{N}$. При $k=0$ равенство очевидно, случай $k=1$ следует из условия. Пусть $k>1$. Тогда
$$
\begin{gathered}
A B^{k}-B^{k} A=(B A+B) B^{k-1}-B B^{k-1} A= \\
=B\left(A B^{k-1}-B^{k-1} A\right)+B^{k}=(k-1) B^{k}+B^{k}=k B^{k}
\end{gathered}
$$

Рассмотрим линейный оператор
$$
\Phi_{A}: \operatorname{Mat}_{n}(\mathbb{K}) \rightarrow \operatorname{Mat}_{n}(\mathbb{K}), \quad \Phi_{A}(X):=A X-X A
$$

Если матрица $B$ не нильпотентна, то матрицы $B^{k}, \quad k \in \mathbb{N}$ являются собственными векторами оператора $\Phi_{A}$, отвечающими собственным значениям $k$. Это невозможно, так как собственные векторы, отвечающие различным собственным значениям, линейно независимы, а пространство $\operatorname{Mat}_{n}(\mathbb{K})$ конечномерно.

Задача 2.19. Пусть $f$ - ненулевая линейная функция на векторном пространстве $V$ (не обязательно конечномерном) над (произвольным) полем $\mathbb{K}$, $U=\operatorname{ker}(f)$. Доказать, что
а) $U$ - максимальное подпространство $V$, т.е. оно не содержится ни в каком другом подпространстве в $V$, отличном от $V$;
b) $V=U \oplus\langle\mathbf{v}\rangle$ для любого $\mathbf{v} \notin U$;
c) если $g$ - еще одна линейная функция на $V$ и $\operatorname{ker} g=\operatorname{ker} f$, то существует такой $\alpha \in \mathbb{K}, \alpha \neq 0$, что $g=\alpha f$.

Решение. Напомним, что $\operatorname{ker} f:=\{\mathbf{v} \in V \mid f(\mathbf{v})=0\}$ - ядро линейной функции $f$.
Пусть дано подпространство $W \subset V$ такое, что $U \nsubseteq W \subset V$; нужно доказать, что $W=V$. Выберем $\mathbf{w} \in W, \mathbf{w} \notin U \Rightarrow f(\mathbf{w}) \neq \neq \mathbf{0}$. Возьмем произвольный $\mathbf{v} \in V \Rightarrow \mathbf{v}-\frac{f(\mathbf{v})}{f(\mathbf{w})} \mathbf{w} \in U \Rightarrow \mathbf{v} \in C W \Rightarrow W=V$. Тем самым пункт а) доказан.
$f \neq 0 \Rightarrow \exists \mathbf{v} \in V$ такой, что $f(\mathbf{v}) \neq 0$. Выберем произвольный $\mathbf{v}^{\prime} \in V \Rightarrow \mathbf{v}^{\prime}-\frac{f\left(\mathbf{v}^{\prime}\right)}{f(\mathbf{v})} \mathbf{v} \in U \Rightarrow V=U \oplus\langle\mathbf{v}\rangle$. Тем самым пункт b) доказан.
Выберем $\mathbf{v} \in V, \mathbf{v} \notin \operatorname{ker} f=\operatorname{ker} g \Rightarrow \exists \alpha \in \mathbb{K}, \alpha \neq 0$, такой, что $g(\mathbf{v})=\alpha f(\mathbf{v})$. Рассмотрим линейную функцию $h:=g-\alpha f$. Имеем $h(\mathbf{v})=0,\left.h\right|_{U}=0$; но, в силу пункта b), $V=U \oplus\langle\mathbf{v}\rangle \Rightarrow \Rightarrow h=0$. Тем самым пункт с) доказан.
Комментарий. Полезность данной задачи заключается в демонстрации того, как можно работать с линейными пространствами без условия конечномерности и использования базисов.

Задача 2.20. Пусть $V$ - линейное пространство размерности $n$, а $\varphi: V \rightarrow V$ - линейный оператор. Доказать, что все $n-1$-мерные $\varphi$-инвариантные подпространства в $V$ имеют вид $\operatorname{ker} f$ для некоторого собственного вектора $f$ оператора $\varphi^{*}$. Обратно, доказать, что любое подпространство вида $\operatorname{ker} f$, где $f$ - некоторый собственный вектор оператора $\varphi^{*}$, инвариантно относительно $\varphi$.

Решение. Напомним, что для линейного пространства $V$ над полем $\mathbb{K}$ через $V^{*}$ обозначается двойственное пространство
$$
V^{*}:=\{f: V \rightarrow \mathbb{K} \mid f \text { линейно над } \mathbb{K}\},
$$

то есть пространство всех линейных функционалов на $V$. Если $V$ конечномерно, то $V^{*}$ тоже конечномерно, причем имеет ту же размерность, что и $V$. Для каждого линейного отображения $\varphi: V \rightarrow W$ имеем линейное отображение $\varphi^{*}: W^{*} \rightarrow V^{*}$, которое произвольный линейный функционал $f \in W^{*}$ переводит в линейный функционал $\varphi^{*}(f) \in V^{*}$, однозначно определяемый условием, что на произвольном векторе $\mathbf{v} \in V$ он принимает значение $f(\varphi(\mathbf{v}))$, то есть определяемое формулой $\varphi^{*}(f)(\mathbf{v})==f(\varphi(\mathbf{v})) \forall \mathbf{v} \in V, f \in W^{* 24}$. В частности, для линейного оператора $\varphi: V \rightarrow V$ имеем линейный оператор $\varphi^{*}: V^{*} \rightarrow V^{*}$.
${ }^{24}$ Нетрудно показать, что * определяет контравариантный функтор из категории линейных пространств над полем $\mathbb{K}$ в себя, см. [35], гл. $1, § 13$.

Пусть $U \subset V$ - $\varphi$-инвариантное подпространство в $V, \operatorname{dim} U=n-1$. Тогда $\exists f \in V^{*}$ такой, что $U=\operatorname{ker} f:=\{\mathbf{v} \in V \mid f(\mathbf{v})=0\}$ (очевидно, что $f \neq 0$ ). Из предыдущей задачи следует, что такой $f$ определен однозначно с точностью до умножения на ненулевой скаляр $\alpha \in \mathbb{K}$. Кроме того, если для некоторого $g \in V^{*}$ из $\mathbf{u} \in U$ следует $g(\mathbf{u})=0$, то $g=\lambda f, \lambda \in \mathbb{K}$. Последнее как раз верно для $g=\varphi^{*}(f)$ :
$$
\forall \mathbf{u} \in U \quad \varphi^{*}(f)(\mathbf{u})=f(\varphi(\mathbf{u}))=0
$$

следовательно, $\varphi^{*}(f)=\lambda f$, то есть $f \in V^{*}$ - собственный вектор оператора $\varphi^{*}$.
Обратно, пусть $\varphi^{*}(f)=\lambda f$. Тогда из $\mathbf{u} \in U$ следует $\varphi^{*}(f)(\mathbf{u})==\lambda f(\mathbf{u})=0$, значит, $f(\varphi(\mathbf{u}))=0 \forall \mathbf{u} \in U \Rightarrow \varphi(\mathbf{u}) \in U$, поскольку $U=\operatorname{ker} f$.

Пусть $\varphi: V \rightarrow V$ - линейный оператор, $U \subset V$ - инвариантное относительно $\varphi$ подпространство, то есть $\varphi(U) \subset U$. Тогда определено ограничение $\left.\varphi\right|_{U}$ оператора $\varphi$ на подпространство $U$, которое является оператором на пространстве $U$, задаваемым формулой
$$
\left.\varphi\right|_{U}(\mathbf{u})=\varphi(\mathbf{u}) \quad \forall \mathbf{u} \in U .
$$

Для краткости обозначим $\psi:=\left.\varphi\right|_{U}$. Выберем базис $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{k}\right\}$ в $U \subset V$ и дополним его до базиса $\left\{\mathbf{e}_{1}, \ldots \mathbf{e}_{n}\right\}$ всего $V$, в нем оператор $\varphi$ имеет матрицу $\left(\begin{array}{cc}A & B \\ 0 & C\end{array}\right)$, где $A$ - матрица $\psi$ в базисе $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{k}\right\}^{25}$. Из этого легко видеть, что характеристический многочлен $\chi_{\psi}(t)$ ограничения $\psi=\left.\varphi\right|_{U}$ делит характеристический многочлен $\chi_{\varphi}(t)$ оператора $\varphi$.

Задача 2.21. Пусть $\varphi$ - линейный оператор на $V,\left\{\lambda_{1}, \ldots, \lambda_{k}\right\}$ - набор его различных собственных значений, принадлежащих основному полю, $V_{\lambda_{j}} \subset V$ - соответствующие собственные подпространства. Пусть $U \subset V-\varphi$ инвариантное подпространство. Доказать, что если для $\mathbf{u} \in U$ существует представление
$$
\begin{equation*}
\mathbf{u}=\mathbf{v}_{1}+\ldots+\mathbf{v}_{k}, \tag{28}
\end{equation*}
$$

где $\mathbf{v}_{j} \in V_{\lambda_{j}}$, то $\mathbf{v}_{j} \in U \quad \forall j, 1 \leq j \leq k$.
Решение. Воспользуемся индукцией по числу $l$ ненулевых слагаемых в разложении (28). Для $l=1$ утверждение очевидно. Допустим, что требуемое утверждение верно для разложений вида (28) с числом ненулевых компонент $\mathbf{v}_{j}$, не превосходящим $l-1$, докажем, что тогда утверждение верно для разложений с $l$ ненулевыми компонентами. Без ограничения общности можно считать, что ненулевыми являются первые $l$ компонент в (28). Пусть
$$
\begin{equation*}
U \ni \mathbf{u}=\mathbf{v}_{1}+\ldots+\mathbf{v}_{l} \tag{29}
\end{equation*}
$$

где все $\mathbf{v}_{j} \neq \mathbf{0}$. Тогда $\varphi(\mathbf{u})=\lambda_{1} \mathbf{v}_{1}+\ldots+\lambda_{l} \mathbf{v}_{l}$. Вычитая из последнего тождества равенство, полученное умножением обеих частей (29) на $\lambda_{l}$, имеем
$$
\varphi(\mathbf{u})-\lambda_{l} \mathbf{u}=\left(\lambda_{1}-\lambda_{l}\right) \mathbf{v}_{1}+\ldots+\left(\lambda_{l-1}-\lambda_{l}\right) \mathbf{v}_{l-1} .
$$
${ }^{25}$ Блок $C$ также имеет интерпретацию - это матрица фактороператора, он определен перед задачей 2.33 .

Мы получили разложение вида (28), содержащее $l-1$ ненулевую компоненту, следовательно, по предположению индукции, $\mathbf{v}_{j} \in \in U \cap V_{\lambda_{j}}, \quad 1 \leq j \leq l-1$.
Но тогда из (29) и $\mathbf{v}_{l} \in U$, что и требовалось доказать.
Приведем также вариант доказательства (в предположении бесконечности основного поля) без использования индукции. Подействуем на $\mathbf{u}=\mathbf{v}_{1}+\ldots+ \mathbf{v}_{k} \in U$ оператором $\varphi$, получим
$$
\varphi(\mathbf{u})=\lambda_{1} \mathbf{v}_{1}+\ldots+\lambda_{k} \mathbf{v}_{k} \in U .
$$

Далее,
$$
\begin{gathered}
\varphi^{2}(\mathbf{u})=\lambda_{1}^{2} \mathbf{v}_{1}+\ldots+\lambda_{k}^{2} \mathbf{v}_{k} \in U, \ldots, \\
\varphi^{k-1}(\mathbf{u})=\lambda_{1}^{k-1} \mathbf{v}_{1}+\ldots+\lambda_{k}^{k-1} \mathbf{v}_{k} \in U .
\end{gathered}
$$

Переписывая полученные равенства в матричном виде, получим
$$
\left(\begin{array}{cccc}
1 & 1 & \ldots & 1 \\
\lambda_{1} & \lambda_{2} & \ldots & \lambda_{k} \\
\lambda_{1}^{2} & \lambda_{2}^{2} & \ldots & \lambda_{k}^{2} \\
\ldots \ldots & \ldots & \ldots & \ldots \\
\lambda_{1}^{k-1} & \lambda_{2}^{k-1} & \ldots & \lambda_{k}^{k-1}
\end{array}\right)\left(\begin{array}{c}
\mathbf{v}_{1} \\
\mathbf{v}_{2} \\
\mathbf{v}_{3} \\
\ldots \\
\mathbf{v}_{k}
\end{array}\right)=\left(\begin{array}{c}
\mathbf{u}_{1} \\
\mathbf{u}_{2} \\
\mathbf{u}_{3} \\
\ldots \\
\mathbf{u}_{k}
\end{array}\right),
$$

где $\mathbf{u}_{j}:=\varphi^{j-1}(\mathbf{u}) \in U, \mathbf{u}_{1}=\mathbf{u}$. Матрица слева - матрица Вандермонда, при $\lambda_{i} \neq \lambda_{j}$ она обратима $\Rightarrow$ все $\mathbf{v}_{j}$ также лежат в $U$. \(\square\)

Положив в условии предыдущей задачи $U=\{\mathbf{0}\}$, в качестве следствия получим следующее важное утверждение: собственные векторы, отвечающие разным собственным значениям, линейно независимы.

Задача 2.22. Доказать, что если оператор $\varphi: V \rightarrow V$ диагонализируем, то и его ограничение $\left.\varphi\right|_{U}$ на любое инвариантное подпространство $U \subset V$ диагонализируемо.

Решение. Очевидно, что оператор $\varphi$ диагонализируем $\Leftrightarrow V=V_{\lambda_{1}} \oplus \ldots \oplus V_{\lambda_{k}}$. В предыдущей задаче доказано, что если подпространство $U \subset V \varphi$-инвариантно, то для представления произвольного вектора $\mathbf{u} \in U$ вида
$$
\mathbf{u}=\mathbf{v}_{1}+\ldots+\mathbf{v}_{k},
$$

где $\mathbf{v}_{j} \in V_{\lambda_{j}}$, следует $\mathbf{v}_{j} \in U \forall j$. Другими словами, $U=\left(U \cap V_{\lambda_{1}}\right) \oplus \oplus \ldots \oplus(U \cap V_{\lambda_{k}}$ ). Отсюда следует диагонализируемость оператора $\left.\varphi\right|_{U}$, так как $U \cap V_{\lambda_{j}}$ - его собственные подпространства.

Другое решение задачи можно получить, используя задачу 2.12 и тот факт, что если $f(t) \in \mathbb{K}[t], U \subset V$ - $\varphi$-инвариантное подпространство, то $f\left(\left.\varphi\right|_{U}\right)= \left.f(\varphi)\right|_{U}$, а значит, минимальный многочлен оператора $\left.\varphi\right|_{U}$ делит минимальный многочлен $\varphi$ (такое решение приведено в [15], гл. $6, § 5$ ). \(\square\)

Задача 2.23. Пусть оператор $\varphi: V \rightarrow V$ диагонализируем. Тогда любое его $\varphi$-инвариантное подпространство $U \subset V$ имеет $\varphi$-инвариантное прямое дополнение $W \subset V$, то есть такое $\varphi$-инвариантное подпространство $W \subset V$, что $V=U \oplus W$.

Решение. В предыдущих обозначениях пусть
$$
V=V_{\lambda_{1}} \oplus \ldots \oplus V_{\lambda_{k}}, \quad U=\left(U \cap V_{\lambda_{1}}\right) \oplus \ldots \oplus\left(U \cap V_{\lambda_{k}}\right) .
$$

Для каждого подпространства $U \cap V_{\lambda_{i}} \subset V_{\lambda_{i}}$ выберем произвольное прямое дополнение $W_{i} \subset V_{\lambda_{i}}$. Тогда подпространство $W==W_{1} \oplus \ldots \oplus W_{k} \subset V$ является $\varphi$-инвариантным и $V=U \oplus W$. \(\square\)

Задача 2.24. Пусть $V$ - векторное пространство над бесконечным полем, $\operatorname{dim} V=n$.
a) Пусть оператор $\varphi: V \rightarrow V$ диагонализируем. Тогда собственные значения $\varphi$ попарно различны тогда и только тогда, когда $\varphi$ имеет циклический вектор, то есть такой вектор $\mathbf{v} \in V$, что $\mathbf{v}, \varphi(\mathbf{v}), \ldots, \varphi^{n-1}(\mathbf{v})$ порождают все пространство $V$.
b) Пусть степень минимального многочлена оператора $\varphi$ равна $n$. Тогда $\varphi$ имеет циклический вектор.

Решение. а) Предположим, что собственные значения $\varphi$ попарно различны; пусть $\mathbf{v}_{i}$ - собственный вектор с собственным значением $\lambda_{i}, i=1, \ldots, n$. Тогда $\left\{\mathbf{v}_{1}, \ldots, \mathbf{v}_{n}\right\}$ - базис в $V$. Положим $\mathbf{v}:=\mathbf{v}_{1}+\ldots+\mathbf{v}_{n}$. Тогда
$$
\varphi(\mathbf{v})=\lambda_{1} \mathbf{v}_{1}+\ldots+\lambda_{n} \mathbf{v}_{n}, \ldots, \varphi^{n-1}(\mathbf{v})=\lambda_{1}^{n-1} \mathbf{v}_{1}+\ldots+\lambda_{n}^{n-1} \mathbf{v}_{n}
$$

и матрицей перехода от базиса $\left\{\mathbf{v}_{1}, \ldots, \mathbf{v}_{n}\right\}$ к системе векторов
$$
\begin{equation*}
\left\{\mathbf{v}, \varphi(\mathbf{v}), \varphi^{2}(\mathbf{v}), \ldots, \varphi^{n-1}(\mathbf{v})\right\} \tag{30}
\end{equation*}
$$

является матрица Вандермонда, которая обратима и поэтому вторая система - тоже базис в $V$.
Обратно, пусть $\mathbf{v}$ - циклический вектор. Тогда система векторов (30) линейно независима, откуда следует, что минимальный многочлен $m_{\varphi}(t)$ оператора $\varphi$ имеет степень $n$ и совпадает с характеристическим, значит (в силу диагонализируемости $\varphi$ ), все собственные значения $\varphi$ попарно различны.
b) Предположим противное, что система (30) линейно зависима для $\forall \mathbf{v} \in V$. Для каждого вектора $\mathbf{v} \in V$ существует наибольшее $k=k(\mathbf{v}), 0 \leq k<n$ такое, что система
$$
\left\{\mathbf{v}, \varphi(\mathbf{v}), \varphi^{2}(\mathbf{v}), \ldots, \varphi^{k-1}(\mathbf{v})\right\}
$$

линейно независима. Линейную оболочку последней системы обозначим $U_{\mathbf{v}}$. То есть каждый вектор $\mathbf{v} \in V$ содержится в $\varphi$-инвариантном подпространстве $U_{\mathbf{v}} \subsetneq V$.
Пусть $\psi_{\mathbf{v}}:=\left.\varphi\right|_{U_{\mathbf{v}}}$. Тогда $\operatorname{deg} \chi_{\psi_{\mathbf{v}}}(t)=k<n$. Кроме того, по теореме ГамильтонаКэли $U_{\mathbf{v}} \subset \operatorname{ker} \chi_{\psi_{\mathbf{v}}}(\varphi) \subsetneq V$ (последнее потому что степень минимального многочлена $\varphi$ равна $n>k$ по условию). Каждый из многочленов $\chi_{\psi_{\mathbf{v}}}(t)$ является делителем $\chi_{\varphi}(t)$ (см текст перед Задачей 2.21). Следовательно их конечное число, а также конечно число подпространств в $V$ вида $\operatorname{ker} \chi_{\psi_{\mathbf{v}}}(\varphi)$. Таким образом, векторное пространство $V$ над бесконечным полем покрывается конечным числом собственных подпространств, что, очевидно, невозможно. Действительно, предположив противное, для каждого такого подпространства рассмотрим ненулевую линейную функцию, обращающуюся на нем в нуль, тогда их произведение обратится в нуль на всем пространстве, будучи в координатах ненулевым однородным многочленом. Полученное противоречие доказывает пункт b ). \(\square\)

Задача 2.25. Доказать, что если линейный оператор $\varphi: V \rightarrow V$ коммутирует с нильпотентным оператором $\eta: V \rightarrow V$, то собственные значения $\varphi$ и $\varphi+\eta$ совпадают.

Решение. Пусть $\lambda$ - собственное значение $\varphi$ и $V_{\lambda} \subset V$ - соответствующее собственное подпространство. Для произвольного $\mathbf{v} \in V_{\lambda}$ имеем
$$
\varphi(\eta(\mathbf{v}))=\eta(\varphi(\mathbf{v}))=\lambda \eta(\mathbf{v}) \Rightarrow \eta\left(V_{\lambda}\right) \subset V_{\lambda}
$$

Так как оператор $\eta$ нильпотентен, то $\eta\left(V_{\lambda}\right) \neq V_{\lambda}$, то есть существует $\mathbf{v} \in V_{\lambda}, \mathbf{v} \neq \mathbf{0}$ такой, что $\eta(\mathbf{v})=\mathbf{0}$. Тогда
$$
(\varphi+\eta)(\mathbf{v})=\varphi(\mathbf{v})=\lambda \mathbf{v}
$$

то есть $\mathbf{v}$ - собственный вектор оператора $\varphi+\eta$ с собственным значением $\lambda$. Таким образом, каждое собственное значение $\varphi$ является также собственным значением $\varphi+\eta$. Обратное теперь также очевидно.
Комментарий. Пример матриц $\left(\begin{array}{ll}0 & 1 \\ 0 & 0\end{array}\right)$ и $\left(\begin{array}{ll}0 & 0 \\ 1 & 0\end{array}\right)$ показывает, что условие коммутирования $\varphi$ и $\eta$ нельзя отбросить.

Задача 2.26. 1) Доказать, что два диагонализируемых оператора $\varphi, \psi: V \rightarrow V$ коммутируют тогда и только тогда, когда они имеют общий базис из собственных векторов.
2) Распространить этот результат на произвольное множество коммутирующих диагонализируемых операторов.

Решение. 1) Тождество $\varphi \psi=\psi \varphi$ влечет ( $\varphi-\lambda \mathrm{id}$ ) $\psi=\psi(\varphi--\lambda \mathrm{id})$ для любого скаляра $\lambda$. Значит, произвольное собственное подпространство $V_{\lambda}$ оператора $\varphi$ является $\psi$-инвариантным. По условию $\psi$ диагонализируемо, значит, согласно задаче 2.22 , его ограничение на $V_{\lambda}$ диагонализируемо, то есть для $\left.\psi\right|_{V_{\lambda}}$ есть базис из собственных векторов, которые, очевидно, собственные также и для $\varphi$ (с собственным значением $\lambda$ ). Поскольку $V=V_{\lambda_{1}} \oplus \oplus \ldots \oplus V_{\lambda_{k}}$, где $\lambda_{1}, \ldots, \lambda_{k}$ - все попарно различные собственные значения оператора $\varphi$, и в каждом $V_{\lambda_{j}}$ есть общий собственный базис для $\left.\psi\right|_{\lambda_{\lambda_{j}}}$ и $\left.\varphi\right|_{V_{\lambda_{j}}}$, то объединение таких базисов по всем $j, 1 \leq j \leq k$, даст требуемый базис во всем $V$.
Таким образом, из $[\varphi, \psi]=0$ следует существование общего базиса из собственных векторов. Обратное утверждение очевидно.
2) Пусть у нас есть три коммутирующих диагонализируемых оператора $\varphi, \psi, \chi$. Пусть $V_{\lambda}$ и $W_{\mu}$ - собственные подпространства операторов $\varphi$ и $\psi$ соответственно. Тогда, как установлено ранее, подпространство $V_{\lambda} \cap W_{\mu}$ является $\chi$-инвариантным.
Пусть $\lambda_{1}, \ldots, \lambda_{k}$ - набор всех различных собственных значений оператора $\varphi$ и $\mu_{1}, \ldots, \mu_{l}$ - аналогичный набор для $\psi$. Пусть $V_{i j}:=V_{\lambda_{i}} \cap W_{\mu_{j}}$. Из предыдущего пункта следует, что сумма подпространств $V_{i j} \subset V$ совпадает с $V$ (так как содержит базис). Кроме того, покажем, что эти подпространства линейно независимы, то есть из $\sum \mathbf{v}_{i j}=\mathbf{0}$, где $\mathbf{v}_{i j} \in V_{i j}$, следует, что все
$\mathbf{v}_{i j}=\mathbf{0}$. Для этого рассмотрим систему равенств
$$
\begin{gathered}
\sum_{i}\left(\sum_{j} \mathbf{v}_{i j}\right)=\mathbf{0}, \quad \sum_{i} \lambda_{i}\left(\sum_{j} \mathbf{v}_{i j}\right)=\mathbf{0}, \quad \ldots, \\
\sum_{i} \lambda_{i}^{k-1}\left(\sum_{j} \mathbf{v}_{i j}\right)=\mathbf{0}
\end{gathered}
$$

получающуюся из первого последовательным применением $\varphi$. Далее, рассуждая, как во втором способе в решении задачи 2.21 , получаем, что $\sum_{j} \mathbf{v}_{i j}= \mathbf{0} \forall i$. Применяя теперь к последнему равенству $\psi$, получаем $\mathbf{v}_{i j}=\mathbf{0} \forall i, j$. Далее ограничиваем $\chi$ на каждое ненулевое подпространство вида $V_{i j}$ и замечаем, что пространство $V$ по доказанному представляется в виде их прямой суммы. Снова применяя задачу 2.22 , получаем, что ограничение $\chi$ на все $V_{i j}$ диагонализируемо. Теперь уже очевидно, как, используя индукцию, доказать требуемый результат для любого конечного множества коммутирующих диагонализируемых операторов. Для того чтобы распространить его на произвольные множества, достаточно заметить, что для конечномерного пространства $V$ пространство операторов на нем конечномерно, поэтому среди произвольного множества операторов только конечное число линейно независимых.

Задача 2.27. Пусть $\varphi: V \rightarrow V$ - диагонализируемый оператор с простым спектром. Доказать, что любой оператор $\psi: V \rightarrow V$ такой, что $\varphi \psi=\psi \varphi$, может быть представлен в виде многочлена от $\varphi$. Верно ли это, если спектр оператора $\varphi$ не прост?

Решение. Пусть $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ - базис в $V$, состоящий из общих собственных векторов операторов $\varphi$ и $\psi$, существование которого было доказано в предыдущей задаче. То есть $\varphi\left(\mathbf{e}_{i}\right)==\lambda_{i} \mathbf{e}_{i}, \psi\left(\mathbf{e}_{i}\right)=\mu_{i} \mathbf{e}_{i}$, причем $\lambda_{i} \neq \lambda_{j}$ при $i \neq j$. Заметим, что существует многочлен $f(t)$ степени не выше $n-1$ такой, что
$$
\begin{equation*}
f\left(\lambda_{i}\right)=\mu_{i}, \quad 1 \leq i \leq n \tag{31}
\end{equation*}
$$

Тогда для матриц операторов $\varphi$ и $\psi$ в базисе $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ имеем равенство $f\left(\operatorname{diag}\left(\lambda_{1}, \ldots, \lambda_{n}\right)\right)=\operatorname{diag}\left(\mu_{1}, \ldots, \mu_{n}\right)$. Отсюда и для операторов $f(\varphi)=\psi$. Дадим "линейно-алгебраическое" доказательство существования многочлена $f(t)$ степени не выше $n-1$, удовлетворяющего системе (31).
Пусть $W:=\mathbb{K}[x]_{n-1}$ - пространство многочленов степени не выше $n-1$. Мы знаем, что $\operatorname{dim} W=n$. Пусть $\theta_{i} \in W^{*}$ - набор линейных функционалов, задаваемых формулой
$$
\theta_{i}(h):=h\left(\lambda_{i}\right) \forall h \in W .
$$

Покажем, что $\left\{\theta_{1}, \ldots, \theta_{n}\right\}$ образуют базис в $W^{*}$. Так как $\operatorname{dim} W^{*}==\operatorname{dim} W= n$, достаточно доказать линейную независимость.
Пусть $\sum_{i=1}^{n} \alpha_{i} \theta_{i}=0$ - равенство нулю линейного функционала. Применяя его к элементам базиса $\left\{1, x, \ldots, x^{n-1}\right\}$ в $W$, получаем, что ( $\alpha_{1}, \ldots, \alpha_{n}$ ) - решение системы линейных однородных уравнений с матрицей Вандермонда, отвечающей $\lambda_{1}, \ldots, \lambda_{n}$. Поскольку $\lambda_{i} \neq \lambda_{j}$ при $i \neq j$, эта система имеет только тривиальное решение. Тем самым линейная независимость $\left\{\theta_{1}, \ldots, \theta_{n}\right\}$ доказана.

Пусть $\left\{g_{1}, \ldots g_{n}\right\}$ - биортогональный (=взаимный) базис в $W \cong W^{* *}$ к базису $\left\{\theta_{1}, \ldots, \theta_{n}\right\}$ в $W^{*}$, то есть
$$
\theta_{i}\left(g_{j}\right)=g_{j}\left(\lambda_{i}\right)=\delta_{i j}= \begin{cases}1, & i=j \\ 0, & i \neq j\end{cases}
$$

Тогда $\forall h \in W$ имеем
$$
h(t)=\sum_{i=1}^{n} \theta_{i}(h) g_{i}(t)=\sum_{i=1}^{n} h\left(\lambda_{i}\right) g_{i}(t)
$$
(эта формула называется интерполяционной формулой Лагранжа) - формула, задающая многочлен степени не выше $n-1$, принимающий в точках $\lambda_{1}, \ldots, \lambda_{n}$ значения $h\left(\lambda_{1}\right), \ldots, h\left(\lambda_{n}\right)$, которые могут быть произвольными. В частности, задав значения (31), получим требуемый многочлен $f(t)$.
Нетрудно получить следующий явный вид многочленов $g_{i}$ :
$$
g_{i}(t)=\frac{\prod_{j \neq i}\left(t-\lambda_{j}\right)}{\prod_{j \neq i}\left(\lambda_{i}-\lambda_{j}\right)} .
$$

\section*{2.2. Комплексификация}

Пусть $V$ - векторное пространство над полем $\mathbb{R}$. Рассмотрим векторное пространство $V \oplus V$ над $\mathbb{R}$, элементами которого являются упорядоченные пары векторов из $V$ с покомпонентными операциями сложения и умножения на вещественные числа. То есть
$$
\begin{gathered}
V \oplus V=\{(\mathbf{u}, \mathbf{v}) \mid \mathbf{u}, \mathbf{v} \in V\}, \\
\left(\mathbf{u}_{1}, \mathbf{v}_{1}\right)+\left(\mathbf{u}_{2}, \mathbf{v}_{2}\right)=\left(\mathbf{u}_{1}+\mathbf{u}_{2}, \mathbf{v}_{1}+\mathbf{v}_{2}\right), \\
\alpha(\mathbf{u}, \mathbf{v})=(\alpha \mathbf{u}, \alpha \mathbf{v}) \forall \mathbf{u}, \mathbf{v} \in V, \alpha \in \mathbb{R} .
\end{gathered}
$$

Легко проверить, что если $\operatorname{dim} V=n$, то $\operatorname{dim}(V \oplus V)=2 n$, и если $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ - базис в $V$, то $\left\{\left(\mathbf{e}_{1}, \mathbf{0}\right),\left(\mathbf{0}, \mathbf{e}_{1}\right),\left(\mathbf{e}_{2}, \mathbf{0}\right),\left(\mathbf{0}, \mathbf{e}_{2}\right), \ldots,\left(\mathbf{e}_{n}, \mathbf{0}\right),\left(\mathbf{0}, \mathbf{e}_{n}\right)\right\}$ - базис в $V \oplus V$.
Сейчас мы определим умножение элементов $V \oplus V$ на элементы поля $\mathbb{C}$, продолжающее умножение на $\mathbb{R} \subset \mathbb{C}$, которое задаст на $V \oplus V$ структуру векторного пространства над $\mathbb{C}$. Из комментария к задаче 1.11 мы знаем, что для этого нужно задать комплексную структуру на $V \oplus V$, то есть такой линейный оператор $I: V \oplus V \rightarrow V \oplus V$, что $I^{2}=-\mathrm{id}$ (такой $I$ играет роль "умножения на $i$ "). А именно, положим
$$
I(\mathbf{u}, \mathbf{v})=(-\mathbf{v}, \mathbf{u})
$$

Линейность $I$ очевидна. Кроме того,
$$
I^{2}(\mathbf{u}, \mathbf{v})=I(-\mathbf{v}, \mathbf{u})=(-\mathbf{u},-\mathbf{v})=-\operatorname{id}(\mathbf{u}, \mathbf{v}) .
$$

Пусть $z:=\alpha+\beta i, \alpha, \beta \in \mathbb{R}$ - комплексное число, тогда
$$
(\alpha+\beta i)(\mathbf{u}, \mathbf{v})=(\alpha \mathrm{id}+\beta I)(\mathbf{u}, \mathbf{v})=
$$
$$
=(\alpha \mathbf{u}, \alpha \mathbf{v})+(-\beta \mathbf{v}, \beta \mathbf{u})=(\alpha \mathbf{u}-\beta \mathbf{v}, \alpha \mathbf{v}+\beta \mathbf{u}) .
$$

Из определения $I$ следует, что $I(\mathbf{v}, \mathbf{0})=(\mathbf{0}, \mathbf{v})$. Чтобы упростить обозначения, обозначим ( $\mathbf{u}, \mathbf{0}$ ) через $\mathbf{u}$, тогда ( $\mathbf{u}, \mathbf{v}$ ) $=\mathbf{u}++i \mathbf{v}$, и в этих обозначениях умножение на комплексные числа запишется в виде
$$
\begin{equation*}
(\alpha+\beta i)(\mathbf{u}+i \mathbf{v})=\alpha \mathbf{u}-\beta \mathbf{v}+i(\alpha \mathbf{v}+\beta \mathbf{u}) \tag{32}
\end{equation*}
$$

Легко проверить, что это определяет на $V \oplus V$ структуру векторного пространства над $\mathbb{C}$, которое мы обозначим $V^{\mathbb{C}}$ и назовем комплексификацией вещественного векторного пространства $V$. Если $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ - базис в $V$ (как векторном пространстве над $\mathbb{R}$ ), то $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ (то есть $\left\{\left(\mathbf{e}_{1}, \mathbf{0}\right),\left(\mathbf{e}_{2}, \mathbf{0}\right), \ldots,\left(\mathbf{e}_{n}, \mathbf{0}\right)\right\}$ ) - базис в $V^{\mathbb{C}}$ (как в векторном пространстве над $\mathbb{C}$ ).

Заметим, что для каждого подпространства $W \subset V^{\mathbb{C}}$ определено его комплексное сопряжение $\bar{W} \subset V^{\mathbb{C}}$, задаваемое условием $(\mathbf{u}, \mathbf{v}) \in W \quad \Leftrightarrow \quad(\mathbf{u},-\mathbf{v}) \in \bar{W}$.

Задача 2.28. Доказать, что подпространство $W \subset V^{\mathbb{C}}$ является комплексификацией некоторого подпространства $U \subset V$ тогда и только тогда, когда $W=\bar{W}$.

Решение. Пусть $W=\bar{W}$, тогда $\{(\mathbf{u}, \mathbf{v}) \in W \quad \Leftrightarrow \quad(\mathbf{u},-\mathbf{v}) \in \in W\} \quad \Leftrightarrow \{(\mathbf{u}, \mathbf{0}) \in W,(\mathbf{0}, \mathbf{v}) \in W\}$. В других обозначениях, $\mathbf{u}+i \mathbf{v} \in W \Leftrightarrow \mathbf{u}, i \mathbf{v} \in W$. Кроме того, так как $W$ является векторным пространством над $\mathbb{C}$, то $\mathbf{u} \in W \Leftrightarrow i \mathbf{u} \in W$. Теперь легко видеть, что $W$ является комплексификацией подпространства $U \subset V$, состоящего из таких $\mathbf{u} \in V$, что ( $\mathbf{u}, \mathbf{0}$ ) $\in W$.
Обратная импликация очевидна.
Пусть $\varphi: V \rightarrow V-\mathbb{R}$-линейный оператор. Определим отображение $\varphi^{\mathbb{C}}: V^{\mathbb{C}} \rightarrow V^{\mathbb{C}}$ формулой $\varphi^{\mathbb{C}}(\mathbf{u}, \mathbf{v})=(\varphi(\mathbf{u}), \varphi(\mathbf{v}))$, то есть $\varphi^{\mathbb{C}}(\mathbf{u}+i \mathbf{v})=\varphi(\mathbf{u})+i \varphi(\mathbf{v})$. Его линейность над $\mathbb{C}$, то есть тождество
$$
\varphi^{\mathbb{C}}((\alpha+i \beta)(\mathbf{u}+i \mathbf{v}))=(\alpha+i \beta) \varphi^{\mathbb{C}}(\mathbf{u}+i \mathbf{v})
$$

проверяется непосредственно. Таким образом, $\varphi^{\mathbb{C}}-\mathbb{C}$-линейный оператор на $V^{\mathbb{C}}$. Заметим, что $\varphi^{\mathbb{C}}$ в базисе $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ в $V^{\mathbb{C}}$ имеет ту же матрицу, что и $\varphi$ в базисе $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ в $V$. В частности, их характеристические многочлены совпадают.
У оператора $\varphi: V \rightarrow V$, где $V$ - векторное пространство над $\mathbb{R}$, может не оказаться ни одного собственного вектора. Причина этого состоит в том, что характеристический многочлен $\chi_{\varphi}(t)$ может не иметь вещественных корней (в случае, когда размерность $V$ четна). После комплексификации для каждого корня (в том числе комплексного) собственные векторы оператора $\varphi^{\mathbb{C}}$ в $V^{\mathbb{C}}$ будут существовать.

Задача 2.29. Найти собственные векторы комплексификации $\varphi^{\mathbb{C}}$ оператора $\varphi$ поворота на угол $\frac{\pi}{2}$ в комплексификации $V^{\mathbb{C}}$ евклидовой плоскости $V$.

Решение. В правом ортонормированном базисе в $V$ оператор $\varphi$ имеет матрицу $\left(\begin{array}{cc}0 & -1 \\ 1 & 0\end{array}\right)$. Его характеристический многочлен $\chi_{\varphi}(t)=t^{2}+1$ имеет

корни $\pm i$. Соответствующие собственные векторы можно найти стандартным способом, решая системы линейных уравнений, но можно также воспользоваться следующими соображениями. Заметим, что такую же матрицу имеет оператор дифференцирования в базисе $\{\sin x, \cos x\}$ линейной оболочки $\langle\sin x, \cos x\rangle$ функций на $\mathbb{R}$ (см. задачу 2.5). Из анализа известно (см. также задачу 2.45), что собственными функциями оператора дифференцирования являются экспоненты: общее решение дифференциального уравнения $f^{\prime}(x)=\lambda f(x)$, где $f: \mathbb{R} \rightarrow \mathbb{C}, \lambda \in \mathbb{C}$, имеет вид $C \exp (\lambda x)$, где $C \in \mathbb{C}$. Беря линейные комбинации функций $\sin x, \cos x$ с коэффициентами из $\mathbb{R}$, экспоненту не получить, другое дело - комплексные линейные комбинации. По формуле Эйлера, $\exp (i x)=\cos x+i \sin x$, значит, собственный вектор, отвечающий собственному значению $i$, имеет координатный столбец $(i, 1)^{T}$, а собственный вектор, отвечающий собственному значению $t=-i$, - столбец $(-i, 1)^{T}$. \(\square\)

Задача 2.30. Доказать, что у любого линейного оператора $\varphi$ на векторном пространстве $V$ над $\mathbb{R}, \operatorname{dim} V \geq 1$, есть 1 - или 2 -мерное инвариантное подпространство.

Решение. Если характеристический многочлен $\chi_{\varphi}(t)$ имеет корень $\lambda \in \mathbb{R}$, то ему отвечает собственный вектор $\mathbf{v} \in V$ и одномерное подпространство $\langle\mathbf{v}\rangle \subset V$ является $\varphi$-инвариантным.
Пусть $\chi_{\varphi}(t)$ не имеет вещественных корней (в частности, размерность $V$ четна). Пусть $\lambda=\mu+i \nu$ - комплексный корень $\chi_{\varphi}(t)$. Рассмотрим $\mathbb{C}$-линейный оператор $\varphi^{\mathbb{C}}: V^{\mathbb{C}} \rightarrow V^{\mathbb{C}}$. Тогда $\lambda$ является корнем $\chi_{\varphi^{\mathbb{C}}}(t)=\chi_{\varphi}(t)$ и существует собственный вектор оператора $\varphi^{\mathbb{C}}$ с собственным значением $\lambda$, то есть ненулевой вектор $\mathbf{w} \in V^{\mathbb{C}}$ такой, что $\varphi^{\mathbb{C}}(\mathbf{w})=\lambda \mathbf{w}$. Пусть $\mathbf{w}=\mathbf{u}+i \mathbf{v}$, где $\mathbf{u}, \mathbf{v} \in V$. Тогда
$$
\begin{gathered}
\varphi^{\mathbb{C}}(\mathbf{w})=\lambda \mathbf{w}=(\mu+i \nu)(\mathbf{u}+i \mathbf{v})= \\
=\mu \mathbf{u}-\nu \mathbf{v}+i(\nu \mathbf{u}+\mu \mathbf{v})=\varphi(\mathbf{u})+i \varphi(\mathbf{v})
\end{gathered}
$$
(где мы использовали (32) и определение $\varphi^{\mathbb{C}}$ ). Отсюда легко получить, что $\varphi(\mathbf{u})=\mu \mathbf{u}-\nu \mathbf{v}, \quad \varphi(\mathbf{v})=\nu \mathbf{u}+\mu \mathbf{v}$. Также легко проверяется, что $\mathbf{u}-i \mathbf{v}$ - собственный вектор оператора $\varphi^{\mathbb{C}}$ с собственным значением $\mu-i \nu=\bar{\lambda}$. Так как $\lambda \neq \bar{\lambda}$ при $\lambda \notin \mathbb{R}$, то векторы $\mathbf{u}$ и $\mathbf{v}$ линейно независимы. Значит, $\langle\mathbf{u}, \mathbf{v}\rangle \subset V-\varphi$-инвариантная плоскость. \(\square\)

Заметим, что ограничение $\varphi$ на инвариантное подпространство $\langle\mathbf{u}, \mathbf{v}\rangle \subset V$ в базисе $\{\mathbf{u}, \mathbf{v}\}$ имеет матрицу $\left(\begin{array}{cc}\mu & \nu \\ -\nu & \mu\end{array}\right)$.

Задача 2.31. Пусть $\varphi: V \rightarrow V$ - линейный оператор на пространстве $V$ над некоторым полем $\mathbb{K}, A$ - его матрица в некотором базисе. Пусть $p(t) \in \mathbb{K}[t]$ - многочлен степени $d$ такой, что $p(A)$ - вырожденная матрица. Докажите, что у $\varphi$ найдется нетривиальное инвариантное подпространство, размерность которого не превосходит $d$.

Решение. Пусть $\mathbf{0} \neq \mathbf{v} \in \operatorname{ker} p(\varphi) \neq 0$. Рассмотрим
$$
U:=\left\langle\mathbf{v}, \varphi(\mathbf{v}), \ldots, \varphi^{d-1}(\mathbf{v})\right\rangle \subset V .
$$

Используя $p$, получаем $\varphi^{d}(\mathbf{v}) \in U$, то есть $U \varphi$-инвариантно, при этом $\operatorname{dim} V \leq d$.
Используя предыдущую задачу можно дать другое решение Задачи 2.30. А именно, пусть $\chi_{\varphi}(t) \in \mathbb{R}[t]$ - характеристический многочлен $\varphi$. Мы знаем, что он является произведением неприводимых вещественных многочленов степеней 1 или 2 . Если у него есть множитель степени 1 , то у $\chi_{\varphi}(t)$ есть вещественный корень - собственное значение $\varphi$, а значит и одномерное инвариантное подпространство (порожденное любым собственным вектором). Если линейных множителей у $\chi_{\varphi}(t)$ нет (что может быть только в четномерном случае), то рассмотрим неприводимый множитель $p(t)= t^{2}+p t+q=(t-\lambda)(t-\bar{\lambda})$ степени 2 . Его (комплексные) корни $\lambda, \bar{\lambda}-$ собственные значения комплексификации $\varphi^{\mathbb{C}}$, и значит если $A$ - матрица $\varphi$, то $p(A)=(A-\lambda E)(A-\bar{\lambda} E)$ - вырожденная матрица. Осталось применить заключение предыдущей задачи.

\section*{2.3. Факторпространство и фактороператор}

Пусть $V$ - векторное пространство над некоторым полем $\mathbb{K}, U \subset V$ - его подпространство. Определим следующее отношение эквивалентности на $V$. По определению
$$
\mathbf{v} \sim \mathbf{v}^{\prime} \Leftrightarrow \mathbf{v}^{\prime}-\mathbf{v} \in U
$$

Проверим, что это - действительно отношение эквивалентности. 1) Рефлексивность: $\forall \mathbf{v} \in V \mathbf{v} \sim \mathbf{v}$. Действительно, $\mathbf{v}-\mathbf{v}=\mathbf{0} \in U$ (любое подпространство содержит нулевой вектор). 2) Симметричность: $\mathbf{v} \sim \mathbf{v}^{\prime} \Rightarrow \mathbf{v}^{\prime} \sim \mathbf{v}$. Действительно, если $\mathbf{v}^{\prime}-\mathbf{v} \in U$, то $\mathbf{v}-\mathbf{v}^{\prime} \in U$ (подпространство вместе с каждым вектором содержит его противоположный). 3) Транзитивность: $\mathbf{v} \sim \mathbf{v}^{\prime}, \mathbf{v}^{\prime} \sim \sim \mathbf{v}^{\prime \prime} \Rightarrow \mathbf{v} \sim \mathbf{v}^{\prime \prime}$. Действительно, если $\mathbf{v}^{\prime}-\mathbf{v} \in U, \mathbf{v}^{\prime \prime}-\mathbf{v}^{\prime} \in U$, то $\mathbf{v}^{\prime \prime}-\mathbf{v}=\left(\mathbf{v}^{\prime \prime}-\mathbf{v}^{\prime}\right)+\left(\mathbf{v}^{\prime}-\mathbf{v}\right) \in U$ (подпространство вместе с каждой парой векторов содержит их сумму).
Обозначим через $[\mathbf{v}]$ класс эквивалентности $\mathbf{v} \in V$, то есть $[\mathbf{v}]:=\left\{\mathbf{v}^{\prime} \in V \mid\right. \left.\mathbf{v}^{\prime} \sim \mathbf{v}\right\}$. Таким образом, $[\mathbf{v}]$ - подмножество $V$, а произвольный элемент $\mathbf{v}^{\prime} \in[\mathbf{v}]$ - представитель класса $[\mathbf{v}]$. Другое его описание: $[\mathbf{v}]=\{\mathbf{v}+\mathbf{u} \mid \mathbf{u} \in U\}$. В частности, $[\mathbf{0}]=U$. Заметим, что
$$
\left[\mathbf{v}_{1}\right]=\left[\mathbf{v}_{2}\right] \Leftrightarrow \mathbf{v}_{2}-\mathbf{v}_{1} \in U \Leftrightarrow \mathbf{v}_{2}=\mathbf{v}_{1}+\mathbf{u}, \text { где } \mathbf{u} \in U .
$$

Рассмотрим новое множество, элементами которого являются классы эквивалентности векторов $\mathbf{v} \in V$. Обозначим его $V / U$. Таким образом, $[\mathbf{v}] \in V / U$. Превратим множество $V / U$ в векторное пространство над $\mathbb{K}$. Для этого нужно определить сумму элементов вида $[\mathbf{v}]$, их умножение на скаляры из $\mathbb{K}$ и проверить выполнение аксиом векторного пространства. Положим по определению
$$
\left[\mathbf{v}_{1}\right]+\left[\mathbf{v}_{2}\right]:=\left[\mathbf{v}_{1}+\mathbf{v}_{2}\right], \quad \lambda[\mathbf{v}]:=[\lambda \mathbf{v}] .
$$

Ключевой момент заключается в проверке корректности введенных операций сложения и умножения на скаляры (см. определение 0.12). Дело в том, что сумму классов $\left[\mathbf{v}_{1}\right]$ и $\left[\mathbf{v}_{2}\right]$ мы определили как класс суммы их конкретных представителей $\mathbf{v}_{1}, \mathbf{v}_{2}$. Нужно проверить, что последний не зависит от выбора этих представителей. То же для умножения на скаляры.

Таким образом, нужно проверить, что если $\left[\mathbf{v}_{1}^{\prime}\right]=\left[\mathbf{v}_{1}\right],\left[\mathbf{v}_{2}^{\prime}\right]==\left[\mathbf{v}_{2}\right]$, то $\left[\mathbf{v}_{1}^{\prime}+\mathbf{v}_{2}^{\prime}\right]=\left[\mathbf{v}_{1}+\mathbf{v}_{2}\right]$, а также если $\left[\mathbf{v}^{\prime}\right]=[\mathbf{v}]$, то $\left[\lambda \mathbf{v}^{\prime}\right]==[\lambda \mathbf{v}]$.
Итак, проверим корректность операции сложения. Если $\left[\mathbf{v}_{1}^{\prime}\right]==\left[\mathbf{v}_{1}\right]$, то $\mathbf{v}_{1}^{\prime}-\mathbf{v}_{1} \in U$, аналогично из $\left[\mathbf{v}_{2}^{\prime}\right]=\left[\mathbf{v}_{2}\right]$ вытекает $\mathbf{v}_{2}^{\prime}-\mathbf{v}_{2} \in U$. Тогда ( $\mathbf{v}_{1}^{\prime}+ \left.\mathbf{v}_{2}^{\prime}\right)-\left(\mathbf{v}_{1}+\mathbf{v}_{2}\right)=\left(\mathbf{v}_{1}^{\prime}-\mathbf{v}_{1}\right)+\left(\mathbf{v}_{2}^{\prime}-\mathbf{v}_{2}\right) \in U$, то есть $\left[\mathbf{v}_{1}^{\prime}+\mathbf{v}_{2}^{\prime}\right]=\left[\mathbf{v}_{1}+\mathbf{v}_{2}\right]$.
Проверка корректности умножения на скаляры:
$$
\begin{gathered}
{\left[\mathbf{v}^{\prime}\right]=[\mathbf{v}] \Rightarrow \mathbf{v}^{\prime}-\mathbf{v} \in U \Rightarrow} \\
\Rightarrow \lambda \mathbf{v}^{\prime}-\lambda \mathbf{v}=\lambda\left(\mathbf{v}^{\prime}-\mathbf{v}\right) \in U \Rightarrow\left[\lambda \mathbf{v}^{\prime}\right]=[\lambda \mathbf{v}] .
\end{gathered}
$$

Аксиомы векторного пространства над полем $\mathbb{K}$ для множества $V / U$ с введенными операциями сложения и умножения на скаляры следуют из соответствующих аксиом для $V$ (в частности, роль нулевого вектора в $V / U$ играет $[\mathbf{0}]$, противоположного к $[\mathbf{v}]-[-\mathbf{v}]$, и т.д.). Таким образом, $V / U$ само является векторным пространством над полем $\mathbb{K}$, которое называется факторпространством пространства $V$ по подпространству $U$.

Задача 2.32. Пусть $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{k}\right\}$ - базис в подпространстве $U \subset V$. Тогда $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{k}, \mathbf{e}_{k+1}, \ldots, \mathbf{e}_{n}\right\}$ - базис в $V \Leftrightarrow\left\{\left[\mathbf{e}_{k+1}\right], \ldots,\left[\mathbf{e}_{n}\right]\right\}$ - базис в $V / U$.

Решение. $\Rightarrow$ Имеем
$$
\begin{gathered}
\sum_{j=k+1}^{n} \beta_{j}\left[\mathbf{e}_{j}\right]=[\mathbf{0}] \Leftrightarrow \sum_{j=k+1}^{n} \beta_{j} \mathbf{e}_{j} \in U \Leftrightarrow \\
\Leftrightarrow \sum_{j=k+1}^{n} \beta_{j} \mathbf{e}_{j}=\sum_{i=1}^{k} \alpha_{i} \mathbf{e}_{i} \Leftrightarrow \\
\Leftrightarrow \beta_{j}=0, \quad k+1 \leq j \leq n, \quad \alpha_{i}=0, \quad 1 \leq i \leq k,
\end{gathered}
$$

поскольку система векторов $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ линейно независима.
Пусть теперь $\mathbf{v} \in V$ - произвольный вектор. Тогда
$$
\mathbf{v}=\sum_{i=1}^{n} \mu_{i} \mathbf{e}_{i} \Rightarrow[\mathbf{v}]=\sum_{j=k+1}^{n} \mu_{j}\left[\mathbf{e}_{j}\right] .
$$
$\Leftarrow$ Так как $\left\{\left[\mathbf{e}_{k+1}\right], \ldots,\left[\mathbf{e}_{n}\right]\right\}$ - базис в $V / U$, то
$$
\sum_{j=k+1}^{n} \beta_{j}\left[\mathbf{e}_{j}\right]=[\mathbf{0}] \quad \Leftrightarrow \quad \beta_{j}=0, \quad k+1 \leq j \leq n .
$$

То есть
$$
\begin{equation*}
\sum_{j=k+1}^{n} \beta_{j} \mathbf{e}_{j} \in U \quad \Leftrightarrow \quad \beta_{j}=0, \quad k+1 \leq j \leq n \tag{33}
\end{equation*}
$$

Пусть
$$
\sum_{i=1}^{k} \alpha_{i} \mathbf{e}_{i}=\sum_{j=k+1}^{n} \beta_{j} \mathbf{e}_{j} .
$$

Тогда из (33) следует, что $\beta_{j}=0, k+1 \leq j \leq n$. Тогда $\sum_{i=1}^{k} \alpha_{i} \mathbf{e}_{i}=0$, и так как $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{k}\right\}$ - базис в $U$, то $\alpha_{i}=0,1 \leq \leq i \leq k$. Тем самым доказана линейная независимость векторов $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$.
Пусть $\mathbf{v} \in V$ - произвольный вектор. Тогда $[\mathbf{v}]=\sum_{j=k+1}^{n} \mu_{j}\left[\mathbf{e}_{j}\right]$. Значит,
$$
\mathbf{v}-\sum_{j=k+1}^{n} \mu_{j} \mathbf{e}_{j} \in U \Rightarrow \mathbf{v}-\sum_{j=k+1}^{n} \mu_{j} \mathbf{e}_{j}=\sum_{i=1}^{k} \mu_{i} \mathbf{e}_{i} .
$$

Таким образом, любой вектор $\mathbf{v} \in V$ раскладывается по системе $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$.
Заметим, что из предыдущей задачи следует, что $\operatorname{dim} V / U==\operatorname{dim} V- \operatorname{dim} U$. (Другое доказательство этого факта: имеем сюръективное линейное отображение ("каноническую проекцию")
$$
\pi: V \rightarrow V / U, \quad \pi(\mathbf{v})=[\mathbf{v}]
$$

причем, как легко видеть, $\operatorname{ker} \pi=U$. Тогда по известной формуле $\operatorname{dim} \operatorname{ker} \pi+ \operatorname{dimim} \pi=\operatorname{dim} V$ имеем $\operatorname{dim} U+\operatorname{dim} V / U=\operatorname{dim} V$.)
Пусть $\varphi: V \rightarrow V$ - линейный оператор, $U \subset V$ - его инвариантное подпространство, то есть $\varphi(U) \subset U$. Тогда формула $\bar{\varphi}([\mathbf{v}])=[\varphi(\mathbf{v})]$ определяет линейный оператор $\bar{\varphi}: V / U \rightarrow V / U$, называемый фактороператором.
Проверим корректность определения фактороператора (в терминологии вводной главы, согласованность отношения эквивалентности с оператором как унарной операцией). То есть нужно проверить импликацию
$$
\left[\mathbf{v}^{\prime}\right]=[\mathbf{v}] \quad \Rightarrow \quad\left[\varphi\left(\mathbf{v}^{\prime}\right)\right]=[\varphi(\mathbf{v})]
$$

Действительно, используя $\varphi$-инвариантность $U$, имеем
$$
\begin{aligned}
{\left[\mathbf{v}^{\prime}\right]=[\mathbf{v}] \Rightarrow \mathbf{v}^{\prime}-\mathbf{v} \in U } & \Rightarrow \varphi\left(\mathbf{v}^{\prime}\right)-\varphi(\mathbf{v})=\varphi\left(\mathbf{v}^{\prime}-\mathbf{v}\right) \in U \Rightarrow \\
& \Rightarrow\left[\varphi\left(\mathbf{v}^{\prime}\right)\right]=[\varphi(\mathbf{v})] .
\end{aligned}
$$

Линейность $\bar{\varphi}$ следует из линейности $\varphi$, например,
$$
\begin{gathered}
\bar{\varphi}\left(\left[\mathbf{v}_{1}\right]+\left[\mathbf{v}_{2}\right]\right)=\bar{\varphi}\left(\left[\mathbf{v}_{1}+\mathbf{v}_{2}\right]\right)=\left[\varphi\left(\mathbf{v}_{1}+\mathbf{v}_{2}\right)\right]=\left[\varphi\left(\mathbf{v}_{1}\right)+\varphi\left(\mathbf{v}_{2}\right)\right]= \\
=\left[\varphi\left(\mathbf{v}_{1}\right)\right]+\left[\varphi\left(\mathbf{v}_{2}\right)\right]=\bar{\varphi}\left(\left[\mathbf{v}_{1}\right]\right)+\bar{\varphi}\left(\left[\mathbf{v}_{2}\right]\right)
\end{gathered}
$$

Задача 2.33. Пусть оператор $\varphi: V \rightarrow V$ диагонализируем, $U \subset \subset V-\varphi$ инвариантное подпространство. Тогда фактороператор $\bar{\varphi}: V / U \rightarrow V / U$ тоже диагонализируем.
Решение. Используя решение задачи 2.23, найдем базис $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{k}, \mathbf{e}_{k+1}, \ldots, \mathbf{e}_{n}\right\}$ в $V$ из собственных векторов оператора $\varphi, \varphi\left(\mathbf{e}_{i}\right)==\mu_{i} \mathbf{e}_{i}$ (при этом $\mu_{i}$ не предполагаются попарно различными) такой, что $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{k}\right\}$ - базис в $U$, а $\left\{\mathbf{e}_{k+1}, \ldots, \mathbf{e}_{n}\right\}$ - базис в $\varphi$-инвариантном прямом дополнении $W$, $V=U \oplus W$. Из задачи 2.32 мы знаем, что $\left\{\left[\mathbf{e}_{k+1}\right], \ldots,\left[\mathbf{e}_{n}\right]\right\}$ - базис в $V / U$. Тогда $\bar{\varphi}\left(\left[\mathbf{e}_{j}\right]\right)=\mu_{j}\left[\mathbf{e}_{j}\right], k+1 \leq j \leq n$.
В частности, если блочная матрица $\left(\begin{array}{cc}A & B \\ 0 & C\end{array}\right)$, где $A$ и $C$ - квадратные подматрицы, диагонализируема, то и матрицы $A$ и $C$ диагонализируемы
(поскольку являются матрицами ограничения оператора и фактороператора в соответствующих базисах). Обратное, конечно, неверно.

Используя понятия факторпространства и фактороператора, докажем следующий полезный результат.

Задача 2.34. Пусть $V$ - векторное пространство над полем $\mathbb{C}, \varphi: V \rightarrow V-$ линейный оператор. Тогда в $V$ существует такой базис, в котором матрица оператора $\varphi$ является верхнетреугольной.

Решение. Воспользуемся индукцией по $n=\operatorname{dim} V$. При $n=1$ утверждение очевидно. Пусть утверждение верно для пространств размерности, не превосходящей $n-1$, докажем тогда его справедливость для $n$.
Любой линейный оператор над $\mathbb{C}$ имеет собственный вектор. Некоторый собственный вектор оператора $\varphi$ обозначим $\mathbf{e}_{1}$. То есть $\mathbf{e}_{1} \neq \mathbf{0}, \varphi\left(\mathbf{e}_{1}\right)=\lambda \mathbf{e}_{1}$. Подпространство $U:=\left\langle\mathbf{e}_{1}\right\rangle$ является инвариантным относительно $\varphi$. Рассмотрим фактороператор $\bar{\varphi}: V / U \rightarrow V / U$. Так как $\operatorname{dim} V / U=\operatorname{dim} V- \operatorname{dim} U=n-1$, то по предположению индукции существует базис $\left\{\left[\mathbf{e}_{2}\right], \ldots,\left[\mathbf{e}_{n}\right]\right\}$ в $V / U$, в котором $\bar{\varphi}$ имеет верхнюю треугольную матрицу. Последнее означает, что
$$
\begin{equation*}
\bar{\varphi}\left(\left[\mathbf{e}_{k}\right]\right)=a_{2 k}\left[\mathbf{e}_{2}\right]+\ldots+a_{k k}\left[\mathbf{e}_{k}\right] \quad \text { при всех } 2 \leq k \leq n . \tag{34}
\end{equation*}
$$

Равенство (34) можно записать как $\left[\varphi\left(\mathbf{e}_{k}\right)\right]=\left[a_{2 k} \mathbf{e}_{2}+\ldots+a_{k k} \mathbf{e}_{k}\right]$, что эквивалентно тому, что $\varphi\left(\mathbf{e}_{k}\right)-\left(a_{2 k} \mathbf{e}_{2}+\ldots+a_{k k} \mathbf{e}_{k}\right) \in U$, то есть $\varphi\left(\mathbf{e}_{k}\right)=a_{1 k} \mathbf{e}_{1}+ a_{2 k} \mathbf{e}_{2}+\ldots+a_{k k} \mathbf{e}_{k}$ для некоторых $a_{1 k} \in \in \mathbb{C}$ при $2 \leq k \leq n$. Кроме того, $\varphi\left(\mathbf{e}_{1}\right)=\lambda \mathbf{e}_{1}=a_{11} \mathbf{e}_{1}$. Тогда в базисе $\left\{\mathbf{e}_{1}, \mathbf{e}_{2}, \ldots, \mathbf{e}_{n}\right\}$ (см. задачу 2.32) пространства $V$ оператор $\varphi$ имеет верхнюю треугольную матрицу.
Другой способ решения этой задачи - воспользоваться существованием $n$ 1 -мерного инвариантного подпространства, которое следует из задачи 2.20 , и снова использовать индукцию по $n$. Вот еще один способ доказательства существования $n-1$-мерного инвариантного подпространства. Заметим, что $\exists \lambda \in \mathbb{C}$ такое, что $\operatorname{ker}\left(\varphi-\lambda \operatorname{id}_{V}\right) \neq\{\mathbf{0}\}$. Тогда $\operatorname{dim}\left(\operatorname{im}\left(\varphi-\lambda \operatorname{id}_{V}\right)\right) \leq n-1$. Пусть $U$ - произвольное $n-1$-мерное подпространство в $V$, содержащее $\operatorname{im}\left(\varphi-\lambda \operatorname{id}_{V}\right)$. Тогда $U$ является $\varphi$-инвариантным. Действительно, $\forall \mathbf{u} \in U \varphi(\mathbf{u})=\varphi(\mathbf{u})-\lambda \mathbf{u}+\lambda \mathbf{u} \in U$, поскольку $\varphi(\mathbf{u})-\lambda \mathbf{u} \in U$ и $\lambda \mathbf{u} \in U$.

Задача 2.35. Пусть $\varphi: V \rightarrow V$ - нильпотентный линейный оператор на конечномерном пространстве $V$ над полем $\mathbb{K}$. Тогда в $V$ существует такой базис, в котором матрица оператора $\varphi$ является верхней нильтреугольной.

Решение. Так же, как и в предыдущей задаче, используем индукцию по $n:=\operatorname{dim} V$. Для $n=1 \varphi$ - нулевой оператор. Пусть утверждение верно для операторов на пространствах $V, \operatorname{dim} V \leq \leq n-1$. Если $\varphi$ нильпотентен, то $\operatorname{ker} \varphi \neq\{\mathbf{0}\} \Rightarrow \exists \mathbf{e}_{1} \neq \mathbf{0}$ такой, что $\varphi\left(\mathbf{e}_{1}\right)=\mathbf{0}$. Очевидно, что подпространство $\left\langle\mathbf{e}_{1}\right\rangle \subset V$-инвариантно. Рассмотрим фактороператор $\bar{\varphi}: V / U \rightarrow V / U$, из его определения $\bar{\varphi}([\mathbf{v}])=[\varphi(\mathbf{v})] \forall \mathbf{v} \in V$ легко следует, что он также нильпотентен. Поскольку $\operatorname{dim} V / U=n-1$, то по предположению индукции существует базис $\left\{\left[\mathbf{e}_{2}\right], \ldots,\left[\mathbf{e}_{n}\right]\right\}$ в $V / U$, в котором матрица $\bar{\varphi}$ является

верхней нильтреугольной. Последнее означает, что
$$
\begin{equation*}
\bar{\varphi}\left(\left[\mathbf{e}_{k}\right]\right)=a_{2 k}\left[\mathbf{e}_{2}\right]+\ldots+a_{k-1 k}\left[\mathbf{e}_{k-1}\right] \quad \text { при всех } 2 \leq k \leq n . \tag{35}
\end{equation*}
$$

Равенство (35) можно записать как
$$
\left[\varphi\left(\mathbf{e}_{k}\right)\right]=\left[a_{2 k} \mathbf{e}_{2}+\ldots+a_{k-1 k} \mathbf{e}_{k-1}\right]
$$

что эквивалентно тому, что $\varphi\left(\mathbf{e}_{k}\right)-\left(a_{2 k} \mathbf{e}_{2}+\ldots+a_{k-1 k} \mathbf{e}_{k-1}\right) \in U$, то есть $\varphi\left(\mathbf{e}_{k}\right)=a_{1 k} \mathbf{e}_{1}+a_{2 k} \mathbf{e}_{2}+\ldots+a_{k-1 k} \mathbf{e}_{k-1}$ для некоторых $a_{1 k} \in \mathbb{K}$ при $2 \leq k \leq n$. Кроме того, $\varphi\left(\mathbf{e}_{1}\right)=\mathbf{0}$. Тогда в базисе $\left\{\mathbf{e}_{1}, \mathbf{e}_{2}, \ldots, \mathbf{e}_{n}\right\}$ (см. задачу 2.32) пространства $V$ оператор $\varphi$ имеет верхнюю нильтреугольную матрицу. В частности, все собственные значения нильпотентного оператора равны 0 .
Другой способ решения этой задачи - применить предположение индукции к $\varphi$-инвариантному подпространству $V_{1}:=:=\varphi(V) \nsubseteq V$. Если $V_{1}=0$, то все доказано. В противном случае пусть $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{k}\right\}$ - базис $V_{1}$, в котором матрица ограничения (которое является нильпотентным оператором) нильтреугольна. Продолжим его до базиса $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{k}, \mathbf{e}_{k+1}, \ldots, \mathbf{e}_{n}\right\}$ в $V$. Легко видеть, что в нем матрица $\varphi$ имеет требуемый вид, поскольку $\forall j \varphi\left(\mathbf{e}_{j}\right) \in V_{1}$.

Читатель, желающий потренироваться в проведении доказательств индукцией по размерности с использованием факторпространств, может попробовать доказать этим способом теорему Гамильтона-Кэли для алгебраически замкнутого поля (такое доказательство дано в [35], ч. 1, § 8).

Опишем способ получения явных выражений для коэффициентов характеристического многочлена (23) через матрицу $A$ оператора $\varphi: V \rightarrow V$ (где $V$ - векторное пространство над $\mathbb{C}$ или $\mathbb{R}$ ). Пока мы знаем явные выражения только для двух коэффициентов - перед $\lambda^{n-1}$ (а именно $-\operatorname{tr} A$ ) и свободного члена (а именно $(-1)^{n} \operatorname{det} A$ ).
Докажем предварительно один результат о симметрических многочленах ${ }^{26}$. Пусть $\sigma_{r}\left(x_{1}, \ldots, x_{n}\right) \in \mathbb{K}\left[x_{1}, \ldots, x_{n}\right], 1 \leq r \leq n$ - элементарные симметрические многочлены, определяемые формулами
$$
\sigma_{r}\left(x_{1}, \ldots, x_{n}\right):=\sum_{1 \leq i_{1}<i_{2}<\ldots<i_{r} \leq n} x_{i_{1}} x_{i_{2}} \ldots x_{i_{r}}
$$

Определим также симметрические многочлены
$$
s_{r}\left(x_{1}, \ldots, x_{n}\right):=x_{1}^{r}+x_{2}^{r}+\ldots+x_{n}^{r}
$$

Лемма 2.36. Для любых $1 \leq k \leq n$ имеет место соотношение
$$
\begin{gather*}
s_{k}\left(x_{1}, \ldots, x_{n}\right)-\sigma_{1}\left(x_{1}, \ldots, x_{n}\right) s_{k-1}\left(x_{1}, \ldots, x_{n}\right)+\ldots+ \\
+(-1)^{k} k \sigma_{k}\left(x_{1}, \ldots, x_{n}\right)=0 \tag{36}
\end{gather*}
$$
${ }^{26}$ По поводу определения и свойств симметрических многочленов см. [15], гл. $3, \S$ в или [32], гл. $6, \S 2$.

Доказательство. Имеет место тождество
$$
\prod_{i=1}^{k}\left(x-x_{i}\right)=x^{k}-\sigma_{1}\left(x_{1}, \ldots, x_{k}\right) x^{k-1}+\ldots+(-1)^{k} \sigma_{k}\left(x_{1}, \ldots, x_{k}\right)
$$

Подставим в него $x=x_{i}, 1 \leq i \leq k$ и просуммируем полученные равенства, получим
$$
\begin{gathered}
0=s_{k}\left(x_{1}, \ldots, x_{k}\right)-\sigma_{1}\left(x_{1}, \ldots, x_{k}\right) s_{k-1}\left(x_{1}, \ldots, x_{k}\right)+\ldots+ \\
+(-1)^{k} k \sigma_{k}\left(x_{1}, \ldots, x_{k}\right)
\end{gathered}
$$

тем самым требуемая формула (36) доказана в случае $k=n$.
Далее воспользуемся индукцией по $l=n-k$. При $l=0$ справедливость тождества установлена. Предположим, что тождество верно для всех $0 \leq l<n-k$, покажем, что тогда оно верно для $n-k$. Многочлен, стоящий в левой части (36), - симметрический многочлен от $x_{1}, \ldots, x_{n}$. Положим в нем $x_{n}=0$. Так как при $r \leq n-1$
$$
\begin{aligned}
\sigma_{r}\left(x_{1}, \ldots, x_{n-1}, 0\right) & =\sigma_{r}\left(x_{1}, \ldots, x_{n-1}\right) \\
s_{r}\left(x_{1}, \ldots x_{n-1}, 0\right) & =s_{r}\left(x_{1}, \ldots x_{n-1}\right)
\end{aligned}
$$

то при $x_{n}=0$ многочлен, стоящий в левой части (36), равен нулю по предположению индукции. Значит, он делится на $x_{n}$, а поскольку он симметрический, и на $\sigma_{n}\left(x_{1}, \ldots, x_{n}\right)$. Так как его степень есть $k<n$, то он равен нулю.
Пользуясь результатом задачи 2.34 , найдем базис, в котором матрица $A$ оператора $\varphi$ верхняя треугольная (предварительно комплексифицировав $V$ в случае поля $\mathbb{R}$ ). Тогда на ее главной диагонали стоят $\lambda_{1}, \ldots, \lambda_{n}$ - собственные значения $\varphi$ (с учетом кратности). По формуле Виета:
$$
\begin{align*}
& \chi_{\varphi}(\lambda)=\prod_{i=1}^{n}\left(\lambda-\lambda_{i}\right)=\lambda^{n}-\sigma_{1}\left(\lambda_{1}, \ldots, \lambda_{n}\right) \lambda^{n-1}+ \\
& +\sigma_{2}\left(\lambda_{1}, \ldots, \lambda_{n}\right) \lambda^{n-2}+\ldots+(-1)^{n} \sigma_{n}\left(\lambda_{1}, \ldots, \lambda_{n}\right), \tag{37}
\end{align*}
$$

где $\sigma_{r}\left(\lambda_{1}, \ldots, \lambda_{n}\right)$ - $r$-й элементарный симметрический многочлен от переменных $\lambda_{1}, \ldots, \lambda_{n}$, который равен
$$
\sigma_{r}\left(\lambda_{1}, \ldots, \lambda_{n}\right)=\sum_{1 \leq i_{1}<\ldots<i_{r} \leq n} \lambda_{i_{1}} \ldots \lambda_{i_{r}}
$$

причем $\operatorname{tr} A=\sum_{i=1}^{n} \lambda_{i}=\sigma_{1}\left(\lambda_{1}, \ldots, \lambda_{n}\right), \operatorname{det} A=\prod_{i=1}^{n} \lambda_{i}==\sigma_{n}\left(\lambda_{1}, \ldots, \lambda_{n}\right)$. Таким образом, нам нужно найти выражения остальных элементарных симметрических многочленов от собственных значений через матрицу $A$.
Поскольку матрица $A$ верхняя треугольная, очевидно равенство
$$
\operatorname{tr}\left(A^{r}\right)=\lambda_{1}^{r}+\ldots+\lambda_{n}^{r}=s_{r}\left(\lambda_{1}, \ldots, \lambda_{n}\right)
$$

Используя это наблюдение и формулу (36), мы можем получить выражения для всех коэффициентов характеристического многочлена (37) через $\operatorname{tr}\left(A^{r}\right), 1 \leq r \leq n$.

Заметим, что числа $\operatorname{tr}\left(A^{r}\right)$ не зависят от базиса в $V$, в котором записана матрица $A$ оператора $\varphi$. Действительно, если $A^{\prime}=C^{-1} A C$, то $\operatorname{tr}\left(A^{\prime r}\right)= \operatorname{tr}\left(C^{-1} A^{r} C\right)=\operatorname{tr}\left(A^{r}\right)$.
Вот несколько первых коэффициентов $\chi_{\varphi}(\lambda)$ :
$$
\begin{gathered}
\sigma_{1}\left(\lambda_{1}, \ldots, \lambda_{n}\right)=\operatorname{tr} A, \quad \sigma_{2}\left(\lambda_{1}, \ldots, \lambda_{n}\right)=\frac{1}{2}\left((\operatorname{tr} A)^{2}-\operatorname{tr}\left(A^{2}\right)\right), \\
\sigma_{3}\left(\lambda_{1}, \ldots, \lambda_{n}\right)=\frac{1}{6}\left((\operatorname{tr} A)^{3}-3 \operatorname{tr}(A) \operatorname{tr}\left(A^{2}\right)+2 \operatorname{tr}\left(A^{3}\right)\right)
\end{gathered}
$$

и т.д. Кстати, определитель $\sigma_{n}\left(\lambda_{1}, \ldots, \lambda_{n}\right)=\operatorname{det} A$ также может быть выражен через $\operatorname{tr}\left(A^{r}\right), 1 \leq r \leq n$.
Из сказанного выше легко получить, например, такой результат (для $\mathbb{K}= \mathbb{C})$ : если $\operatorname{tr} A=\operatorname{tr} A^{2}=\ldots=\operatorname{tr} A^{n}=0$, то матрица $A$ нильпотентна.
Отметим еще, что, согласно основной теореме о симметрических многочленах, произвольный симметрический многочлен $f \in \mathbb{Z}\left[x_{1}, \ldots, x_{n}\right]$ единственным образом представляется в виде многочлена с целыми коэффициентами от элементарных симметрических многочленов $\sigma_{1}\left(x_{1}, \ldots, x_{n}\right), \ldots, \sigma_{n}\left(x_{1}, \ldots, x_{n}\right)$ (то есть подкольцо симметрических многочленов в $\mathbb{Z}\left[x_{1}, \ldots, x_{n}\right]$ само есть кольцо многочленов от $n$ переменных $\mathbb{Z}\left[\sigma_{1}, \ldots, \sigma_{n}\right]$ ). В частности, это верно для $s_{r}\left(x_{1}, \ldots, x_{n}\right) \in \mathbb{Z}\left[x_{1}, \ldots, x_{n}\right], 1 \leq r \leq n$. В свою очередь, многочлены $\sigma_{r}\left(x_{1}, \ldots, x_{n}\right), 1 \leq r \leq n$ тоже могут быть представлены как многочлены от $s_{1}\left(x_{1}, \ldots, x_{n}\right), \ldots, s_{n}\left(x_{1}, \ldots, x_{n}\right)$, но только уже с рациональными коэффициентами (то есть подкольцо симметрических многочленов в кольце $\mathbb{Q}\left[x_{1}, \ldots, x_{n}\right]$ есть $\mathbb{Q}\left[\sigma_{1}, \ldots, \sigma_{n}\right]=\mathbb{Q}\left[s_{1}, \ldots, s_{n}\right]$ ) - отсюда знаменатели в приведенных выше формулах.

\section*{2.4. Жорданова нормальная форма}

Даже в случае векторного пространства $V$ над алгебраически замкнутым полем $\mathbb{K}$ не для всякого оператора $\varphi: V \rightarrow V$ существует базис в $V$, состоящий из собственных векторов оператора $\varphi$. Простейшим примером является оператор на двумерном пространстве с матрицей $A=\left(\begin{array}{ll}0 & 1 \\ 0 & 0\end{array}\right)$. Его единственным собственным значением является 0 , и соответствующее собственное подпространство, совпадающее с ядром, есть линейная оболочка вектора $(1,0)^{T}$. Таким образом, оператор с такой матрицей не приводится к диагональному виду, иными словами, не существует обратимой матрицы $C \in \mathrm{GL}_{2}(\mathbb{K})$ такой, что $C^{-1} A C=\Lambda$, где матрица $\Lambda$ диагональна.

Определение 2.37. Жордановой матрицей называется блочно-диагональная матрица с жордановыми клетками $J_{k}(\lambda)$ (вообще говоря, с разными собственными значениями $\lambda$ ) в качестве диагональных блоков. Жордановым базисом для оператора $\varphi: V \rightarrow \rightarrow V$ называется такой базис в $V$, в котором $\varphi$ имеет жорданову матрицу. Последняя называется жордановой нормальной формой оператора $\varphi$.
Теорема 2.38. Для любого линейного оператора $\varphi: V \rightarrow V$ на конечномерном пространстве $V$ над полем $\mathbb{C}$ существует жорданов базис. Жорданова нормальная форма оператора $\varphi$ определена однозначно с точностью до перестановки жордановых клеток.

Заметим, что диагональный вид - частный случай жордановой нормальной формы, когда все жордановы клетки имеют размер 1.

Задача 2.39. Напишите возможные ЖНФ оператора $\varphi$, зная его характеристический $\chi_{\varphi}(t)=t^{4}(t-1)^{3}$ и минимальный $m_{\varphi}(t)=t^{2}(t-1)^{2}$ многочлены.

Решение. Характеристический многочлен показывает, что $\varphi$ имеет собственные значения 0 и 1 , причем сумма порядков отвечающих им клеток равна соответственно 4 и 3 . Из минимального многочлена мы получаем максимальный порядок жордановых клеток: для обоих собственных значений он равен 2. Для собственного значения 1 это оставляет единственную возможность $2+1$, а для собственного значения 0 - два варианта $2+2$ или $2+1+1$.
Если оператор $\varphi$ нильпотентен, то все его жордановы клетки отвечают $\lambda=$ 0 , и обратно (см. задачу 2.16 и комментарий к ней).

Задача 2.40. Доказать существование жорданова базиса для нильпотентного оператора $\varphi: V \rightarrow V$.

В более развернутом виде нам нужно доказать следующее. Если $\varphi: V \rightarrow V$ - линейный оператор на конечномерном векторном пространстве $V$ такой, что $\varphi^{m}=0$ для некоторого $m \geq 1$, то в $V$ существует такой набор векторов $\mathbf{v}_{1}, \ldots, \mathbf{v}_{r}$ и отвечающий им набор натуральных чисел $k_{1}, \ldots, k_{r}$, что система векторов
$$
\begin{gathered}
\varphi^{k_{1}-1}\left(\mathbf{v}_{1}\right), \varphi^{k_{1}-2}\left(\mathbf{v}_{1}\right), \ldots, \varphi\left(\mathbf{v}_{1}\right), \mathbf{v}_{1}, \ldots, \varphi^{k_{r}-1}\left(\mathbf{v}_{r}\right), \\
\varphi^{k_{r}-2}\left(\mathbf{v}_{r}\right), \ldots, \varphi\left(\mathbf{v}_{r}\right), \mathbf{v}_{r}
\end{gathered}
$$

где $\varphi^{k_{i}}\left(\mathbf{v}_{i}\right)=\mathbf{0}$ для всех $1 \leq i \leq r$, является базисом в $V^{27}$. Легко видеть, что это - жорданов базис для $\varphi$, и обратно, любой жорданов базис имеет такой вид.
Данную задачу можно решить разными способами, например, их можно найти в [15] и [33]. Ниже приведено доказательство, основанное на работе [53].
Решение задачи 2.40. Воспользуемся индукцией по $\operatorname{dim} V$. Если $\operatorname{dim} V=$ 1 , то $\varphi=0$ и требуемый результат, очевидно, верен. Для доказательства шага индукции предположим, что $\operatorname{dim} V \geq 2$. Ясно, что $\varphi(V):=\operatorname{im} \varphi \subset V$, но при этом $\varphi(V) \neq V$, ибо тогда $\varphi^{m}(V)=\varphi^{m-1}(V)=\ldots=\varphi(V)=V$, что противоречит равенству $\varphi^{m}=0$. Кроме того, в случае $\varphi=0$ требуемый результат тривиален. Таким образом, мы можем предположить, что
$$
0 \nsubseteq \varphi(V) \subsetneq V
$$

По предположению индукции (примененному к пространству $U:=\varphi(V)$ и ограничению на него оператора $\varphi$ ) в $U$ существует набор векторов $\mathbf{u}_{1}, \ldots, \mathbf{u}_{l}$ такой, что
$$
\begin{equation*}
\mathbf{u}_{1}, \varphi\left(\mathbf{u}_{1}\right), \ldots, \varphi^{l_{1}-1}\left(\mathbf{u}_{1}\right), \ldots, \mathbf{u}_{s}, \varphi\left(\mathbf{u}_{s}\right), \ldots, \varphi^{l_{s}-1}\left(\mathbf{u}_{s}\right) \tag{38}
\end{equation*}
$$

\footnotetext{
${ }^{27}$ Заметим, что порядок нильпотентности $\varphi$ тогда равен $\max _{1 \leq i \leq r}\left(k_{i}\right)$.
}
- базис в $U$ и $\varphi^{l_{i}}\left(\mathbf{u}_{i}\right)=\mathbf{0}$ для $1 \leq i \leq s$.

Для $1 \leq i \leq s$ выберем такие векторы $\mathbf{v}_{i} \in V$, что $\varphi\left(\mathbf{v}_{i}\right)=\mathbf{u}_{i}$ (такие $\mathbf{v}_{i}$ существуют, поскольку $\mathbf{u}_{i} \in \varphi(V)$ ). Подпространство $\operatorname{ker} \varphi \subset V$ содержит линейно независимые векторы $\varphi^{l_{1}-1}\left(\mathbf{u}_{1}\right), \ldots, \varphi^{l_{s}-1}\left(\mathbf{u}_{s}\right)$. Дополним эти векторы до базиса в $\operatorname{ker} \varphi$ векторами $\mathbf{w}_{1}, \ldots, \mathbf{w}_{p}$. Мы докажем, что
$$
\begin{equation*}
\mathbf{v}_{1}, \varphi\left(\mathbf{v}_{1}\right), \ldots, \varphi^{l_{1}}\left(\mathbf{v}_{1}\right), \ldots, \mathbf{v}_{s}, \varphi\left(\mathbf{v}_{s}\right), \ldots, \varphi^{l_{s}}\left(\mathbf{v}_{s}\right), \mathbf{w}_{1}, \ldots, \mathbf{w}_{p} \tag{39}
\end{equation*}
$$
- требуемый (с точностью до перестановки векторов) базис в $V$.

Для доказательства линейной независимости системы (39) применим $\varphi$ к произвольной линейной комбинации указанных векторов, равной нулю. Тогда в силу линейной независимости системы (38) получим, что коэффициенты перед векторами
$$
\mathbf{v}_{1}, \ldots, \varphi^{l_{1}-1}\left(\mathbf{v}_{1}\right), \ldots, \mathbf{v}_{s}, \ldots, \varphi^{l_{s}-1}\left(\mathbf{v}_{s}\right)
$$

равны нулю. Теперь линейная независимость (39) следует из того, что
$$
\varphi^{l_{1}}\left(\mathbf{v}_{1}\right), \ldots, \varphi^{l_{s}}\left(\mathbf{v}_{s}\right), \mathbf{w}_{1}, \ldots, \mathbf{w}_{p}
$$
- базис в $\operatorname{ker} \varphi$.

Проверим теперь, что число векторов в (39) равно $\operatorname{dim} V$. Действительно, из (38) $\operatorname{dimim} \varphi=l_{1}+\ldots+l_{s} ;$ кроме того, $\operatorname{dim} \operatorname{ker} \varphi==s+p$. Тогда
$$
\operatorname{dim} V=\operatorname{dimim} \varphi+\operatorname{dim} \operatorname{ker} \varphi=\left(l_{1}+1\right) \ldots+\left(l_{s}+1\right)+p,
$$

а это - в точности число элементов в системе (39).
Задача 2.41. Пусть $V$ - конечномерное векторное пространство над полем $\mathbb{C}, \varphi: V \rightarrow V$ - линейный оператор такой, что $\varphi^{k}==\operatorname{id}_{V}$ для некоторого $k \in \mathbb{N}$. Доказать, что $\varphi$ диагонализируем.

Решение. 1-й способ. Пусть $J$ - жорданова нормальная форма оператора $\varphi$. Она определена однозначно с точностью до перестановки клеток. Пусть она не является диагональной, это означает, что хотя бы одна клетка $J_{r}(\lambda)$ имеет размер $r>1$. Заметим еще, что $\lambda \neq 0$, поскольку $\varphi$ обратим.
Заметим теперь, что если $r \geq 2$, то ни в какой натуральной степени $J_{r}(\lambda)$ не может быть диагональной матрицей. Действительно, $J_{r}(\lambda)=\lambda E+J_{r}$ (где $J_{r}:=J_{r}(0)$ ) и матрицы $E$ и $J_{r}$ коммутируют, поэтому по формуле бинома имеем
$$
J_{r}(\lambda)^{k}=\lambda^{k} E+k \lambda^{k-1} J_{r}+\frac{k(k-1)}{2} \lambda^{k-2} J_{r}^{2}+\ldots+J_{r}^{k}
$$
(если $k \geq r$, то несколько последних слагаемых равны 0 ). С другой стороны, если $\varphi^{k}=\operatorname{id}_{V}$, то $J^{k}=E$, поскольку $\operatorname{id}_{V}$ имеет единичную матрицу $E$ в любом базисе. Противоречие.
2-й способ. Многочлен $f(\lambda)=\lambda^{k}-1$ является аннулирующим для оператора $\varphi$, причем все его корни простые (то есть не кратные), так как он взаимно прост с производной $f^{\prime}(\lambda)=k \lambda^{k-1}$. Следовательно, минимальный многочлен, будучи его делителем, тоже не имеет кратных корней. В то же время легко видеть, что кратность $r_{i}$ корня $\lambda_{i}$ минимального многочлена

линейного оператора $\psi$ над полем $\mathbb{C}$ равна максимальному размеру жордановой клетки, отвечающей собственному значению $\lambda_{i}$. Значит, в жордановой форме оператора $\varphi$ все клетки размера 1.
Заметим, что в случае даже алгебраически замкнутого поля положительной характеристики результат предыдущей задачи неверен: контрпример дает матрица
$$
\left(\begin{array}{ll}
1 & 1 \\
0 & 1
\end{array}\right)
$$

чья $p$-я степень над полем характеристики $p$ равна единичной матрице.
Две квадратные матрицы $A, B \in \operatorname{Mat}_{n}(\mathbb{K})$ называются подобными, если найдется обратимая матрица $C \in \mathrm{GL}_{n}(\mathbb{K})$ такая, что $B=C^{-1} A C$ (см. примеры 0.14 и 4) из § 2.5.). Подобие - отношение эквивалентности на множестве квадратных матриц данного порядка. Другое его описание: две матрицы порядка $n$ подобны, если они являются матрицами одного и того же линейного оператора на $n$-мерном пространстве $V$ над полем $\mathbb{K}$.

Задача 2.42. Доказать, что любая квадратная матрица над полем $\mathbb{C}$ подобна своей транспонированной.

Решение. Теорема о ЖНФ утверждает, что если поле $\mathbb{K}$ алгебраически замкнуто (например, $\mathbb{K}=\mathbb{C}$ ), то любая матрица $A \in \operatorname{Mat}_{n}(\mathbb{K})$ подобна жордановой матрице $J_{A}$, причем для каждого корня $\lambda$ характеристического многочлена $\chi_{A}(t)$ число и размер жордановых клеток в $J_{A}$ однозначно определяются самой матрицей $A$ (другими словами, $J_{A}$ определена однозначно с точностью до перестановок жордановых клеток).
Из того, что $A$ подобна $J_{A}$, следует, что $A^{T}$ подобна $J_{A}^{T}$. Поскольку подобие является отношением эквивалентности, для решения задачи достаточно доказать, что $J_{A}$ подобна $J_{A}^{T}$. Для этого, в свою очередь, достаточно установить, что жорданова клетка $J_{k}(\lambda)$ подобна $J_{k}(\lambda)^{T}$. Так как матрица $J_{k}(\lambda)^{T}$ получается из $J_{k}(\lambda)$ центральной симметрией, то является матрицей того же преобразования, записанного в базисе, перенумерованном "задом наперед", откуда следует подобие указанных матриц.
Для полноты приведем другое доказательство подобия матриц $J_{k}(\lambda)$ и $J_{k}(\lambda)^{T}$. Из того, что $J_{k}(\lambda)=\lambda E++J_{k}, J_{k}(\lambda)^{T}==\lambda E+J_{k}^{T}$ (где $J_{k}:=J_{k}(0)$ ), легко следует, что достаточно установить подобие матриц $J_{k}$ и $J_{k}^{T}$. (Действительно, если $J_{k}^{T}=C^{-1} J_{k} C$, то $J_{k}(\lambda)^{T}=\lambda E+J_{k}^{T}=C^{-1}\left(\lambda E+J_{k}\right) C= =C^{-1} J_{k}(\lambda) C$ ). Так как $\operatorname{rk}\left(\left(J_{k}^{T}\right)^{m}\right)=\operatorname{rk}\left(J_{k}^{m}\right)^{T}=\operatorname{rk}\left(J_{k}^{m}\right) \forall m \in \mathbb{N}$, то жорданова нормальная форма $J_{k}^{T}$ есть $J_{k}$, откуда следует требуемое.
Другой, еще более короткий, способ решения основан на том, что $\chi_{A}(t)= \chi_{A^{T}}(t)$ и для любого корня $\lambda$ характеристического многочлена и для любого натурального $m$
$$
\operatorname{rk}\left((A-\lambda E)^{m}\right)=\operatorname{rk}\left((A-\lambda E)^{m}\right)^{T}=\operatorname{rk}\left(\left(A^{T}-\lambda E\right)^{m}\right),
$$

откуда следует, что жордановы нормальные формы матриц $A$ и $A^{T}$ совпадают, поскольку число и размер жордановых клеток для данного $\lambda$ полностью определяются набором указанных рангов.

Задача 2.43. Найти жорданову нормальную форму и жорданов базис для оператора, имеющего матрицу $J_{n}^{2}$.

Решение. Заметим, что матрицу $J_{n}$ имеет оператор $\frac{d}{d x}$ на пространстве $\mathbb{R}[x]_{n-1}$ в базисе $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$, где $\mathbf{e}_{k}:=\frac{x^{k-1}}{(k-1)!}$. Значит, матрицу $J_{n}^{2}$ в том же базисе имеет оператор $\varphi:=\frac{d^{2}}{d x^{2}}$. Так как $\operatorname{dim} \operatorname{ker} \varphi=2$, то ЖНФ оператора $\varphi$ состоит из двух клеток, причем обе с собственным значением 0 . Для $n=2 m$ имеем две жордановы цепочки
$$
\begin{gathered}
\mathbf{e}_{n} \mapsto \mathbf{e}_{n-2} \mapsto \ldots \mapsto \mathbf{e}_{2} \mapsto \mathbf{0}, \\
\mathbf{e}_{n-1} \mapsto \mathbf{e}_{n-3} \mapsto \ldots \mapsto \mathbf{e}_{1} \mapsto \mathbf{0},
\end{gathered}
$$

а для $n=2 m+1$ - тоже две жордановы цепочки
$$
\begin{gathered}
\mathbf{e}_{n} \mapsto \mathbf{e}_{n-2} \mapsto \ldots \mapsto \mathbf{e}_{1} \mapsto \mathbf{0}, \\
\mathbf{e}_{n-1} \mapsto \mathbf{e}_{n-3} \mapsto \ldots \mapsto \mathbf{e}_{2} \mapsto \mathbf{0} .
\end{gathered}
$$

Значит, для четного $n$ имеем две клетки порядка $n / 2$, я для нечетного $n$ клетки порядков $(n+1) / 2$ и $(n-1) / 2$.

Задача 2.44. Найти жорданову нормальную форму и жорданов базис оператора $D=\frac{\partial}{\partial x}+\frac{\partial}{\partial y}$ на пространстве $\mathbb{R}[x, y]_{4}$ многочленов степени не выше 4 от переменных $x, y$.

Решение. Во-первых, заметим, что оператор $D$ нильпотентен $\Rightarrow$ все жордановы клетки будут иметь собственное значение 0 . Проще всего решать эту задачу, сделав замену переменных $u:=:=\frac{x+y}{2}, v:=\frac{x-y}{2}$. Тогда $D=\frac{\partial}{\partial u}$; кроме того, $\mathbb{R}[x, y]_{4}=\mathbb{R}[u, v]_{4}$. Тогда имеем жордановы цепочки (вертикальная цепочка - набор базисных векторов, отвечающих одной жордановой клетке):
![](https://cdn.mathpix.com/cropped/2025_10_20_7581694eb1917f03fa57g-37.jpg?height=409&width=381&top_left_y=1186&top_left_x=512)

Горизонтальные строки отвечают подпространствам $V_{k}$ однородных многочленов в $\mathbb{R}[u, v]_{4}$ степени $k, 0 \leq k \leq 4$, при этом $\operatorname{dim} V_{k}=k+1$. Видно, что ограничение $\left.D\right|_{V_{k}}$ отображает $V_{k}$ на $V_{k-1}$, причем $\left.\operatorname{dim} \operatorname{ker} D\right|_{V_{k}}=1$. Таким образом, в жордановой нормальной форме $D$ имеется по одной жордановой клетке размера от 1 до 5 , а жорданов базис получается, например, если выбрать базис в $\mathbb{R}[x, y]_{4}$ из мономов в диаграмме выше, упорядоченных снизу вверх в каждой цепочке (сначала - собственный вектор, потом корневой

вектор высоты $2, \ldots$ ), а сами цепочки - слева направо (это будет отвечать упорядочению жордановых клеток по убыванию). То есть жорданова нормальная форма тогда имеет вид
$$
\left(\begin{array}{ccccc}
J_{5} & & & & \\
& J_{4} & & & \\
& & J_{3} & & \\
& & & J_{2} & \\
& & & & J_{1}
\end{array}\right)
$$

Задача 2.45. [35] Пусть $L$ - конечномерное пространство комплекснозначных дифференцируемых функций вещественной переменной $x$, обладающее тем свойством, что если $f \in L$, то $\frac{d f}{d x} \in L$. Доказать, что существуют такие комплексные числа $\lambda_{1}, \ldots, \lambda_{s}$ и целые числа $r_{1}, \ldots, r_{s} \geq 1$, что $L=\oplus L_{i}$, где $L_{i}$ - пространство функций вида $e^{\lambda_{i} x} P(x)$, где $P(x)$ - произвольный многочлен степени $\leq r_{i}-1$.

Решение. Так как пространство $L$ инвариантно относительно $\frac{d}{d x}$, то этот оператор можно ограничить на $L$ (причем поскольку $\frac{d}{d x}$ к функциям из $L$ можно применять неограниченное число раз, все функции из $L$ бесконечно дифференцируемы). Идея заключается в том, чтобы рассмотреть жорданов базис для оператора $\frac{d}{d x}$ на $L$ и последовательно вычислить вид входящих в него функций, начиная с нижней строки его диаграммы (образованной собственными векторами).
А именно, предположим что линейный оператор $\frac{d}{d x}$ на комплексном пространстве $L$ имеет жорданову форму с клетками, отвечающими собственным значениям $\lambda_{1}, \ldots, \lambda_{s}$ размеров $r_{1}, \ldots, r_{s}$ и рассмотрим соответствующие жордановы цепочки
$$
\begin{aligned}
& \mathbf{e}_{r_{1}}^{1} \xrightarrow{\frac{d}{d x}-\lambda_{1} \text { id }} \mathbf{e}_{r_{1}-1}^{1} \rightarrow \ldots \rightarrow \mathbf{e}_{1}^{1} \xrightarrow{\frac{d}{d x}-\lambda_{1} \text { id }} 0 \\
& \mathbf{e}_{r_{2}}^{2} \xrightarrow{\frac{d}{d x}-\lambda_{2} \text { id }} \mathbf{e}_{r_{2}-1}^{2} \rightarrow \ldots \rightarrow \mathbf{e}_{1}^{2} \xrightarrow{\frac{d}{d x}-\lambda_{2} \text { id }} 0 \\
& \text {.................................................... } \\
& \mathbf{e}_{r_{s}}^{s} \xrightarrow{\frac{d}{d x}-\lambda_{s} \mathrm{id}} \mathbf{e}_{r_{s}-1}^{s} \rightarrow \ldots \rightarrow \mathbf{e}_{1}^{s} \xrightarrow{\frac{d}{d x}-\lambda_{s} \mathrm{id}} 0
\end{aligned}
$$

Тогда можно положить $\mathbf{e}_{1}^{i}=e^{\lambda_{i} x}$. Действительно, это - ненулевое (поскольку собственный вектор) решение дифференциального уравнения $\frac{d f}{d x}=\lambda_{i} f$, которое определено однозначно с точностью до умножения на ненулевое число. (В самом деле, если $f$ - решение указанного уравнения, то дифференцирование выражения $f e^{-\lambda_{i} x}$ дает 0 , то есть это - некоторая константа). В частности, мы видим, что $\lambda_{i}, 1 \leq i \leq s$, попарно различны. В следующей строчке стоят решения уравнений $\frac{d f}{d x}-\lambda_{i} f=e^{\lambda_{i} x}$ (для тех $i$, для которых $r_{i}>1$ ). Произвольное решение линейного неоднородного уравнения является суммой его частного решения и общего решения соответствующего однородного уравнения. Легко видеть, что в качестве частного решения подходит $\frac{x}{1!} e^{\lambda_{i} x}$. Поэтому положим $\mathbf{e}_{2}^{i}=\frac{x}{1!} e^{\lambda_{i} x}$ для $i$ таких, что $r_{i}>1$.
Далее положим по индукции $\mathbf{e}_{k}^{i}=\frac{x^{k-1}}{(k-1)!} e^{\lambda_{i} x}$ при $1 \leq k<r_{i}$. Тогда $\frac{x^{k}}{k!} e^{\lambda_{i} x}$ является решением уравнения $\frac{d f}{d x}-\lambda_{i} f=\mathbf{e}_{k}^{i}$, что доказывает индуктивное

предположение. Очевидно, что линейная оболочка векторов $\mathbf{e}_{1}^{i}, \ldots, \mathbf{e}_{r_{i}}^{i}$ совпадает с пространством, состоящим из всех функций $P(x) e^{\lambda_{i} x}$, где $\operatorname{deg} P(x) \leq r_{i}-1$.

Комментарий. Предыдущая задача объясняет роль квазимногочленов (то есть функций вида $P(x) e^{\lambda x}$, где $P(x)$-многочлен) в теории обыкновенных линейных дифференциальных уравнений с постоянными коэффициентами. Действительно, если $y(x)$ - функция вещественной переменной $x$, являющаяся решением однородного дифференциального уравнения
$$
\begin{equation*}
\frac{d^{n} y}{d x^{n}}+\sum_{i=0}^{n-1} a_{i} \frac{d^{i} y}{d x^{i}}=0, \quad a_{i} \in \mathbb{C} \tag{40}
\end{equation*}
$$

то $y(x)$ как минимум $n$ раз дифференцируема и индукция, использующая выражение (40) $n$-й производной через производные меньшего порядка показывает, что на самом деле она бесконечно дифференцируема, а также что линейная оболочка функций $\frac{d^{i} y}{d x^{i}}, i \geq 0$, конечномерна и оператор $\frac{d}{d x}$ переводит ее в себя. Из этого вытекает, что $y(x)$ представляется в виде $\sum P_{i}(x) e^{\lambda_{i} x}$, где $P_{i}(x)$ - многочлены.
По уравнению (40) определим многочлен $f(t):=t^{n}+\sum a_{i} t^{i}$. Очевидно, что $f(t)$ - аннулирующий многочлен оператора $\frac{d}{d x}$ на пространстве $L$ всех решений уравнения (40).

Задача 2.46. Доказать, что $f(t)$ является характеристическим и минимальным многочленом оператора $\frac{d}{d x}$ на пространстве $L$ всех решений уравнения (40). В частности, $\operatorname{dim} L=n$ и $\lambda_{i}$ - его корни кратностей $r_{i}, \sum_{i} r_{i}=n$.

Решение. Если $L$ бесконечномерно, то тем не менее произвольный его элемент принадлежит конечномерному $\frac{d}{d x}$-инвариантному подпространству. Любое такое подпространство представляется в виде прямой суммы корневых подпространств оператора $\frac{d}{d x}$, в которых (как мы видели в предыдущей задаче) квазиодночлены $\left\{e^{\lambda x}, x e^{\lambda x}, \ldots, \frac{x^{k}}{k!} e^{\lambda x}\right\}$ (для некоторого $k$ ) образуют базис. Подставляя $e^{\lambda x}$ в (40) получаем, что $\lambda$ - корень $f(t)$.
Пусть $f(t)=\prod_{i=1}^{s}\left(t-\lambda_{i}\right)^{r_{i}}$, причем $\lambda_{i} \neq \lambda_{j}$ при $i \neq j$. Поскольку оператор $\frac{d}{d x}-\lambda_{i} \operatorname{id}_{L}$ понижает степень $\frac{x^{k}}{k!} e^{\lambda_{i} x}, k \geq 1$ на 1 и определяет изоморфизм при ограничении на пространство квазимногочленов с $\lambda \neq \lambda_{i}$ мы видим, что для каждого корня $\lambda_{i}$ многочлена $f(t)$ в $L$ имеется $r_{i}$-мерное корневое подпространство оператора $\frac{d}{d x}$ и все $L$ является их прямой суммой. В частности, многочлен $f(t)$ является минимальным многочленом оператора $\frac{d}{d x}$.
Комментарий. Таким образом, пространство решений уравнения (40) является линейной оболочкой квазимногочленов
$$
P_{i}(x) e^{\lambda_{i} x}, \operatorname{deg} P_{i}(x) \leq r_{i}-1
$$

Задача 2.47. Найти все решения дифференциального уравнения
$$
y^{\prime \prime \prime}+2 y^{\prime \prime}-4 y^{\prime}-8 y=0
$$

Решение. Характеристическое уравнение
$$
t^{3}+2 t^{2}-4 t-8=(t+2)\left(t^{2}-4\right)=0
$$

Его корни $\lambda_{1}=2$ кратности 1 и $\lambda_{2}=-2$ кратности 2 . Таким образом, функции $e^{2 x}, e^{-2 x}, x e^{-2 x}$ образуют базис в пространстве решений.

\section*{2.5. Ещё об отношениях эквивалентности}

Изученные нами выше задачи делают естественным рассмотрение еще нескольких примеров отношений эквивалентности, возникающих в линейной алгебре. Легкая проверка того, что это - действительно отношения эквивалентности, оставляется читателю.
1) Пусть $X=\operatorname{Mat}_{m \times n}(\mathbb{K})$, два элемента $A, A^{\prime} \in X$ эквивалентны $\Leftrightarrow \exists D \in \mathrm{GL}_{m}(\mathbb{K}), C \in \mathrm{GL}_{n}(\mathbb{K})$ такие, что $A^{\prime}=D A C^{-1}$. Другими словами, две матрицы $A, A^{\prime}$ эквивалентны $\Leftrightarrow$ они являются матрицами одного и того же линейного отображения $\mathbb{K}^{n} \rightarrow \mathbb{K}^{m}$ в разных базисах.
Данное отношение эквивалентности имеет единственный инвариант ${ }^{28}$ - ранг матрицы (= размерность образа линейного отображения). Более того, две $m \times n$-матрицы $A, A^{\prime}$ с элементами из поля $\mathbb{K}$ эквивалентны $\Leftrightarrow$ их ранги равны. Значит, классов эквивалентности всего $\min (m, n)+1$ штук. Канонический представитель класса, отвечающего $r, 0 \leq r \leq \min (m, n)$, - матрица, имеющая вид $\left(\begin{array}{cc}E_{r} & 0 \\ 0 & 0\end{array}\right)$.
1') Пусть $X=\operatorname{Mat}_{m \times n}(\mathbb{K})$, два элемента $A, A^{\prime} \in X$ эквивалентны $\Leftrightarrow$ существует последовательность элементарных преобразований строк и столбцов, превращающая $A$ в $A^{\prime}$. Данное отношение эквивалентности совпадает с отношением п. 1).
2) Пусть $X=\operatorname{Mat}_{m \times n}(\mathbb{R})$, два элемента $A, A^{\prime} \in X$ эквивалентны тогда и только тогда, когда существуют ортогональные матрицы $D \in \mathrm{O}(m), C \in \mathrm{O}(n)^{29}$ такие, что $A^{\prime}=D A C^{T}$. Другими словами, две матрицы $A, A^{\prime}$ эквивалентны, если и только если они являются матрицами одного и того же линейного отображения $\mathbb{R}^{n} \rightarrow \mathbb{R}^{m}$ в разных ортонормированных базисах.
Это отношение более тонкое, чем в пункте 1), поэтому неудивительно, что появляются дополнительные инварианты. Любая матрица $A \in X$ представляется в виде (ср. (52)) $A=U \Lambda V$, где $U$ и $V$ - ортогональные матрицы порядков $m$ и $n$ соответственно, а $\Lambda=\left(\begin{array}{cc}\Lambda_{r} & 0 \\ 0 & 0\end{array}\right) \in X$, где $\Lambda_{r}=\operatorname{diag}\left(\sigma_{1}, \ldots, \sigma_{r}\right)$, причем все $\sigma_{i}>0$. По существу, это аналог рассмотренного выше сингулярного разложения, но только не для операторов, а для линейных отображений между евклидовыми пространствами. Классы эквивалентности взаимно однозначно соответствуют наборам вещественных чисел ( $\sigma_{1}, \ldots, \sigma_{r}$ ) при условии $\sigma_{1} \geq \sigma_{2} \geq \ldots \geq \sigma_{r}$.

\footnotetext{
${ }^{28}$ Инвариант - функция на $X$, постоянная на классах эквивалентности.
${ }^{29}$ Напомним, что $\mathrm{O}(n)$ обозначает группу ортогональных матриц порядка $n$, то есть вещественных матриц таких, что $C^{T} C=E$.
}
3) Пусть $X=\operatorname{Mat}_{m \times n}(\mathbb{K})$, два элемента $A, A^{\prime} \in X$ эквивалентны $\Leftrightarrow \exists D \in \mathrm{GL}_{m}(\mathbb{K})$ такая, что $A^{\prime}=D A$. Данное отношение эквивалентности совпадает со следующим, более знакомым по теории систем линейных уравнений.
3') Пусть $X=\operatorname{Mat}_{m \times n}(\mathbb{K})$, два элемента $A, A^{\prime} \in X$ эквивалентны $\Leftrightarrow$ существует последовательность элементарных преобразований строк, превращающая $A$ в $A^{\prime}$. Другими словами, матрицы $A, A^{\prime}$ эквивалентны $\Leftrightarrow$ они задают эквивалентные системы из $m$ линейных однородных уравнений.
Ранг является инвариантом данного отношения. Более того, каждый класс эквивалентности содержит единственную строгую ступенчатую матрицу, то есть ступенчатую матрицу, в которой главным переменным отвечает единичная подматрица. Существует также биекция между классами эквивалентности и линейными подпространствами в $\mathbb{K}^{n}$, которые могут быть заданы системой из не более чем $m$ уравнений. Если ввести подмножество $X_{r}$ в $X$, состоящее из матриц ранга $r, 0 \leq r \leq \min (m, n)$, то классы эквивалентности элементов $X_{r}$ будут отвечать множеству, состоящему из всех $k:=n-r$-мерных подпространств в $\mathbb{K}^{n}$, то есть множеству точек грассманиана $\operatorname{Gr}(k, n)$ над полем $\mathbb{K}$. Подробнее см. [19], гл. $3, \S 8$.
4) Пусть $X=\operatorname{Mat}_{n}(\mathbb{C})$, два элемента $A, A^{\prime} \in X$ эквивалентны $\Leftrightarrow \exists C \in \mathrm{GL}_{n}(\mathbb{C})$ такая, что $A^{\prime}=C A C^{-1}$. Другими словами, две матрицы $A, A^{\prime}$ эквивалентны $\Leftrightarrow$ они являются матрицами одного и того же линейного оператора $\mathbb{C}^{n} \rightarrow \mathbb{C}^{n}$ в разных базисах.
Инварианты: ранг, характеристический многочлен (в частности, след и определитель). Две матрицы эквивалентны $\Leftrightarrow$ они имеют одинаковую жорданову нормальную форму (с точностью до перестановки жордановых клеток). Классов столько же, сколько различных жордановых нормальных форм для матриц порядка $n$ (мы не различаем жордановы формы, отличающиеся только перестановкой клеток). В частности, если $n \neq 0$, то классы эквивалентности образуют континуальное множество.
5) Пусть $X=\operatorname{Sym}_{n}(\mathbb{R})$ - подпространство симметрических матриц в $\operatorname{Mat}_{n}(\mathbb{R})$ (такая матрица определяет билинейную симметричную форму); два элемента $A, A^{\prime} \in X$ эквивалентны, если существует такая обратимая матрица $C \in \mathrm{GL}_{n}(\mathbb{R})$, что $A^{\prime}==C A C^{T}$. Другими словами, две матрицы эквивалентны $\Leftrightarrow$ они являются матрицами одной и той же билинейной симметричной формы в разных базисах. Канонический представитель класса диагональная матрица с числами $1,-1$ и 0 на главной диагонали (таким образом, классов - конечное число). Инвариант - сигнатура ( $r_{+}, r_{-}, r_{0}$ ).
6) Пусть $X$ - снова подпространство $\operatorname{Sym}_{n}(\mathbb{R})$ симметрических матриц в $\operatorname{Mat}_{n}(\mathbb{R})$ (теперь интерпретируем такую матрицу как матрицу самосопряженного оператора в ортонормированном базисе); два элемента $A, A^{\prime} \in X$ эквивалентны $\Leftrightarrow \exists C \in \mathrm{O}(n)$ такая, что $A^{\prime}=C A C^{T}$. Другими словами, две такие матрицы эквивалентны $\Leftrightarrow$ они являются матрицами одного и того же самосопряженного оператора в разных ортонормированных базисах. Инвариантом является характеристический многочлен. Канонический вид: диагональная матрица с вещественными числами на главной диагонали (набор собственных значений определен однозначно с точностью до перестановки).
Рассмотренные выше примеры 1) - 6) отношений эквивалентности возникают из разбиений множеств с заданным действием групп на орбиты (детали оставляем читателю).

\section*{3 Евклидовы и эрмитовы пространства}

\section*{3.1. Билинейные и квадратичные функции}

Определение 3.1. Квадратичной формой $q$ на векторном пространстве $V$ над полем $\mathbb{K}$ называется отображение $q: V \rightarrow \mathbb{K}$, для которого существует билинейная форма $h: V \times V \rightarrow \mathbb{K}$ со свойством
$$
q(\mathbf{v})=h(\mathbf{v}, \mathbf{v}) \quad \forall \mathbf{v} \in V .
$$

Если характеристика поля $\mathbb{K}$ не равна 2 , то для всякой квадратичной формы $q$ существует единственная симметричная билинейная форма $g$ со свойством $q(\mathbf{v})=g(\mathbf{v}, \mathbf{v})$, называемая поляризацией $q$. Нетрудно показать, что поляризация может быть найдена по формуле
$$
\begin{equation*}
g(\mathbf{v}, \mathbf{w})=1 / 2[q(\mathbf{v}+\mathbf{w})-q(\mathbf{v})-q(\mathbf{w})] \quad \forall \mathbf{v}, \mathbf{w} \in V . \tag{41}
\end{equation*}
$$

В произвольном базисе квадратичная форма задается однородным многочленом второй степени от координат векторов. Обратно, всякий такой многочлен является выражением некоторой квадратичной формы в заданном базисе.

Задача 3.2. Убедитесь, что функция $A \mapsto \operatorname{det} A$ является квадратичной формой на пространстве $\operatorname{Mat}_{2}(\mathbb{R})$, и покажите, что ее поляризация равна $\widetilde{\operatorname{det}}(A, B):=\operatorname{tr}(A \widehat{B}) / 2$, где $\widehat{B}$ - присоединенная к $B$ матрица ${ }^{30}$. Какова сигнатура этой формы?

Решение. По определению, $\operatorname{det} A=a_{11} a_{22}-a_{12} a_{21}$, последнее выражение - однородный многочлен второй степени от матричных элементов $a_{i j}$, то есть от координат матрицы $A$ в базисе из матричных единиц $E_{i j}$. Таким образом, определитель - квадратичная форма на пространстве $\mathrm{Mat}_{2}(\mathbb{R})$. Найдем ее поляризацию, применяя (41):
$$
\begin{aligned}
& \operatorname{det}(A+B)-\operatorname{det} A-\operatorname{det} B=a_{11} b_{22}-a_{12} b_{21}-a_{21} b_{12}+a_{22} b_{11}= \\
& \quad=\left(\begin{array}{llll}
a_{11} & a_{12} & a_{21} & a_{22}
\end{array}\right)\left(\begin{array}{cccc}
0 & 0 & 0 & 1 \\
0 & 0 & -1 & 0 \\
0 & -1 & 0 & 0 \\
1 & 0 & 0 & 0
\end{array}\right)\left(\begin{array}{l}
b_{11} \\
b_{12} \\
b_{21} \\
b_{22}
\end{array}\right) .
\end{aligned}
$$

Прямым вычислением легко убедиться, что полученная билинейная функция совпадает с $\operatorname{tr}(A \widehat{B})$. Приведение к сумме квадратов с помощью элементарных преобразований или методом Лагранжа показывает, что сигнатура этой формы ( 2,2 ).
Эту задачу (без пункта о сигнатуре) можно решить и по-другому. Во-первых, покажем, что $(A, B) \mapsto \operatorname{tr}(A \widehat{B}) / 2$ - билинейная форма на $\operatorname{Mat}_{2}(\mathbb{R})$ такая, что $\operatorname{det} A=\operatorname{tr}(A \widehat{A}) / 2$. Отсюда будет следовать, что $A \mapsto \operatorname{det} A-$ квадратичная форма на $\operatorname{Mat}_{2}(\mathbb{R})$. А поскольку билинейная форма $(A, B) \mapsto \operatorname{tr}(A \widehat{B}) / 2$ симметрична, то она - поляризация $\operatorname{det} A$.

\footnotetext{
${ }^{30}$ То есть транспонированная к матрице, состоящей из алгебраических дополнений матрицы $B$.
}

Линейность функции $\operatorname{tr}(A \widehat{B})$ как функции от первого аргумента $A$ при фиксированном втором очевидна; линейность относительно второго аргумента следует из линейности отображения $B \mapsto \widehat{B}$. Отсюда следует билинейность $\widetilde{\operatorname{det}}(A, B)$. Легко проверяемое тождество $\operatorname{tr}(A \widehat{A}) / 2=\operatorname{det} A$ означает равенство $\widetilde{\operatorname{det}}(A, A)=\operatorname{det} A$. Значит, $A \mapsto \operatorname{det} A-$ квадратичная форма.
Симметричность $\widetilde{\operatorname{det}}(A, B)$ вытекает из проверяемого прямым вычислением тождества $\operatorname{tr}(A \widehat{B})=\operatorname{tr}(B \widehat{A})$. Это и означает, что симметричная билинейная форма $\operatorname{tr}(A \widehat{B}) / 2$ является поляризацией квадратичной формы $A \mapsto \operatorname{det} A$.

Задача 3.3. Может ли матрица
$$
G=\left(\begin{array}{lll}
1 & 2 & 1 \\
2 & 1 & 1 \\
1 & 1 & 2
\end{array}\right)
$$

быть матрицей Грама некоторого базиса евклидова пространства?
Решение. Нет, не может. Для доказательства проще всего воспользоваться критерием Сильвестра, но можно рассуждать и непосредственно с помощью неравенства Коши-Буняковского: подматрица, стоящая на пересечении 1 -й и 2 -й строк и 1 -го и 2 -го столбцов матрицы $G$, показывает, что
$$
\left|\mathbf{e}_{1}\right|^{2}\left|\mathbf{e}_{2}\right|^{2}-\left(\mathbf{e}_{1}, \mathbf{e}_{2}\right)^{2}=-3<0
$$
(где $\left\{\mathbf{e}_{1}, \mathbf{e}_{2}, \mathbf{e}_{3}\right\}$ - базис, в котором записана матрица Грама $G$ ), что в евклидовом пространстве невозможно.

Комментарий. С помощью приведения квадратичной формы к сумме квадратов (по методу Лагранжа, с помощью элементарных преобразований или по методу Якоби, см. [15], гл. 5, § 4) легко проверить, что сигнатура формы, имеющей (в некотором базисе) матрицу Грама $G$, есть $(2,1)$, то есть найдется базис, в котором матрица Грама имеет диагональный вид $\operatorname{diag}(1,1,-1)$, или, эквивалентно, найдется невырожденная матрица $C$ такая, что $C^{T} G C=\operatorname{diag}(1,1,-1)$.

Задача 3.4. Пусть угловые миноры квадратичной формы $q$ на трехмерном вещественном пространстве $V$ удовлетворяют условиям $\delta_{1}=\delta_{2}=0, \delta_{3}>0$. Какие могут быть положительный $r_{+}$и отрицательный $r_{-}$индексы инерции $q$ ?

Решение. Ясно, что $r_{+}+r_{-}=3$, но при этом $r_{+}$и $r_{-}$больше нуля (поскольку в противном случае $q$ была бы знакоопределенной, но по условию она не удовлетворяет критерию Сильвестра). Если $r_{+}=2$, то существует двумерное подпространство $U \subset V$ такое, что $\left.q\right|_{U}$ положительно определена. Перейдем к базису в $V$, первые два вектора которого образуют базис в $U$, в нем $\delta_{1}^{\prime}>0, \delta_{2}^{\prime}>0$ и $\delta_{3}^{\prime}$ имеет тот же знак что и $\delta_{3}$, то есть тоже больше нуля. Тогда по критерию Сильвестра $q$ должна быть положительно определена, что противоречит условию. Значит, единственная возможность $r_{+}=1, r_{-}=2$. Она действительно реализуется (можно взять матрицу с единственными ненулевыми элементами $1,-1,1$ на побочной диагонали).

Любопытно, что набору $\delta_{1}=\delta_{2}=0, \delta_{3}<0$ отвечает сигнатура $r_{+}=2$, $r_{-}=1$.
Пусть $V$ - евклидово пространство, $U \subset V$ - его подпространство. Тогда $V=U \oplus U^{\perp}$, где $U^{\perp}:=\{\mathbf{v} \in V \mid(\mathbf{v}, \mathbf{u})==0 \forall \mathbf{u} \in U\}$, - ортогональное дополнение к $U$ в $V$. Следовательно, $\operatorname{dim} U^{\perp}=\operatorname{dim} V-\operatorname{dim} U$ и $U \cap U^{\perp}=\{\mathbf{0}\}$.

Задача 3.5. Пусть $V$ - конечномерное пространство над $\mathbb{R}, U \subset V, W \subset V$ - его подпространства, причем $V=U \oplus W$. Доказать, что существует скалярное произведение $(\cdot, \cdot)(=$ евклидова структура) на $V$ такое, что $W= U^{\perp}$ (и, таким образом, приведенное выше прямое разложение есть $V=U \oplus U^{\perp}$ ). Единственно ли оно?

Решение. Пусть $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{k}\right\}$ - базис в $U,\left\{\mathbf{e}_{k+1}, \ldots \mathbf{e}_{n}\right\}$ - базис в $W$, тогда их объединение $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ - базис в $V$. Объявим его ортонормированным; тогда, очевидно, $W=U^{\perp}$.
Если базис $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ ортонормирован для евклидовой структуры ( $\cdot, \cdot$ ), то ортонормированы и все базисы, получающиеся из него ортогональной заменой, и только они (см. комментарий к задаче 3.12 ниже). Отсюда легко видеть, что, за исключением тривиального случая $V=\{\mathbf{0}\}$, требуемая евклидова структура не единственна.

Задача 3.6. Доказать, что пространство $\operatorname{Mat}_{n}(\mathbb{R})$ с билинейной функцией $(A, B):=\operatorname{tr}\left(A^{T} B\right)$ является евклидовым пространством. Найти ортогональное дополнение в $\operatorname{Mat}_{n}(\mathbb{R})$ к подпространствам $V$ симметрических и $W$ верхнетреугольных матриц.

Решение. Во-первых, нужно проверить билинейность, симметричность и положительную определенность данной билинейной функции. Линейность по первому аргументу:
$$
\begin{gathered}
\left(A+A^{\prime}, B\right)=\operatorname{tr}\left(\left(A+A^{\prime}\right)^{T} B\right)=\operatorname{tr}\left(\left(A^{T}+A^{T}\right) B\right)= \\
=\operatorname{tr}\left(A^{T} B+A^{T} B\right)=\operatorname{tr}\left(A^{T} B\right)+\operatorname{tr}\left(A^{T} B\right)=(A, B)+\left(A^{\prime}, B\right), \\
(\lambda A, B)=\operatorname{tr}\left((\lambda A)^{T} B\right)=\operatorname{tr}\left(\lambda A^{T} B\right)=\lambda \operatorname{tr}\left(A^{T} B\right)=\lambda(A, B),
\end{gathered}
$$

и аналогично для второго аргумента. Симметричность:
$$
(A, B)=\operatorname{tr}\left(A^{T} B\right)=\operatorname{tr}\left(\left(A^{T} B\right)^{T}\right)=\operatorname{tr}\left(B^{T} A\right)=(B, A)
$$

Положительная определенность следует из формулы $\operatorname{tr}\left(A^{T} A\right)==\sum_{i, j=1}^{n} a_{i j}^{2}$. Таким образом, $\operatorname{Mat}_{n}(\mathbb{R})$ со скалярным произведением $(\cdot, \cdot)-n^{2}$-мерное евклидово пространство.
Для нахождения ортогонального дополнения к подпространству $W$ верхнетреугольных матриц воспользуемся следующим легко проверяемым утверждением: если $\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ - ортонормированный базис в евклидовом пространстве $V$, то для произвольного подмножества $I:=\left\{i_{1}, \ldots, i_{k}\right\} \subset\{1, \ldots, n\}$ ортогональным дополнением к линейной оболочке векторов $\left\{\mathbf{e}_{i_{1}}, \ldots, \mathbf{e}_{i_{k}}\right\}$ является линейная оболочка векторов $\left\{\mathbf{e}_{j_{1}}, \ldots, \mathbf{e}_{j_{n-k}}\right\}$, где $\left\{j_{1}, \ldots, j_{n-k}\right\}= \{1, \ldots, n\} \backslash I$.

Легко проверить, что матричные единицы $\left\{E_{i j} \mid 1 \leq i, j \leq n\right\}$ (при выбранном упорядочивании) образуют в евклидовом пространстве $\operatorname{Mat}_{n}(\mathbb{R})$ ортонормированный базис. Подпространство $W$ совпадает с линейной оболочкой матриц $\left\{E_{i j} \mid 1 \leq i \leq j \leq \leq n\right\}$, поэтому ортогональным дополнением $W^{\perp}$ является линейная оболочка матриц $\left\{E_{i j} \mid 1 \leq j \leq i \leq n\right\}$, то есть подпространство нижних нильтреугольных матрии (матриц, у которых нули на главной диагонали и выше).
Чтобы найти ортогональное дополнение к подпространству симметрических матриц $V$, для начала заметим, что $\operatorname{tr}\left(A^{T} B\right)==\sum_{i, j=1}^{n} a_{i j} b_{i j}$. Если $B$ ортогональна симметрическим матрицам, то, в частности, она ортогональна матрицам $E_{i i}, i=1, \ldots, n$. Отсюда $b_{i i}=0, i=1, \ldots, n$. Кроме того, $B$ ортогональна всем матрицам вида $E_{i j}+E_{j i}$, откуда $b_{i j}+b_{j i}=0,1 \leq i<j \leq n$. Значит, матрица $B$ кососимметрична.
С другой стороны, если $A=A^{T}$, а $B=-B^{T}$, то
$$
\begin{aligned}
& (A, B)=\operatorname{tr}\left(A^{T} B\right)=\operatorname{tr}(A B)=\operatorname{tr}(B A)= \\
& \quad=\operatorname{tr}\left(A^{T} B^{T}\right)=-\operatorname{tr}\left(A^{T} B\right)=-(A, B)
\end{aligned}
$$

откуда $(A, B)=0$. Объединяя этот результат с предыдущим, получаем, что $V^{\perp}$ совпадает с подпространством кососимметрических матриц.
Результат про $V^{\perp}$ можно доказать и по-другому, если заметить, что оператор транспонирования
$$
T: \operatorname{Mat}_{n}(\mathbb{R}) \rightarrow \operatorname{Mat}_{n}(\mathbb{R}), \quad T(A)=A^{T}
$$

самосопряжен относительно скалярного произведения $(A, B)=\operatorname{tr}\left(A^{T} B\right)$ :
$$
\begin{gathered}
(T(A), B)=\left(A^{T}, B\right)=\operatorname{tr}(A B)=\operatorname{tr}(B A)= \\
=\operatorname{tr}\left(A^{T} B^{T}\right)=\left(A, B^{T}\right)=(A, T(B))
\end{gathered}
$$
(здесь мы воспользовались известным свойством следа $\operatorname{tr}(A B)=\operatorname{tr}(B A)$, см. задачу 2.2). Собственные подпространства самосопряженного оператора, отвечающие разным собственным значениям, ортогональны. Подпространства симметричных и кососимметричных операторов в $\operatorname{Mat}_{n}(\mathbb{R})$ - собственные подпространства, отвечающие собственным значениям 1 и -1 .

Задача 3.7. Доказать, что любая линейная функция $f$ на пространстве матриц $\operatorname{Mat}_{n}(\mathbb{R})$ имеет вид $f(X)=\operatorname{tr}(A X)$, где $A \in \operatorname{Mat}_{n}(\mathbb{R})$, причем матрица $A=A_{f}$ функцией $f$ определяется однозначно.

Решение. Хорошо известно (и легко доказывается), что для всякого линейного функционала $f$ на евклидовом пространстве $V$ со скалярным произведением $g$ существует такой единственный вектор $\mathbf{u} \in V$, что $f(\mathbf{v})= g(\mathbf{u}, \mathbf{v}) \forall \mathbf{v} \in V$. Отсюда и из предыдущей задачи получаем, что всякий линейный функционал на $\operatorname{Mat}_{n}(\mathbb{R})$ имеет вид $f(X)=\operatorname{tr}\left(B^{T} X\right)$ для некоторой однозначно определенной матрицы $B \in \operatorname{Mat}_{n}(\mathbb{R})$. Полагая $A=B^{T}$, получаем требуемое.

Задача 3.8. Доказать, что функция $q(A):=\operatorname{tr}\left(A^{2}\right)$ является квадратичной формой на пространстве $\operatorname{Mat}_{n}(\mathbb{R})$, и найти ее сигнатуру.

Решение. Легко видеть, что $g(A, B):=\operatorname{tr}(A B)$ - билинейная форма на $\operatorname{Mat}_{n}(\mathbb{R})$ такая, что $q(A)=g(A, A)$. Таким образом, $q$ - квадратичная форма на $\operatorname{Mat}_{n}(\mathbb{R})$. Кстати, ввиду тождества $\operatorname{tr}(A B)=\operatorname{tr}(B A)$, билинейная форма $g$ симметрична.
Пусть $A^{T}=A$. Тогда, в силу предыдущей задачи, $\operatorname{tr}\left(A^{2}\right)==\operatorname{tr}\left(A^{T} A\right)> 0 \forall A \neq 0$. Таким образом, на подпространстве $V \subset \subset \operatorname{Mat}_{n}(\mathbb{R})$ симметрических матриц $q$ положительно определена.
Пусть $B^{T}=-B$. Тогда, в силу предыдущей задачи, $\operatorname{tr}\left(B^{2}\right)==-\operatorname{tr}\left(B^{T} B\right)< 0 \forall B \neq 0$. Таким образом, на подпространстве $U \subset \operatorname{Mat}_{n}(\mathbb{R})$ кососимметрических матриц $q$ отрицательно определена.
Приведем два варианта дальнейших рассуждений. Во-первых, легко заметить, что $U$ и $V$ ортогональны относительно $g$ : для симметрической и кососимметрической матриц $A, B$ имеем
$$
\begin{aligned}
& g(A, B)=\operatorname{tr}(A B)=\operatorname{tr}\left(B^{T} A^{T}\right)=-\operatorname{tr}(B A)= \\
& \quad=-\operatorname{tr}(A B)=-g(A, B) \quad \Rightarrow \quad g(A, B)=0 .
\end{aligned}
$$

Объединяя ортонормированные базисы в $V$ и $U$, получаем ортонормированный базис в $\operatorname{Mat}_{n}(\mathbb{R})$, в котором $\operatorname{dim} V=\frac{n(n+1)}{2}$ элементов имеют скалярный квадрат 1 и $\operatorname{dim} U=\frac{n(n-1)}{2}$ элементов - скалярный квадрат -1 .
Во-вторых, можно воспользоваться следующим соображением: если в пространстве $L$ с квадратичной формой $q$ есть $k$-мерное подпространство $W \subset L$, ограничение $q$ на которое положительно (отрицательно) определено, то положительный (отрицательный) индекс инерции $q$ не меньше $k$. Действительно, $W$ невырождено, поэтому $L=W \oplus W^{\perp}$. Возвращаясь к нашей задаче, мы видим, что положительный индекс инерции $q$ не меньше $\frac{n(n+1)}{2}$, а отрицательный индекс инерции - не меньше $\frac{n(n-1)}{2}$, причем сумма этих чисел равна $n^{2}=\operatorname{dim}_{\operatorname{Mat}}^{n}$ ( $\mathbb{R}$ ). Отсюда следует, что индексы инерции в точности равны указанным числам. \(\square\)

Задача 3.9. Предположим, что вещественное векторное пространство $V$, на котором задана квадратичная форма $q: V \rightarrow \mathbb{R}$, разложено в прямую сумму $V=U \oplus W$ своих подпространств, причем ограничения $\left.q\right|_{U}$ и $\left.q\right|_{W}$ положительно определены. Следует ли отсюда, что сама $q$ положительно определена? ${ }^{31}$

Решение. Ответ отрицательный, причем для построения контрпримера достаточно рассмотреть случай, когда двумерное пространство $V$ разложено в прямую сумму одномерных подпространств. Рассуждать при построении контрпримера можно следующим образом. Выберем базис $\left\{\mathbf{e}_{1}, \mathbf{e}_{2}\right\}$ в $V$ такой, что $U=\left\langle\mathbf{e}_{1}\right\rangle, W=\left\langle\mathbf{e}_{2}\right\rangle$. То, что ограничения $q$ на указанные подпространства положительно определены означает, что на главной диагонали в матрице $q$ в базисе $\left\{\mathbf{e}_{1}, \mathbf{e}_{2}\right\}$ стоят положительные числа, скажем, равные 1 . Требуется выбрать элементы вне главной диагонали так, чтобы полученная симметричная матрица не была положительно определенной, чего, конечно, легко добиться, положив эти элементы равными произвольному числу больше либо равному 1.

\footnotetext{
${ }^{31}$ задача сообщена авторам О.К. Подлипским.
}

Другой вариант рассуждения использует аргумент "по непрерывности". А именно, пусть ограничение $q$ на $\left\langle\mathbf{e}_{1}\right\rangle$ положительно определено. Рассмотрим вектор $\mathbf{e}_{2}^{\prime}:=\mathbf{e}_{1}+\varepsilon \mathbf{e}_{2}$, где положительное число $\varepsilon$ достаточно мало. Ясно, что линейная оболочка $\left\langle\mathbf{e}_{1}, \mathbf{e}_{2}^{\prime}\right\rangle$ совпадает с $V=\left\langle\mathbf{e}_{1}, \mathbf{e}_{2}\right\rangle$, в то же время из непрерывности $q$ и $q\left(\mathbf{e}_{1}\right)>0$ следует, что и $q\left(\mathbf{e}_{2}^{\prime}\right)>0$ при достаточно малых $\varepsilon$.

Задача 3.10. Доказать, что формула $(f, g)=\int_{-1}^{1} f(t) g(t) d t$ определяет скалярное произведение на линейном пространстве вещественнозначных функций, непрерывных на отрезке $[-1,1]$.

Решение. Билинейность следует из свойства линейности интеграла (см. [39], теорема 12.10 на с. 117), симметричность - из коммутативности умножения функций. Докажем положительную определенность. Если функция $f$ тождественно не равна нулю на отрезке $[-1,1]$, найдется точка $\alpha \in[-1,1]$ такая, что $f(\alpha) \neq 0$. Тогда (здесь используется непрерывность) для некоторого $\varepsilon>0$ найдется $\varepsilon$-окрестность $U_{\varepsilon}(\alpha)$ точки $\alpha$ (односторонняя в случае, когда $\alpha$ совпадает с одним из концов отрезка) такая, что $|f(x)| \geq |f(\alpha)| / 2 \forall x \in U_{\varepsilon}(\alpha)$. Тогда $(f, f)=\int_{-1}^{1} f(t)^{2} d t \geq \geq f(\alpha)^{2} \varepsilon / 4$. Подробности см., например, в [39], теорема 12.15 на с. 121.

Комментарий. Заметим, что данное пространство функций бесконечномерно. Так, например, мономы $\left\{1, x, x^{2}, \ldots, x^{n}\right\}$ линейно независимы как функции на $[-1,1]$ для любого $n \in \mathbb{N}$. Однако мономы не образуют ортонормированного базиса. Можно при помощи процесса Грама-Шмидта построить ортогональную систему из многочленов. Тогда мы придем к системе многочленов Лежандра (см., например, [35]), известны и другие системы ортогональных многочленов. Впрочем, есть и простой пример ортогональной (даже нормированной) системы функций на $[-1,1]$ : это система из тригонометрических функций
$$
\left\{\frac{1}{\sqrt{2}}, \cos k \pi x, \sin k \pi x \mid k \in \mathbb{N}\right\} .
$$

Разложение функции по такому базису приводит к понятию ряда Фурье. Обратим внимание читателя, что многие вопросы, которые не являются сложными для конечномерных пространств, в случае пространств бесконечномерных уже могут быть непростыми. Так, например, не очевиден ответ на вопрос, является ли в пространстве бесконечно дифференцируемых функций указанный базис из тригонометрических функций максимальной линейно независимой системой векторов. Подробнее об этом можно прочитать, например, в [31] (см. также добавление 3.6. в конце пособия).

Задача 3.11. Доказать, что матрица
$$
\left(\begin{array}{ccccc}
1 & \frac{1}{2} & \frac{1}{3} & \cdots & \frac{1}{n} \\
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} & \cdots & \frac{1}{n+1} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
\frac{1}{n} & \frac{1}{n+1} & \frac{1}{n+2} & \cdots & \frac{1}{2 n-1}
\end{array}\right)
$$

положительно определена.
Решение. В пространстве многочленов $\mathbb{R}[x]_{n-1}$ степени не выше $n-1$ введем скалярное произведение $(f, g)=\int_{0}^{1} f(x) g(x) d x$. Очевидно, форма $(\cdot, \cdot)$ билинейна, симметрична и положительно определена, значит, пространство $\mathbb{R}[x]_{n-1}$, снабженное данной билинейной формой, является $n$-мерным евклидовым пространством.
Рассмотрим базис $\left\{1, x, x^{2}, \ldots, x^{n-1}\right\}$ в $\mathbb{R}[x]_{n-1}$. Нетрудно проверить, что приведенная в условии матрица является матрицей Грама этого базиса.
Комментарий. Указанная в условии задачи матрица называется матрицей Гильберта и является классическим примером плохо обусловленной матрицы, то есть если $A_{n}$ - матрица Гильберта $n$-го порядка, то число обусловленности $\left\|A_{n}\right\| \times\left\|A_{n}^{-1}\right\|$ - велико. Вообще, матрица Гильберта является хорошей тестовой матрицей для проверки алгоритмов решения систем линейных уравнений и алгоритмов точного нахождения определителей матриц, наглядно демонстрируя даже на матрицах небольшого размера, какие проблемы возникают в вычислительной математике. Попробуйте, например, при помощи классического метода Гаусса на компьютере обратить матрицу Гильберта размера $5 \times 5$.

Задача 3.12. Доказать, что квадратичная форма является положительно определенной тогда и только тогда, когда ее матрица $A$ представляется в виде $A=C^{T} C$ для некоторой невырожденной верхней треугольной матрицы $C$.

Решение. То, что существует такая невырожденная матрица $C$, очевидно. Действительно, для положительно определенной квадратичной формы существует ортонормированный базис, то есть базис, в котором она имеет единичную матрицу $E$. Если $Q$ - матрица перехода от исходного базиса к данному ортонормированному, то $E=Q^{T} A Q$, тогда можно положить $C=Q^{-1}$. Tо, что, обратно, квадратичная форма с матрицей $A=C^{T} C$ положительно определена, тоже очевидно, так как условие положительной определенности не зависит от базиса, а для такой квадратичной формы найдется базис, в котором ее матрица есть $E$ (и она сама есть сумма квадратов).
Однако доказательство существования невырожденной верхней треугольной матрицы $C$ с указанным свойством требует чуть более тонкого исследования. А именно, вспомним, что ортонормированный базис можно строить из исходного с помощью алгоритма Грама-Шмидта. Точнее, пусть исходный базис (в котором матрица квадратичной формы была $A$ ) есть $\left\{\mathbf{e}_{1}^{\prime}, \ldots, \mathbf{e}_{n}^{\prime}\right\}$. Тогда ортогональный базис $\left\{\mathbf{e}_{1}^{\prime \prime}, \ldots, \mathbf{e}_{n}^{\prime \prime}\right\}$ строится по индукции: в качестве $\mathbf{e}_{1}^{\prime \prime}$ возьмем $\mathbf{e}_{1}^{\prime}$, и, если $\mathbf{e}_{1}^{\prime \prime}, \ldots, \mathbf{e}_{i-1}^{\prime \prime}$ уже построены, $\mathbf{e}_{i}^{\prime \prime}$ ищем в виде $\mathbf{e}_{i}^{\prime \prime}= \mathbf{e}_{i}^{\prime}-\sum_{j=1}^{i-1} x_{j} \mathbf{e}_{j}^{\prime}$, где скаляры $x_{j}$ находятся из условия ортогональности $\mathbf{e}_{i}^{\prime \prime}$ к векторам $\mathbf{e}_{1}^{\prime}, \ldots, \mathbf{e}_{i-1}^{\prime}$. Такой набор $\left\{x_{j}\right\}$ существует и единствен, поскольку является решением квадратной системы линейных уравнений, матрицей коэффициентов которой является матрица Грама системы линейно независимых векторов $\left\{\mathbf{e}_{1}^{\prime}, \ldots, \mathbf{e}_{i-1}^{\prime}\right\}$, которая в силу положительной определенности квадратичной формы невырождена.
Легко видеть, что матрица перехода от базиса $\left\{\mathbf{e}_{1}^{\prime}, \ldots, \mathbf{e}_{n}^{\prime}\right\}$ к его ортогонализации $\left\{\mathbf{e}_{1}^{\prime \prime}, \ldots, \mathbf{e}_{n}^{\prime \prime}\right\}$ верхняя треугольная с единицами на главной диагонали. Затем при построении ортонормированного базиса мы каждый столбец

умножаем на величину, обратную длине соответствующего базисного вектора ортогонального базиса (что равносильно умножению матрицы перехода справа на диагональную матрицу). Это дает искомую верхнетреугольную матрицу. Заметим еще, что на главной диагонали этой матрицы стоят положительные числа.

Комментарий. Заметим, что из приведенного рассуждения легко выводится, что для произвольной невырожденной матрицы $C \in \operatorname{Mat}_{n}(\mathbb{R})$ существует, причем единственная, пара, состоящая из ортогональной матрицы $Q$ и верхней треугольной матрицы с положительными диагональными элементами $R$ такая, что $C=Q R$ (так называемое " $Q R$-разложение" [10], гл. VII, § 1, п. 9).
Кстати, данный результат позволяет описать множество всех структур евклидова пространства на вещественном векторном $n$-мерном пространстве $V$. Действительно, пусть $\mathcal{E}$ - структура евклидова пространства на $V$, для которой базис $\{\mathbf{e}\}:=\left\{\mathbf{e}_{1}, \ldots, \mathbf{e}_{n}\right\}$ является ортонормированным (ясно, что выбор ортонормированного базиса определяет евклидову структуру однозначно; обратно, базис определяется евклидовой структурой с точностью до ортогональной замены). Тогда если $\mathcal{E}^{\prime}$ - еще одна структура евклидова пространства на $V$ с некоторым ортонормированным базисом $\left\{\mathbf{e}^{\prime}\right\}:= \left\{\mathbf{e}_{1}^{\prime}, \ldots, \mathbf{e}_{n}^{\prime}\right\}$, то существует единственная матрица $C_{\{\mathbf{e}\} \rightarrow\left\{\mathbf{e}^{\prime}\right\}} \in \mathrm{GL}_{n}(\mathbb{R})$ (матрица перехода). Таким образом, на множестве евклидовых структур на $V$ группа $\mathrm{GL}(V) \cong \mathrm{GL}_{n}(\mathbb{R})$ действует транзитивно, причем стабилизатором точки является ортогональная подгруппа $\mathrm{O}(n) \subset \mathrm{GL}_{n}(\mathbb{R})$. Тогда множество евклидовых структур есть однородное пространство $\mathrm{GL}_{n}(\mathbb{R}) / \mathrm{O}(n)$, которое $Q R$-разложение позволяет отождествить с множеством верхних треугольных матриц с положительными элементами на главной диагонали.

Задача 3.13. Множество положительно определенных квадратичных форм в $\mathbb{R}^{n}$ открыто в линейном пространстве всех квадратичных форм $\mathbb{R}^{n(n+1)}$.

Решение. Согласно критерию Сильвестра, подмножество положительно определенных форм в $\mathbb{R}^{n}$ совпадает с пересечением $n$ открытых подмножеств в $\mathbb{R}^{n(n+1)}$, задаваемых условиями положительности главных миноров их матриц.

Комментарий. Более того, можно доказать, что множество невырожденных квадратичных форм с данной сигнатурой открыто в $\mathbb{R}^{n(n+1)}$. Например, пространство квадратичных форм $a x^{2}+b x y+c y^{2}$ от двух переменных - это трехмерное пространство с координатами ( $a, b, c$ ). Конус $b^{2}=4 a c$ делит это пространство на три открытые части соответственно сигнатурам.

Задача 3.14. Пусть $V$ - двумерное векторное пространство над $\mathbb{R}$, снабженное билинейной симметричной формой $h$ сигнатуры $(1,1)$. Найти группу изометрий ( $V, h$ ).

Решение. Выберем ортонормированный базис $\left\{\mathbf{e}_{1}, \mathbf{e}_{2}\right\}$ в $V$, в котором матрица Грама формы $h$ имеет вид $H:=\left(\begin{array}{cc}1 & 0 \\ 0 & -1\end{array}\right)$, а значит, сама билинейная форма $h(\mathbf{u}, \mathbf{v})=x_{1} y_{1}-x_{2} y_{2}$, где $\mathbf{u}=\left(x_{1}, x_{2}\right)^{T}, \mathbf{v}=\left(y_{1}, y_{2}\right)^{T}$.

Линейное преобразование $\varphi: V \rightarrow V$ является изометрией тогда и только тогда, когда $h(\varphi(\mathbf{u}), \varphi(\mathbf{v}))=h(\mathbf{u}, \mathbf{v}) \quad \forall \mathbf{u}, \mathbf{v} \in V$. Если $A=A_{\varphi}$ - матрица преобразования $\varphi$ в выбранном базисе, то это эквивалентно равенству $(A \mathbf{u})^{T} H(A \mathbf{v})=\mathbf{u}^{T} H \mathbf{v} \quad \forall \mathbf{u}, \mathbf{v} \in V$, откуда
$$
\begin{equation*}
A^{T} H A=H . \tag{42}
\end{equation*}
$$

То есть наша задача - найти все матрицы $A$, удовлетворяющие (42). Равенство (42) можно переписать в эквивалентном виде $A^{T} H=H A^{-1}$. Заметим, что из (42) следует, что $\operatorname{det} A= \pm 1$.
Пусть $A=\left(\begin{array}{ll}a & b \\ c & d\end{array}\right)$, тогда если $\operatorname{det} A=1$, то $A^{-1}=\left(\begin{array}{cc}d & -b \\ -c & a\end{array}\right)$, и мы получаем систему $a=d, b=c, a^{2}-b^{2}=1$, то есть $A==\left(\begin{array}{ll}a & b \\ b & a\end{array}\right)$, причем $a^{2}-b^{2}=1$. Последнее равенство - уравнение гиперболы, одну ее ветвь можно параметризовать, положив $a=\operatorname{ch} \vartheta, b=\operatorname{sh} \vartheta, \vartheta \in \mathbb{R}$, другую -$a=-\operatorname{ch} \vartheta, b=-\operatorname{sh} \vartheta, \vartheta \in \mathbb{R}$. Первая ветвь отвечает множеству матриц
$$
\left(\begin{array}{ll}
\operatorname{ch} \vartheta & \operatorname{sh} \vartheta  \tag{43}\\
\operatorname{sh} \vartheta & \operatorname{ch} \vartheta
\end{array}\right)
$$

содержащему единичный элемент (при $\vartheta=0$ ). Легко проверить, что это подгруппа в группе $\mathrm{GL}_{2}(\mathbb{R})$ (даже в $\mathrm{SL}_{2}(\mathbb{R})$ ).
Пусть $\operatorname{det} A=-1$, в этом случае $A^{-1}=\left(\begin{array}{cc}-d & b \\ c & -a\end{array}\right)$, тогда из (42) получаем систему $a=-d, b=-c$, кроме того, из $\operatorname{det} A==-1$ получаем $a^{2}-b^{2}=1$. В этом случае мы также имеем два семейства: $a=\operatorname{ch} \vartheta, b=\operatorname{sh} \vartheta$ и $a= -\operatorname{ch} \vartheta, b=-\operatorname{sh} \vartheta$.
Таким образом, группа изометрий ( $V, h$ ) в выбранном базисе состоит из матриц, принадлежащих четырем семействам:
$$
\begin{gathered}
\left(\begin{array}{cc}
\operatorname{ch} \vartheta & \operatorname{sh} \vartheta \\
\operatorname{sh} \vartheta & \operatorname{ch} \vartheta
\end{array}\right), \quad\left(\begin{array}{ll}
-\operatorname{ch} \vartheta & -\operatorname{sh} \vartheta \\
-\operatorname{sh} \vartheta & -\operatorname{ch} \vartheta
\end{array}\right), \\
\left(\begin{array}{cc}
\operatorname{ch} \vartheta & \operatorname{sh} \vartheta \\
-\operatorname{sh} \vartheta & -\operatorname{ch} \vartheta
\end{array}\right) \text { и }\left(\begin{array}{cc}
-\operatorname{ch} \vartheta & -\operatorname{sh} \vartheta \\
\operatorname{sh} \vartheta & \operatorname{ch} \vartheta
\end{array}\right), \text { где } \vartheta \in \mathbb{R},
\end{gathered}
$$

причем первое семейство является подгруппой ("связной компонентой единицы").
Комментарий. Матрицы (43) похожи на матрицы поворота плоскости, правда, в них участвуют гиперболические функции вместо тригонометрических. Действительно, матрицы (43) сохраняют квадратичную форму $x_{1}^{2}-x_{2}^{2}$, в то время как "обычные" матрицы поворота - форму $x_{1}^{2}+x_{2}^{2}$. Матрицы вида (43) определяют так называемые гиперболические повороты, при которых концы векторов, отложенных от начала координат, движутся по равнобочной гиперболе (в то время как в случае обычных поворотов - по окружности).
Гиперболические повороты дают геометрическое описание так называемых бустов (переходов к новой инерциальной системе отсчета) в специальной теории относительности (СТО). Поясним это.

Пространство-время в СТО - четырехмерное вещественное линейное пространство $V$, снабженное квадратичной формой сигнатуры $(1,3)$ ("метрикой Минковского"). Выбирая ортонормированный базис $\left\{\mathbf{e}_{0}, \mathbf{e}_{1}, \mathbf{e}_{2}, \mathbf{e}_{3}\right\}$, отождествим $V$ с $\mathbb{R}^{4}$, при этом квадратичная форма примет вид $c^{2} t^{2}-x^{2}-y^{2}-z^{2}$, где $t$ - временна́я, $x, y, z$ - пространственные координаты, а $c$ - физическая постоянная, имеющая физическую размерность скорости (скорость света в вакууме). Заметим, что выбор базиса фиксирует некоторую инерциальную систему отсчета, для которой ортогональное дополнение $\left\langle\mathbf{e}_{0}\right\rangle^{\perp}$ к временно́й оси $t$ (то есть трехмерное подпространство в $V$ с базисом $\left\{\mathbf{e}_{1}, \mathbf{e}_{2}, \mathbf{e}_{3}\right\}$ ) пространство одновременных событий для соответствующего наблюдателя. Изометрии пространства-времени образуют так называемую группу Лорен$u_{u}{ }^{32}$. Они включают в себя помимо обычных вращений в трехмерном пространстве $\left\langle\mathbf{e}_{0}\right\rangle^{\perp}$ гиперболические повороты в плоскостях с ортонормированными базисами вида $\left\{\mathbf{e}_{0}, \mathbf{e}\right\}$ (гиперболические, так как ограничение формы $c^{2} t^{2}-x^{2}-y^{2}-z^{2}$ на такую плоскость имеет сигнатуру $(1,1)$ ), "перемешивающие" временну́ю и пространственную координаты. Например, пусть $\mathbf{e}=\mathbf{e}_{1}$. Тогда гиперболический поворот в этой плоскости - то же, что буст в направлении оси $x$.
Более подробно: к матрице (43) добавим справа внизу единичную матрицу порядка 2 , дополнив нулями до матрицы порядка 4 , и полученную матрицу интерпретируем как матрицу перехода от базиса $\left\{\mathbf{e}_{0}, \mathbf{e}_{1}, \mathbf{e}_{2}, \mathbf{e}_{3}\right\}$ к новому ортонормированному базису $\left\{\mathbf{e}_{0}^{\prime}, \mathbf{e}_{1}^{\prime}, \mathbf{e}_{2}, \mathbf{e}_{3}\right\}$ (т.е. матрицу $A$ в формуле (42) мы интерпретируем как матрицу перехода, это соответствует интерпретации $A$ как пассивного преобразования). Тогда старые и новые координаты окажутся связанными формулой
$$
\left(\begin{array}{c}
c t \\
x \\
y \\
z
\end{array}\right)=\left(\begin{array}{cccc}
\operatorname{ch} \vartheta & \operatorname{sh} \vartheta & 0 & 0 \\
\operatorname{sh} \vartheta & \operatorname{ch} \vartheta & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{array}\right)\left(\begin{array}{c}
c t^{\prime} \\
x^{\prime} \\
y^{\prime} \\
z^{\prime}
\end{array}\right)
$$

В СТО безразмерная величина $\operatorname{th} \vartheta$ интерпретируется как $v / c$, где $v$ - скорость новой системы отсчета, связанной с базисом $\left\{\mathbf{e}_{0}^{\prime}, \mathbf{e}_{1}^{\prime}, \mathbf{e}_{2}, \mathbf{e}_{3}\right\}$ относительно старой системы отсчета, связанной с базисом $\left\{\mathbf{e}_{0}, \mathbf{e}_{1}, \mathbf{e}_{2}, \mathbf{e}_{3}\right\}$. То есть формулы перехода к новой системе отсчета, движущейся относительно старой со скоростью $v$ в направлении оси $x$, имеют следующий вид:
$$
\binom{c t}{x}=\left(\begin{array}{cc}
\frac{1}{\sqrt{1-v^{2} / c^{2}}} & \frac{v / c}{\sqrt{1-v^{2} / c^{2}}} \\
\frac{v / c}{\sqrt{1-v^{2} / c^{2}}} & \frac{1}{\sqrt{1-v^{2} / c^{2}}}
\end{array}\right)\binom{c t^{\prime}}{x^{\prime}}, \quad y=y^{\prime}, \quad z=z^{\prime} .
$$

Таким образом, буст в направлении оси $x$ записывается формулами
$$
t=\frac{t^{\prime}+\frac{v x^{\prime}}{c^{2}}}{\sqrt{1-v^{2} / c^{2}}}, \quad x=\frac{x^{\prime}+v t^{\prime}}{\sqrt{1-v^{2} / c^{2}}}, \quad y=y^{\prime}, z=z^{\prime}
$$

Заметим, что при $v / c \rightarrow 0$ приведенные выше формулы переходят в преобразование Галилея $t=t^{\prime}, x=x^{\prime}+v t^{\prime}, y=y^{\prime}, z=z^{\prime}$. Еще одно простое

\footnotetext{
${ }^{32}$ Впервые описанную А. Пуанкаре.
}